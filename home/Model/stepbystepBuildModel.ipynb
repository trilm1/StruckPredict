{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<center>BỘ GIÁO DỤC VÀ ĐÀO TẠO</center>**\n",
    "**<center>TRƯỜNG ĐẠI HỌC SƯ PHẠM KỸ THUẬT TP.HỒ CHÍ MINH</center>**\n",
    "**<center>KHOA CÔNG NGHỆ THÔNG TIN</center>**\n",
    "**<center>BÁO CÁO ĐỒ ÁN</center>**\n",
    "**<center>MÔN HỌC : TIỂU LUẬN CHUYÊN NGÀNH KỸ THUẬT DỮ LIỆU</center>**\n",
    "**<center>TÊN ĐỀ TÀI: TÌM HIỂU BẢO MẬT KHÁC BIỆT TRONG XÂY DỰNG MÔ HÌNH HỌC MÁY HỖ TRỢ CHẨN ĐOÁN BỆNH</center>**\n",
    "**<center>GVHD: PGS.TS Hoàng Văn Dũng</center>**\n",
    "**<center>GVPB: ThS Quách Đình Hoàng</center>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Sinh viên thực hiện**<br>\n",
    "- Huỳnh Nguyễn Như Nguyên - 20133019<br>\n",
    "- Lê Minh Trí - 20133100<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I. Giới thiệu về bài toán và dữ liệu\n",
    "#### 1. Giới thiệu về bài toán\n",
    " Bài toán dự đoán nguy cơ bị đột quỵ thông qua mô hình học máy đang trở thành một lĩnh vực nghiên cứu quan trọng trong y học hiện đại. Đối với bệnh nhân, việc đánh giá rủi ro đột quỵ không chỉ mang lại sự hiểu biết sâu sắc về tình trạng sức khỏe cá nhân mà còn giúp họ có thể thay đổi lối sống và thực hiện biện pháp phòng tránh để giảm nguy cơ. Tuy nhiên, mặc dù mô hình học máy có thể mang lại những độ chính xác đáng kể, nhưng vấn đề về quyền riêng tư ngày càng trở nên nghiêm trọng. Đặc biệt là trong lĩnh vực y tế, bảo vệ thông tin cá nhân của bệnh nhân là ưu tiên hàng đầu. Để giải quyết vấn đề này, áp dụng Differential Privacy vào mô hình dự đoán đột quỵ có thể đóng một vai trò quan trọng.\n",
    "Differential Privacy là một khái niệm về bảo vệ quyền riêng tư trong việc xử lý dữ liệu. Khi được áp dụng vào mô hình học máy, nó giúp đảm bảo rằng thông tin cá nhân của từng bệnh nhân không thể được tái tạo hoặc xâm phạm dựa trên kết quả đầu ra của mô hình. Điều này có nghĩa là người sử dụng mô hình sẽ chỉ nhận được thông tin tổng quát mà không thể xác định được thông tin chi tiết của từng cá nhân trong tập dữ liệu.Tóm lại, sự kết hợp giữa mô hình học máy dự đoán đột quỵ và Differential Privacy không chỉ mang lại hiệu suất cao mà còn đảm bảo sự an toàn và bảo vệ quyền riêng tư cho bệnh nhân. Điều này mở ra những triển vọng tích cực trong nghiên cứu y học và có thể giúp cải thiện chất lượng chăm sóc sức khỏe cũng như quản lý nguy cơ đột quỵ trong cộng đồng.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Dữ liệu của nhóm\n",
    "- Tập dữ liệu brain_stroke.csv mà nhóm sử dụng được thu thập từ Kaggle: https://www.kaggle.com/datasets/jillanisofttech/brain-stroke-dataset<br>\n",
    "- Cung cấp thông tin chi tiết về các yếu tố ảnh hưởng đến nguy cơ đột quỵ.<br> \n",
    "- Tập dữ liệu này bao gồm 4981 hàng và 11 thuộc tính khác nhau, mô tả đa dạng các thông tin liên quan đến sức khỏe và lối sống của các cá nhân.<br>\n",
    "- Dữ liệu được tổ chức chặt chẽ trong các cột như giới tính (gender), độ tuổi (age), có mắc bệnh cao huyết áp (hypertension) hay bệnh tim (heart_disease) không, tình trạng hôn nhân (ever_married), loại công việc (work_type), loại nơi cư trú (Residence_type), cấp độ đường huyết trung bình (avg_glucose_level), chỉ số BMI (bmi), tình trạng hút thuốc (smoking_status), và kết quả về việc có phát sinh đột quỵ hay không (stroke)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### II. Tiền xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import opacus\n",
    "from imblearn.over_sampling import SVMSMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>work_type</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>smoking_status</th>\n",
       "      <th>stroke</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>smokes</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Self-employed</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>never smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Private</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>formerly smoked</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married      work_type  \\\n",
       "0    Male  67.0             0              1          Yes        Private   \n",
       "1    Male  80.0             0              1          Yes        Private   \n",
       "2  Female  49.0             0              0          Yes        Private   \n",
       "3  Female  79.0             1              0          Yes  Self-employed   \n",
       "4    Male  81.0             0              0          Yes        Private   \n",
       "\n",
       "  Residence_type  avg_glucose_level   bmi   smoking_status  stroke  \n",
       "0          Urban             228.69  36.6  formerly smoked       1  \n",
       "1          Rural             105.92  32.5     never smoked       1  \n",
       "2          Urban             171.23  34.4           smokes       1  \n",
       "3          Rural             174.12  24.0     never smoked       1  \n",
       "4          Urban             186.21  29.0  formerly smoked       1  "
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"./data/brain_stroke.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248\n",
      "4733\n"
     ]
    }
   ],
   "source": [
    "print((data['stroke']==1).sum())\n",
    "print((data['stroke']==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                object\n",
       "age                  float64\n",
       "hypertension           int64\n",
       "heart_disease          int64\n",
       "ever_married          object\n",
       "work_type             object\n",
       "Residence_type        object\n",
       "avg_glucose_level    float64\n",
       "bmi                  float64\n",
       "smoking_status        object\n",
       "stroke                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gender - 2 : ['Male' 'Female']\n",
      "age - 104 : [6.70e+01 8.00e+01 4.90e+01 7.90e+01 8.10e+01 7.40e+01 6.90e+01 7.80e+01\n",
      " 6.10e+01 5.40e+01 5.00e+01 6.40e+01 7.50e+01 6.00e+01 7.10e+01 5.20e+01\n",
      " 8.20e+01 6.50e+01 5.70e+01 4.20e+01 4.80e+01 7.20e+01 5.80e+01 7.60e+01\n",
      " 3.90e+01 7.70e+01 6.30e+01 7.30e+01 5.60e+01 4.50e+01 7.00e+01 5.90e+01\n",
      " 6.60e+01 4.30e+01 6.80e+01 4.70e+01 5.30e+01 3.80e+01 5.50e+01 4.60e+01\n",
      " 3.20e+01 5.10e+01 1.40e+01 3.00e+00 8.00e+00 3.70e+01 4.00e+01 3.50e+01\n",
      " 2.00e+01 4.40e+01 2.50e+01 2.70e+01 2.30e+01 1.70e+01 1.30e+01 4.00e+00\n",
      " 1.60e+01 2.20e+01 3.00e+01 2.90e+01 1.10e+01 2.10e+01 1.80e+01 3.30e+01\n",
      " 2.40e+01 3.60e+01 6.40e-01 3.40e+01 4.10e+01 8.80e-01 5.00e+00 2.60e+01\n",
      " 3.10e+01 7.00e+00 1.20e+01 6.20e+01 2.00e+00 9.00e+00 1.50e+01 2.80e+01\n",
      " 1.00e+01 1.80e+00 3.20e-01 1.08e+00 1.90e+01 6.00e+00 1.16e+00 1.00e+00\n",
      " 1.40e+00 1.72e+00 2.40e-01 1.64e+00 1.56e+00 7.20e-01 1.88e+00 1.24e+00\n",
      " 8.00e-01 4.00e-01 8.00e-02 1.48e+00 5.60e-01 1.32e+00 1.60e-01 4.80e-01]\n",
      "hypertension - 2 : [0 1]\n",
      "heart_disease - 2 : [1 0]\n",
      "ever_married - 2 : ['Yes' 'No']\n",
      "work_type - 4 : ['Private' 'Self-employed' 'Govt_job' 'children']\n",
      "Residence_type - 2 : ['Urban' 'Rural']\n",
      "avg_glucose_level - 3895 : [228.69 105.92 171.23 ... 191.15  95.02  83.94]\n",
      "bmi - 342 : [36.6 32.5 34.4 24.  29.  27.4 22.8 24.2 29.7 36.8 27.3 28.2 30.9 37.5\n",
      " 25.8 37.8 22.4 48.9 26.6 27.2 23.5 28.3 44.2 25.4 22.2 30.5 26.5 33.7\n",
      " 23.1 32.  29.9 23.9 28.5 26.4 20.2 33.6 38.6 39.2 27.7 31.4 36.5 33.2\n",
      " 32.8 40.4 25.3 30.2 47.5 20.3 30.  28.9 28.1 31.1 21.7 27.  24.1 45.9\n",
      " 44.1 22.9 29.1 32.3 41.1 25.6 29.8 26.3 26.2 29.4 24.4 28.  28.8 34.6\n",
      " 19.4 30.3 41.5 22.6 27.1 31.3 31.  31.7 35.8 28.4 20.1 26.7 38.7 34.9\n",
      " 25.  23.8 21.8 27.5 24.6 32.9 26.1 31.9 34.1 36.9 37.3 45.7 34.2 23.6\n",
      " 22.3 37.1 45.  25.5 30.8 37.4 34.5 27.9 29.5 46.  42.5 35.5 26.9 45.5\n",
      " 31.5 33.  23.4 30.7 20.5 21.5 40.  28.6 42.2 29.6 35.4 16.9 26.8 39.3\n",
      " 32.6 35.9 21.2 42.4 40.5 36.7 29.3 19.6 18.  17.6 17.7 35.  22.  39.4\n",
      " 19.7 22.5 25.2 41.8 23.7 24.5 31.2 16.  31.6 25.1 24.8 18.3 20.  19.5\n",
      " 36.  35.3 40.1 43.1 21.4 34.3 27.6 16.5 24.3 25.7 21.9 38.4 25.9 18.6\n",
      " 24.9 48.2 20.7 39.5 23.3 35.1 43.6 21.  47.3 16.6 21.6 15.5 35.6 16.7\n",
      " 41.9 16.4 17.1 29.2 37.9 44.6 39.6 40.3 41.6 39.  23.2 18.9 36.1 36.3\n",
      " 46.5 16.8 46.6 35.2 20.9 31.8 15.3 38.2 45.2 17.  27.8 23.  22.1 26.\n",
      " 44.3 39.7 34.7 21.3 41.2 34.8 19.2 35.7 40.8 24.7 19.  32.4 34.  28.7\n",
      " 32.1 20.4 30.6 19.3 40.9 17.2 16.1 16.2 40.6 18.4 21.1 42.3 32.2 17.5\n",
      " 42.1 47.8 20.8 30.1 17.3 36.4 36.2 14.4 43.  41.7 33.8 43.9 22.7 18.7\n",
      " 37.  38.5 16.3 44.  32.7 40.2 33.3 17.4 41.3 14.6 17.8 46.1 33.1 18.1\n",
      " 43.8 38.9 43.7 39.9 15.9 19.8 38.3 41.  42.6 43.4 15.1 20.6 33.5 43.2\n",
      " 19.1 30.4 38.  33.4 44.9 44.7 37.6 39.8 42.  37.2 42.8 18.8 42.9 14.3\n",
      " 37.7 48.4 46.2 43.3 33.9 18.5 44.5 45.4 19.9 17.9 15.6 15.2 18.2 48.5\n",
      " 14.1 15.7 44.8 38.1 44.4 38.8 39.1 41.4 14.2 15.4 45.1 48.7 42.7 48.8\n",
      " 15.8 45.3 14.8 40.7 48.  46.8 48.3 14.5 15.  47.4 47.9 45.8 47.6 14.\n",
      " 46.4 46.9 47.1 48.1 46.3 14.9]\n",
      "smoking_status - 4 : ['formerly smoked' 'never smoked' 'smokes' 'Unknown']\n",
      "stroke - 2 : [1 0]\n"
     ]
    }
   ],
   "source": [
    "for column in data:\n",
    "    print(f\"{column} - {len(data[column].unique())} : {data[column].unique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Rural</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Urban</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease ever_married Residence_type  \\\n",
       "0    Male  67.0             0              1          Yes          Urban   \n",
       "1    Male  80.0             0              1          Yes          Rural   \n",
       "2  Female  49.0             0              0          Yes          Urban   \n",
       "3  Female  79.0             1              0          Yes          Rural   \n",
       "4    Male  81.0             0              0          Yes          Urban   \n",
       "\n",
       "   avg_glucose_level   bmi  stroke  work_type_Govt_job  work_type_Private  \\\n",
       "0             228.69  36.6       1                   0                  1   \n",
       "1             105.92  32.5       1                   0                  1   \n",
       "2             171.23  34.4       1                   0                  1   \n",
       "3             174.12  24.0       1                   0                  0   \n",
       "4             186.21  29.0       1                   0                  1   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  smoking_status_Unknown  \\\n",
       "0                        0                   0                       0   \n",
       "1                        0                   0                       0   \n",
       "2                        0                   0                       0   \n",
       "3                        1                   0                       0   \n",
       "4                        0                   0                       0   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               1                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            0   \n",
       "3                               0                            1   \n",
       "4                               1                            0   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummies = pd.get_dummies(data, columns = [\"work_type\", \"smoking_status\"])\n",
    "data = dummies\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                             object\n",
       "age                               float64\n",
       "hypertension                        int64\n",
       "heart_disease                       int64\n",
       "ever_married                       object\n",
       "Residence_type                     object\n",
       "avg_glucose_level                 float64\n",
       "bmi                               float64\n",
       "stroke                              int64\n",
       "work_type_Govt_job                  uint8\n",
       "work_type_Private                   uint8\n",
       "work_type_Self-employed             uint8\n",
       "work_type_children                  uint8\n",
       "smoking_status_Unknown              uint8\n",
       "smoking_status_formerly smoked      uint8\n",
       "smoking_status_never smoked         uint8\n",
       "smoking_status_smokes               uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "      <td>4981.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>43.419859</td>\n",
       "      <td>0.096165</td>\n",
       "      <td>0.055210</td>\n",
       "      <td>105.943562</td>\n",
       "      <td>28.498173</td>\n",
       "      <td>0.049789</td>\n",
       "      <td>0.129291</td>\n",
       "      <td>0.574182</td>\n",
       "      <td>0.161413</td>\n",
       "      <td>0.135113</td>\n",
       "      <td>0.301144</td>\n",
       "      <td>0.174061</td>\n",
       "      <td>0.369002</td>\n",
       "      <td>0.155792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>22.662755</td>\n",
       "      <td>0.294848</td>\n",
       "      <td>0.228412</td>\n",
       "      <td>45.075373</td>\n",
       "      <td>6.790464</td>\n",
       "      <td>0.217531</td>\n",
       "      <td>0.335556</td>\n",
       "      <td>0.494516</td>\n",
       "      <td>0.367949</td>\n",
       "      <td>0.341879</td>\n",
       "      <td>0.458801</td>\n",
       "      <td>0.379200</td>\n",
       "      <td>0.482583</td>\n",
       "      <td>0.362694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55.120000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>77.230000</td>\n",
       "      <td>23.700000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>91.850000</td>\n",
       "      <td>28.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>113.860000</td>\n",
       "      <td>32.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>82.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>271.740000</td>\n",
       "      <td>48.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               age  hypertension  heart_disease  avg_glucose_level  \\\n",
       "count  4981.000000   4981.000000    4981.000000        4981.000000   \n",
       "mean     43.419859      0.096165       0.055210         105.943562   \n",
       "std      22.662755      0.294848       0.228412          45.075373   \n",
       "min       0.080000      0.000000       0.000000          55.120000   \n",
       "25%      25.000000      0.000000       0.000000          77.230000   \n",
       "50%      45.000000      0.000000       0.000000          91.850000   \n",
       "75%      61.000000      0.000000       0.000000         113.860000   \n",
       "max      82.000000      1.000000       1.000000         271.740000   \n",
       "\n",
       "               bmi       stroke  work_type_Govt_job  work_type_Private  \\\n",
       "count  4981.000000  4981.000000         4981.000000        4981.000000   \n",
       "mean     28.498173     0.049789            0.129291           0.574182   \n",
       "std       6.790464     0.217531            0.335556           0.494516   \n",
       "min      14.000000     0.000000            0.000000           0.000000   \n",
       "25%      23.700000     0.000000            0.000000           0.000000   \n",
       "50%      28.100000     0.000000            0.000000           1.000000   \n",
       "75%      32.600000     0.000000            0.000000           1.000000   \n",
       "max      48.900000     1.000000            1.000000           1.000000   \n",
       "\n",
       "       work_type_Self-employed  work_type_children  smoking_status_Unknown  \\\n",
       "count              4981.000000         4981.000000             4981.000000   \n",
       "mean                  0.161413            0.135113                0.301144   \n",
       "std                   0.367949            0.341879                0.458801   \n",
       "min                   0.000000            0.000000                0.000000   \n",
       "25%                   0.000000            0.000000                0.000000   \n",
       "50%                   0.000000            0.000000                0.000000   \n",
       "75%                   0.000000            0.000000                1.000000   \n",
       "max                   1.000000            1.000000                1.000000   \n",
       "\n",
       "       smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "count                     4981.000000                  4981.000000   \n",
       "mean                         0.174061                     0.369002   \n",
       "std                          0.379200                     0.482583   \n",
       "min                          0.000000                     0.000000   \n",
       "25%                          0.000000                     0.000000   \n",
       "50%                          0.000000                     0.000000   \n",
       "75%                          0.000000                     1.000000   \n",
       "max                          1.000000                     1.000000   \n",
       "\n",
       "       smoking_status_smokes  \n",
       "count            4981.000000  \n",
       "mean                0.155792  \n",
       "std                 0.362694  \n",
       "min                 0.000000  \n",
       "25%                 0.000000  \n",
       "50%                 0.000000  \n",
       "75%                 0.000000  \n",
       "max                 1.000000  "
      ]
     },
     "execution_count": 268,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                            0\n",
       "age                               0\n",
       "hypertension                      0\n",
       "heart_disease                     0\n",
       "ever_married                      0\n",
       "Residence_type                    0\n",
       "avg_glucose_level                 0\n",
       "bmi                               0\n",
       "stroke                            0\n",
       "work_type_Govt_job                0\n",
       "work_type_Private                 0\n",
       "work_type_Self-employed           0\n",
       "work_type_children                0\n",
       "smoking_status_Unknown            0\n",
       "smoking_status_formerly smoked    0\n",
       "smoking_status_never smoked       0\n",
       "smoking_status_smokes             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dropna(axis = 0, inplace = True)\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>228.69</td>\n",
       "      <td>36.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>105.92</td>\n",
       "      <td>32.5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171.23</td>\n",
       "      <td>34.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>174.12</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>186.21</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender   age  hypertension  heart_disease  ever_married  Residence_type  \\\n",
       "0       1  67.0             0              1             0               0   \n",
       "1       1  80.0             0              1             0               1   \n",
       "2       0  49.0             0              0             0               0   \n",
       "3       0  79.0             1              0             0               1   \n",
       "4       1  81.0             0              0             0               0   \n",
       "\n",
       "   avg_glucose_level   bmi  stroke  work_type_Govt_job  work_type_Private  \\\n",
       "0             228.69  36.6       1                   0                  1   \n",
       "1             105.92  32.5       1                   0                  1   \n",
       "2             171.23  34.4       1                   0                  1   \n",
       "3             174.12  24.0       1                   0                  0   \n",
       "4             186.21  29.0       1                   0                  1   \n",
       "\n",
       "   work_type_Self-employed  work_type_children  smoking_status_Unknown  \\\n",
       "0                        0                   0                       0   \n",
       "1                        0                   0                       0   \n",
       "2                        0                   0                       0   \n",
       "3                        1                   0                       0   \n",
       "4                        0                   0                       0   \n",
       "\n",
       "   smoking_status_formerly smoked  smoking_status_never smoked  \\\n",
       "0                               1                            0   \n",
       "1                               0                            1   \n",
       "2                               0                            0   \n",
       "3                               0                            1   \n",
       "4                               1                            0   \n",
       "\n",
       "   smoking_status_smokes  \n",
       "0                      0  \n",
       "1                      0  \n",
       "2                      1  \n",
       "3                      0  \n",
       "4                      0  "
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['gender']= data['gender'].map({'Male':1,'Female':0})\n",
    "#data['work_type'], mapping = pd.factorize(data['work_type'])\n",
    "data['ever_married'], mapping = pd.factorize(data['ever_married'])\n",
    "#data['smoking_status'], mapping = pd.factorize(data['smoking_status'])\n",
    "data['Residence_type'], mapping = pd.factorize(data['Residence_type'])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gender                              int64\n",
       "age                               float64\n",
       "hypertension                        int64\n",
       "heart_disease                       int64\n",
       "ever_married                        int64\n",
       "Residence_type                      int64\n",
       "avg_glucose_level                 float64\n",
       "bmi                               float64\n",
       "stroke                              int64\n",
       "work_type_Govt_job                  uint8\n",
       "work_type_Private                   uint8\n",
       "work_type_Self-employed             uint8\n",
       "work_type_children                  uint8\n",
       "smoking_status_Unknown              uint8\n",
       "smoking_status_formerly smoked      uint8\n",
       "smoking_status_never smoked         uint8\n",
       "smoking_status_smokes               uint8\n",
       "dtype: object"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>hypertension</th>\n",
       "      <th>heart_disease</th>\n",
       "      <th>ever_married</th>\n",
       "      <th>Residence_type</th>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <th>bmi</th>\n",
       "      <th>stroke</th>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <th>work_type_Private</th>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <th>work_type_children</th>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <th>smoking_status_smokes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.026538</td>\n",
       "      <td>0.021485</td>\n",
       "      <td>0.086476</td>\n",
       "      <td>0.028971</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.055796</td>\n",
       "      <td>-0.012093</td>\n",
       "      <td>0.008870</td>\n",
       "      <td>-0.017176</td>\n",
       "      <td>-0.028706</td>\n",
       "      <td>-0.029635</td>\n",
       "      <td>0.090275</td>\n",
       "      <td>0.059858</td>\n",
       "      <td>0.045109</td>\n",
       "      <td>-0.102387</td>\n",
       "      <td>0.013349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.026538</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.278120</td>\n",
       "      <td>0.264852</td>\n",
       "      <td>-0.677137</td>\n",
       "      <td>-0.017155</td>\n",
       "      <td>0.236763</td>\n",
       "      <td>0.373703</td>\n",
       "      <td>0.246478</td>\n",
       "      <td>0.126868</td>\n",
       "      <td>0.111020</td>\n",
       "      <td>0.326835</td>\n",
       "      <td>-0.636866</td>\n",
       "      <td>-0.379669</td>\n",
       "      <td>0.235508</td>\n",
       "      <td>0.122617</td>\n",
       "      <td>0.070899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hypertension</th>\n",
       "      <td>0.021485</td>\n",
       "      <td>0.278120</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>-0.164534</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.170028</td>\n",
       "      <td>0.158762</td>\n",
       "      <td>0.131965</td>\n",
       "      <td>0.016378</td>\n",
       "      <td>-0.004177</td>\n",
       "      <td>0.110468</td>\n",
       "      <td>-0.128924</td>\n",
       "      <td>-0.139901</td>\n",
       "      <td>0.056797</td>\n",
       "      <td>0.065267</td>\n",
       "      <td>0.030749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>heart_disease</th>\n",
       "      <td>0.086476</td>\n",
       "      <td>0.264852</td>\n",
       "      <td>0.111974</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.114765</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.166847</td>\n",
       "      <td>0.060926</td>\n",
       "      <td>0.134610</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>0.087474</td>\n",
       "      <td>-0.092974</td>\n",
       "      <td>-0.066710</td>\n",
       "      <td>0.067541</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>0.044011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ever_married</th>\n",
       "      <td>0.028971</td>\n",
       "      <td>-0.677137</td>\n",
       "      <td>-0.164534</td>\n",
       "      <td>-0.114765</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>-0.150724</td>\n",
       "      <td>-0.371690</td>\n",
       "      <td>-0.108398</td>\n",
       "      <td>-0.133655</td>\n",
       "      <td>-0.146139</td>\n",
       "      <td>-0.191668</td>\n",
       "      <td>0.548851</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>-0.172039</td>\n",
       "      <td>-0.104120</td>\n",
       "      <td>-0.106234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Residence_type</th>\n",
       "      <td>0.004301</td>\n",
       "      <td>-0.017155</td>\n",
       "      <td>0.004755</td>\n",
       "      <td>-0.002125</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>-0.013185</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>-0.013925</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>-0.013427</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>-0.009825</td>\n",
       "      <td>0.026892</td>\n",
       "      <td>-0.030490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_glucose_level</th>\n",
       "      <td>0.055796</td>\n",
       "      <td>0.236763</td>\n",
       "      <td>0.170028</td>\n",
       "      <td>0.166847</td>\n",
       "      <td>-0.150724</td>\n",
       "      <td>-0.001346</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.186348</td>\n",
       "      <td>0.133227</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>0.020764</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>-0.101960</td>\n",
       "      <td>-0.095504</td>\n",
       "      <td>0.066989</td>\n",
       "      <td>0.024727</td>\n",
       "      <td>0.017873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>-0.012093</td>\n",
       "      <td>0.373703</td>\n",
       "      <td>0.158762</td>\n",
       "      <td>0.060926</td>\n",
       "      <td>-0.371690</td>\n",
       "      <td>-0.013185</td>\n",
       "      <td>0.186348</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.056926</td>\n",
       "      <td>0.087375</td>\n",
       "      <td>0.211820</td>\n",
       "      <td>0.085582</td>\n",
       "      <td>-0.484257</td>\n",
       "      <td>-0.293912</td>\n",
       "      <td>0.120156</td>\n",
       "      <td>0.109322</td>\n",
       "      <td>0.100710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stroke</th>\n",
       "      <td>0.008870</td>\n",
       "      <td>0.246478</td>\n",
       "      <td>0.131965</td>\n",
       "      <td>0.134610</td>\n",
       "      <td>-0.108398</td>\n",
       "      <td>-0.016494</td>\n",
       "      <td>0.133227</td>\n",
       "      <td>0.056926</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>0.062643</td>\n",
       "      <td>-0.085075</td>\n",
       "      <td>-0.055699</td>\n",
       "      <td>0.065320</td>\n",
       "      <td>-0.004806</td>\n",
       "      <td>0.008561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_type_Govt_job</th>\n",
       "      <td>-0.017176</td>\n",
       "      <td>0.126868</td>\n",
       "      <td>0.016378</td>\n",
       "      <td>0.001166</td>\n",
       "      <td>-0.133655</td>\n",
       "      <td>-0.013925</td>\n",
       "      <td>0.009223</td>\n",
       "      <td>0.087375</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.447467</td>\n",
       "      <td>-0.169061</td>\n",
       "      <td>-0.152306</td>\n",
       "      <td>-0.096437</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.045091</td>\n",
       "      <td>0.030804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_type_Private</th>\n",
       "      <td>-0.028706</td>\n",
       "      <td>0.111020</td>\n",
       "      <td>-0.004177</td>\n",
       "      <td>-0.001600</td>\n",
       "      <td>-0.146139</td>\n",
       "      <td>0.016104</td>\n",
       "      <td>0.020764</td>\n",
       "      <td>0.211820</td>\n",
       "      <td>0.010459</td>\n",
       "      <td>-0.447467</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.509458</td>\n",
       "      <td>-0.458968</td>\n",
       "      <td>-0.210882</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.109936</td>\n",
       "      <td>0.096769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_type_Self-employed</th>\n",
       "      <td>-0.029635</td>\n",
       "      <td>0.326835</td>\n",
       "      <td>0.110468</td>\n",
       "      <td>0.087474</td>\n",
       "      <td>-0.191668</td>\n",
       "      <td>-0.013427</td>\n",
       "      <td>0.058419</td>\n",
       "      <td>0.085582</td>\n",
       "      <td>0.062643</td>\n",
       "      <td>-0.169061</td>\n",
       "      <td>-0.509458</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.173407</td>\n",
       "      <td>-0.106007</td>\n",
       "      <td>0.092186</td>\n",
       "      <td>0.030898</td>\n",
       "      <td>-0.003396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>work_type_children</th>\n",
       "      <td>0.090275</td>\n",
       "      <td>-0.636866</td>\n",
       "      <td>-0.128924</td>\n",
       "      <td>-0.092974</td>\n",
       "      <td>0.548851</td>\n",
       "      <td>0.004825</td>\n",
       "      <td>-0.101960</td>\n",
       "      <td>-0.484257</td>\n",
       "      <td>-0.085075</td>\n",
       "      <td>-0.152306</td>\n",
       "      <td>-0.458968</td>\n",
       "      <td>-0.173407</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.513777</td>\n",
       "      <td>-0.161310</td>\n",
       "      <td>-0.236529</td>\n",
       "      <td>-0.166553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status_Unknown</th>\n",
       "      <td>0.059858</td>\n",
       "      <td>-0.379669</td>\n",
       "      <td>-0.139901</td>\n",
       "      <td>-0.066710</td>\n",
       "      <td>0.335689</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>-0.095504</td>\n",
       "      <td>-0.293912</td>\n",
       "      <td>-0.055699</td>\n",
       "      <td>-0.096437</td>\n",
       "      <td>-0.210882</td>\n",
       "      <td>-0.106007</td>\n",
       "      <td>0.513777</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.301350</td>\n",
       "      <td>-0.501989</td>\n",
       "      <td>-0.281995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status_formerly smoked</th>\n",
       "      <td>0.045109</td>\n",
       "      <td>0.235508</td>\n",
       "      <td>0.056797</td>\n",
       "      <td>0.067541</td>\n",
       "      <td>-0.172039</td>\n",
       "      <td>-0.009825</td>\n",
       "      <td>0.066989</td>\n",
       "      <td>0.120156</td>\n",
       "      <td>0.065320</td>\n",
       "      <td>0.029833</td>\n",
       "      <td>0.022685</td>\n",
       "      <td>0.092186</td>\n",
       "      <td>-0.161310</td>\n",
       "      <td>-0.301350</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.351057</td>\n",
       "      <td>-0.197208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status_never smoked</th>\n",
       "      <td>-0.102387</td>\n",
       "      <td>0.122617</td>\n",
       "      <td>0.065267</td>\n",
       "      <td>-0.022727</td>\n",
       "      <td>-0.104120</td>\n",
       "      <td>0.026892</td>\n",
       "      <td>0.024727</td>\n",
       "      <td>0.109322</td>\n",
       "      <td>-0.004806</td>\n",
       "      <td>0.045091</td>\n",
       "      <td>0.109936</td>\n",
       "      <td>0.030898</td>\n",
       "      <td>-0.236529</td>\n",
       "      <td>-0.501989</td>\n",
       "      <td>-0.351057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.328510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>smoking_status_smokes</th>\n",
       "      <td>0.013349</td>\n",
       "      <td>0.070899</td>\n",
       "      <td>0.030749</td>\n",
       "      <td>0.044011</td>\n",
       "      <td>-0.106234</td>\n",
       "      <td>-0.030490</td>\n",
       "      <td>0.017873</td>\n",
       "      <td>0.100710</td>\n",
       "      <td>0.008561</td>\n",
       "      <td>0.030804</td>\n",
       "      <td>0.096769</td>\n",
       "      <td>-0.003396</td>\n",
       "      <td>-0.166553</td>\n",
       "      <td>-0.281995</td>\n",
       "      <td>-0.197208</td>\n",
       "      <td>-0.328510</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  gender       age  hypertension  \\\n",
       "gender                          1.000000 -0.026538      0.021485   \n",
       "age                            -0.026538  1.000000      0.278120   \n",
       "hypertension                    0.021485  0.278120      1.000000   \n",
       "heart_disease                   0.086476  0.264852      0.111974   \n",
       "ever_married                    0.028971 -0.677137     -0.164534   \n",
       "Residence_type                  0.004301 -0.017155      0.004755   \n",
       "avg_glucose_level               0.055796  0.236763      0.170028   \n",
       "bmi                            -0.012093  0.373703      0.158762   \n",
       "stroke                          0.008870  0.246478      0.131965   \n",
       "work_type_Govt_job             -0.017176  0.126868      0.016378   \n",
       "work_type_Private              -0.028706  0.111020     -0.004177   \n",
       "work_type_Self-employed        -0.029635  0.326835      0.110468   \n",
       "work_type_children              0.090275 -0.636866     -0.128924   \n",
       "smoking_status_Unknown          0.059858 -0.379669     -0.139901   \n",
       "smoking_status_formerly smoked  0.045109  0.235508      0.056797   \n",
       "smoking_status_never smoked    -0.102387  0.122617      0.065267   \n",
       "smoking_status_smokes           0.013349  0.070899      0.030749   \n",
       "\n",
       "                                heart_disease  ever_married  Residence_type  \\\n",
       "gender                               0.086476      0.028971        0.004301   \n",
       "age                                  0.264852     -0.677137       -0.017155   \n",
       "hypertension                         0.111974     -0.164534        0.004755   \n",
       "heart_disease                        1.000000     -0.114765       -0.002125   \n",
       "ever_married                        -0.114765      1.000000        0.008191   \n",
       "Residence_type                      -0.002125      0.008191        1.000000   \n",
       "avg_glucose_level                    0.166847     -0.150724       -0.001346   \n",
       "bmi                                  0.060926     -0.371690       -0.013185   \n",
       "stroke                               0.134610     -0.108398       -0.016494   \n",
       "work_type_Govt_job                   0.001166     -0.133655       -0.013925   \n",
       "work_type_Private                   -0.001600     -0.146139        0.016104   \n",
       "work_type_Self-employed              0.087474     -0.191668       -0.013427   \n",
       "work_type_children                  -0.092974      0.548851        0.004825   \n",
       "smoking_status_Unknown              -0.066710      0.335689        0.003937   \n",
       "smoking_status_formerly smoked       0.067541     -0.172039       -0.009825   \n",
       "smoking_status_never smoked         -0.022727     -0.104120        0.026892   \n",
       "smoking_status_smokes                0.044011     -0.106234       -0.030490   \n",
       "\n",
       "                                avg_glucose_level       bmi    stroke  \\\n",
       "gender                                   0.055796 -0.012093  0.008870   \n",
       "age                                      0.236763  0.373703  0.246478   \n",
       "hypertension                             0.170028  0.158762  0.131965   \n",
       "heart_disease                            0.166847  0.060926  0.134610   \n",
       "ever_married                            -0.150724 -0.371690 -0.108398   \n",
       "Residence_type                          -0.001346 -0.013185 -0.016494   \n",
       "avg_glucose_level                        1.000000  0.186348  0.133227   \n",
       "bmi                                      0.186348  1.000000  0.056926   \n",
       "stroke                                   0.133227  0.056926  1.000000   \n",
       "work_type_Govt_job                       0.009223  0.087375  0.002574   \n",
       "work_type_Private                        0.020764  0.211820  0.010459   \n",
       "work_type_Self-employed                  0.058419  0.085582  0.062643   \n",
       "work_type_children                      -0.101960 -0.484257 -0.085075   \n",
       "smoking_status_Unknown                  -0.095504 -0.293912 -0.055699   \n",
       "smoking_status_formerly smoked           0.066989  0.120156  0.065320   \n",
       "smoking_status_never smoked              0.024727  0.109322 -0.004806   \n",
       "smoking_status_smokes                    0.017873  0.100710  0.008561   \n",
       "\n",
       "                                work_type_Govt_job  work_type_Private  \\\n",
       "gender                                   -0.017176          -0.028706   \n",
       "age                                       0.126868           0.111020   \n",
       "hypertension                              0.016378          -0.004177   \n",
       "heart_disease                             0.001166          -0.001600   \n",
       "ever_married                             -0.133655          -0.146139   \n",
       "Residence_type                           -0.013925           0.016104   \n",
       "avg_glucose_level                         0.009223           0.020764   \n",
       "bmi                                       0.087375           0.211820   \n",
       "stroke                                    0.002574           0.010459   \n",
       "work_type_Govt_job                        1.000000          -0.447467   \n",
       "work_type_Private                        -0.447467           1.000000   \n",
       "work_type_Self-employed                  -0.169061          -0.509458   \n",
       "work_type_children                       -0.152306          -0.458968   \n",
       "smoking_status_Unknown                   -0.096437          -0.210882   \n",
       "smoking_status_formerly smoked            0.029833           0.022685   \n",
       "smoking_status_never smoked               0.045091           0.109936   \n",
       "smoking_status_smokes                     0.030804           0.096769   \n",
       "\n",
       "                                work_type_Self-employed  work_type_children  \\\n",
       "gender                                        -0.029635            0.090275   \n",
       "age                                            0.326835           -0.636866   \n",
       "hypertension                                   0.110468           -0.128924   \n",
       "heart_disease                                  0.087474           -0.092974   \n",
       "ever_married                                  -0.191668            0.548851   \n",
       "Residence_type                                -0.013427            0.004825   \n",
       "avg_glucose_level                              0.058419           -0.101960   \n",
       "bmi                                            0.085582           -0.484257   \n",
       "stroke                                         0.062643           -0.085075   \n",
       "work_type_Govt_job                            -0.169061           -0.152306   \n",
       "work_type_Private                             -0.509458           -0.458968   \n",
       "work_type_Self-employed                        1.000000           -0.173407   \n",
       "work_type_children                            -0.173407            1.000000   \n",
       "smoking_status_Unknown                        -0.106007            0.513777   \n",
       "smoking_status_formerly smoked                 0.092186           -0.161310   \n",
       "smoking_status_never smoked                    0.030898           -0.236529   \n",
       "smoking_status_smokes                         -0.003396           -0.166553   \n",
       "\n",
       "                                smoking_status_Unknown  \\\n",
       "gender                                        0.059858   \n",
       "age                                          -0.379669   \n",
       "hypertension                                 -0.139901   \n",
       "heart_disease                                -0.066710   \n",
       "ever_married                                  0.335689   \n",
       "Residence_type                                0.003937   \n",
       "avg_glucose_level                            -0.095504   \n",
       "bmi                                          -0.293912   \n",
       "stroke                                       -0.055699   \n",
       "work_type_Govt_job                           -0.096437   \n",
       "work_type_Private                            -0.210882   \n",
       "work_type_Self-employed                      -0.106007   \n",
       "work_type_children                            0.513777   \n",
       "smoking_status_Unknown                        1.000000   \n",
       "smoking_status_formerly smoked               -0.301350   \n",
       "smoking_status_never smoked                  -0.501989   \n",
       "smoking_status_smokes                        -0.281995   \n",
       "\n",
       "                                smoking_status_formerly smoked  \\\n",
       "gender                                                0.045109   \n",
       "age                                                   0.235508   \n",
       "hypertension                                          0.056797   \n",
       "heart_disease                                         0.067541   \n",
       "ever_married                                         -0.172039   \n",
       "Residence_type                                       -0.009825   \n",
       "avg_glucose_level                                     0.066989   \n",
       "bmi                                                   0.120156   \n",
       "stroke                                                0.065320   \n",
       "work_type_Govt_job                                    0.029833   \n",
       "work_type_Private                                     0.022685   \n",
       "work_type_Self-employed                               0.092186   \n",
       "work_type_children                                   -0.161310   \n",
       "smoking_status_Unknown                               -0.301350   \n",
       "smoking_status_formerly smoked                        1.000000   \n",
       "smoking_status_never smoked                          -0.351057   \n",
       "smoking_status_smokes                                -0.197208   \n",
       "\n",
       "                                smoking_status_never smoked  \\\n",
       "gender                                            -0.102387   \n",
       "age                                                0.122617   \n",
       "hypertension                                       0.065267   \n",
       "heart_disease                                     -0.022727   \n",
       "ever_married                                      -0.104120   \n",
       "Residence_type                                     0.026892   \n",
       "avg_glucose_level                                  0.024727   \n",
       "bmi                                                0.109322   \n",
       "stroke                                            -0.004806   \n",
       "work_type_Govt_job                                 0.045091   \n",
       "work_type_Private                                  0.109936   \n",
       "work_type_Self-employed                            0.030898   \n",
       "work_type_children                                -0.236529   \n",
       "smoking_status_Unknown                            -0.501989   \n",
       "smoking_status_formerly smoked                    -0.351057   \n",
       "smoking_status_never smoked                        1.000000   \n",
       "smoking_status_smokes                             -0.328510   \n",
       "\n",
       "                                smoking_status_smokes  \n",
       "gender                                       0.013349  \n",
       "age                                          0.070899  \n",
       "hypertension                                 0.030749  \n",
       "heart_disease                                0.044011  \n",
       "ever_married                                -0.106234  \n",
       "Residence_type                              -0.030490  \n",
       "avg_glucose_level                            0.017873  \n",
       "bmi                                          0.100710  \n",
       "stroke                                       0.008561  \n",
       "work_type_Govt_job                           0.030804  \n",
       "work_type_Private                            0.096769  \n",
       "work_type_Self-employed                     -0.003396  \n",
       "work_type_children                          -0.166553  \n",
       "smoking_status_Unknown                      -0.281995  \n",
       "smoking_status_formerly smoked              -0.197208  \n",
       "smoking_status_never smoked                 -0.328510  \n",
       "smoking_status_smokes                        1.000000  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### III. Chuẩn bị dữ liệu cho học máy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4981 16\n"
     ]
    }
   ],
   "source": [
    "X = data.drop('stroke', axis=1)\n",
    "y= data.stroke.values\n",
    "num_samples, num_features=X.shape\n",
    "print(num_samples, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\imblearn\\over_sampling\\_smote\\filter.py:461: FutureWarning: The parameter `n_jobs` has been deprecated in 0.10 and will be removed in 0.12. You can pass an nearest neighbors estimator where `n_jobs` is already set instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "sm = SVMSMOTE(k_neighbors=4, m_neighbors=10, svm_estimator=None, n_jobs=-1, random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2172\n",
      "3790\n"
     ]
    }
   ],
   "source": [
    "print((y_train==1).sum())\n",
    "print((y_train==0).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(X_train)\n",
    "X_test=sc.transform(X_test)\n",
    "\n",
    "X_train=torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test=torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train=torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test=torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train=y_train.view(y_train.shape[0],1)\n",
    "y_test=y_test.view(y_test.shape[0],1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IV. Xây dựng và đào tạo mô hình"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Hàm đánh giá mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateModel(y_test,YResult):\n",
    "    y_test = y_test.cpu().numpy()\n",
    "    from sklearn.metrics import f1_score, recall_score, precision_score, roc_auc_score\n",
    "    f1 = f1_score(y_test, YResult)\n",
    "    recall = recall_score(y_test, YResult)\n",
    "    precision = precision_score(y_test, YResult)\n",
    "    auc = roc_auc_score(y_test, YResult)\n",
    "    print(f\"auc_score = {auc}\")\n",
    "    print(f\"F1_score = {f1}\")\n",
    "    print(f\"Recall = {recall}\")\n",
    "    print(f\"Precision = {precision}\")\n",
    "    ReSult = {'roc_auc_score' : auc,'F1_score':f1,'Recall': recall,'Precision':precision}\n",
    "    return ReSult "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Mô hình Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, Loss: 0.6639\n",
      "Epoch: 20, Loss: 0.6336\n",
      "Epoch: 30, Loss: 0.6070\n",
      "Epoch: 40, Loss: 0.5835\n",
      "Epoch: 50, Loss: 0.5626\n",
      "Epoch: 60, Loss: 0.5438\n",
      "Epoch: 70, Loss: 0.5269\n",
      "Epoch: 80, Loss: 0.5115\n",
      "Epoch: 90, Loss: 0.4975\n",
      "Epoch: 100, Loss: 0.4847\n",
      "Epoch: 110, Loss: 0.4729\n",
      "Epoch: 120, Loss: 0.4620\n",
      "Epoch: 130, Loss: 0.4519\n",
      "Epoch: 140, Loss: 0.4425\n",
      "Epoch: 150, Loss: 0.4338\n",
      "auc_score = 0.5488483783026319\n",
      "F1_score = 0.20800000000000002\n",
      "Recall = 0.1326530612244898\n",
      "Precision = 0.48148148148148145\n",
      "Epoch: 10, Loss: 0.6664\n",
      "Epoch: 20, Loss: 0.6065\n",
      "Epoch: 30, Loss: 0.5610\n",
      "Epoch: 40, Loss: 0.5259\n",
      "Epoch: 50, Loss: 0.4980\n",
      "Epoch: 60, Loss: 0.4752\n",
      "Epoch: 70, Loss: 0.4563\n",
      "Epoch: 80, Loss: 0.4401\n",
      "Epoch: 90, Loss: 0.4260\n",
      "Epoch: 100, Loss: 0.4137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 110, Loss: 0.4026\n",
      "Epoch: 120, Loss: 0.3927\n",
      "Epoch: 130, Loss: 0.3838\n",
      "auc_score = 0.5787981651376147\n",
      "F1_score = 0.26815642458100564\n",
      "Recall = 0.192\n",
      "Precision = 0.4444444444444444\n",
      "Epoch: 10, Loss: 0.5431\n",
      "Epoch: 20, Loss: 0.4841\n",
      "Epoch: 30, Loss: 0.4406\n",
      "Epoch: 40, Loss: 0.4075\n",
      "Epoch: 50, Loss: 0.3817\n",
      "Epoch: 60, Loss: 0.3610\n",
      "Epoch: 70, Loss: 0.3440\n",
      "Epoch: 80, Loss: 0.3299\n",
      "Epoch: 90, Loss: 0.3180\n",
      "Epoch: 100, Loss: 0.3079\n",
      "Epoch: 110, Loss: 0.2991\n",
      "Epoch: 120, Loss: 0.2913\n",
      "Epoch: 130, Loss: 0.2845\n",
      "Epoch: 140, Loss: 0.2785\n",
      "Epoch: 150, Loss: 0.2731\n",
      "Epoch: 160, Loss: 0.2682\n",
      "auc_score = 0.5902372296279975\n",
      "F1_score = 0.23214285714285715\n",
      "Recall = 0.22413793103448276\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.6485\n",
      "Epoch: 20, Loss: 0.5903\n",
      "Epoch: 30, Loss: 0.5463\n",
      "Epoch: 40, Loss: 0.5124\n",
      "Epoch: 50, Loss: 0.4854\n",
      "auc_score = 0.5503232533889469\n",
      "F1_score = 0.20960698689956334\n",
      "Recall = 0.13714285714285715\n",
      "Precision = 0.4444444444444444\n",
      "Epoch: 10, Loss: 0.5794\n",
      "Epoch: 20, Loss: 0.5381\n",
      "Epoch: 30, Loss: 0.5050\n",
      "Epoch: 40, Loss: 0.4777\n",
      "Epoch: 50, Loss: 0.4548\n",
      "Epoch: 60, Loss: 0.4352\n",
      "Epoch: 70, Loss: 0.4182\n",
      "Epoch: 80, Loss: 0.4034\n",
      "Epoch: 90, Loss: 0.3902\n",
      "Epoch: 100, Loss: 0.3785\n",
      "Epoch: 110, Loss: 0.3680\n",
      "auc_score = 0.5555120439988861\n",
      "F1_score = 0.21390374331550802\n",
      "Recall = 0.15037593984962405\n",
      "Precision = 0.37037037037037035\n",
      "Epoch: 10, Loss: 0.6982\n",
      "Epoch: 20, Loss: 0.6757\n",
      "Epoch: 30, Loss: 0.6552\n",
      "Epoch: 40, Loss: 0.6364\n",
      "Epoch: 50, Loss: 0.6190\n",
      "auc_score = 0.4952275249722531\n",
      "F1_score = 0.07766990291262135\n",
      "Recall = 0.047058823529411764\n",
      "Precision = 0.2222222222222222\n",
      "Epoch: 10, Loss: 0.5454\n",
      "Epoch: 20, Loss: 0.4849\n",
      "Epoch: 30, Loss: 0.4425\n",
      "Epoch: 40, Loss: 0.4109\n",
      "Epoch: 50, Loss: 0.3865\n",
      "Epoch: 60, Loss: 0.3669\n",
      "Epoch: 70, Loss: 0.3508\n",
      "Epoch: 80, Loss: 0.3374\n",
      "Epoch: 90, Loss: 0.3260\n",
      "Epoch: 100, Loss: 0.3161\n",
      "Epoch: 110, Loss: 0.3075\n",
      "auc_score = 0.581412651174571\n",
      "F1_score = 0.22950819672131148\n",
      "Recall = 0.20588235294117646\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.6711\n",
      "Epoch: 20, Loss: 0.5935\n",
      "Epoch: 30, Loss: 0.5382\n",
      "Epoch: 40, Loss: 0.4969\n",
      "Epoch: 50, Loss: 0.4646\n",
      "auc_score = 0.5220270084056773\n",
      "F1_score = 0.13852813852813853\n",
      "Recall = 0.0903954802259887\n",
      "Precision = 0.2962962962962963\n",
      "Epoch: 10, Loss: 0.8423\n",
      "Epoch: 20, Loss: 0.8283\n",
      "Epoch: 30, Loss: 0.8148\n",
      "Epoch: 40, Loss: 0.8018\n",
      "Epoch: 50, Loss: 0.7894\n",
      "Epoch: 60, Loss: 0.7774\n",
      "auc_score = 0.48912499192349934\n",
      "F1_score = 0.07648183556405354\n",
      "Recall = 0.042643923240938165\n",
      "Precision = 0.37037037037037035\n",
      "Epoch: 10, Loss: 0.6934\n",
      "Epoch: 20, Loss: 0.6280\n",
      "Epoch: 30, Loss: 0.5782\n",
      "Epoch: 40, Loss: 0.5390\n",
      "Epoch: 50, Loss: 0.5072\n",
      "Epoch: 60, Loss: 0.4808\n",
      "Epoch: 70, Loss: 0.4585\n",
      "Epoch: 80, Loss: 0.4394\n",
      "Epoch: 90, Loss: 0.4227\n",
      "Epoch: 100, Loss: 0.4081\n",
      "Epoch: 110, Loss: 0.3951\n",
      "Epoch: 120, Loss: 0.3836\n",
      "Epoch: 130, Loss: 0.3732\n",
      "Epoch: 140, Loss: 0.3638\n",
      "Epoch: 150, Loss: 0.3553\n",
      "Epoch: 160, Loss: 0.3475\n",
      "Epoch: 170, Loss: 0.3403\n",
      "Epoch: 180, Loss: 0.3337\n",
      "Epoch: 190, Loss: 0.3277\n",
      "auc_score = 0.5626629422718809\n",
      "F1_score = 0.21794871794871792\n",
      "Recall = 0.16666666666666666\n",
      "Precision = 0.3148148148148148\n",
      "Epoch: 10, Loss: 0.6953\n",
      "Epoch: 20, Loss: 0.6210\n",
      "Epoch: 30, Loss: 0.5667\n",
      "Epoch: 40, Loss: 0.5254\n",
      "Epoch: 50, Loss: 0.4928\n",
      "Epoch: 60, Loss: 0.4664\n",
      "Epoch: 70, Loss: 0.4444\n",
      "Epoch: 80, Loss: 0.4257\n",
      "Epoch: 90, Loss: 0.4097\n",
      "Epoch: 100, Loss: 0.3957\n",
      "Epoch: 110, Loss: 0.3834\n",
      "Epoch: 120, Loss: 0.3725\n",
      "Epoch: 130, Loss: 0.3627\n",
      "Epoch: 140, Loss: 0.3538\n",
      "Epoch: 150, Loss: 0.3458\n",
      "Epoch: 160, Loss: 0.3385\n",
      "Epoch: 170, Loss: 0.3318\n",
      "auc_score = 0.5621329757199321\n",
      "F1_score = 0.1984732824427481\n",
      "Recall = 0.16883116883116883\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.6244\n",
      "Epoch: 20, Loss: 0.5567\n",
      "Epoch: 30, Loss: 0.5072\n",
      "Epoch: 40, Loss: 0.4695\n",
      "Epoch: 50, Loss: 0.4399\n",
      "Epoch: 60, Loss: 0.4160\n",
      "Epoch: 70, Loss: 0.3962\n",
      "Epoch: 80, Loss: 0.3796\n",
      "Epoch: 90, Loss: 0.3654\n",
      "auc_score = 0.549303247507308\n",
      "F1_score = 0.19161676646706588\n",
      "Recall = 0.1415929203539823\n",
      "Precision = 0.2962962962962963\n",
      "Epoch: 10, Loss: 0.6171\n",
      "Epoch: 20, Loss: 0.5214\n",
      "Epoch: 30, Loss: 0.4625\n",
      "Epoch: 40, Loss: 0.4219\n",
      "Epoch: 50, Loss: 0.3918\n",
      "Epoch: 60, Loss: 0.3685\n",
      "Epoch: 70, Loss: 0.3498\n",
      "Epoch: 80, Loss: 0.3344\n",
      "auc_score = 0.5464468320727598\n",
      "F1_score = 0.17567567567567569\n",
      "Recall = 0.13829787234042554\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.6457\n",
      "Epoch: 20, Loss: 0.6185\n",
      "Epoch: 30, Loss: 0.5941\n",
      "Epoch: 40, Loss: 0.5721\n",
      "Epoch: 50, Loss: 0.5521\n",
      "Epoch: 60, Loss: 0.5339\n",
      "Epoch: 70, Loss: 0.5173\n",
      "Epoch: 80, Loss: 0.5021\n",
      "auc_score = 0.545379149152734\n",
      "F1_score = 0.19889502762430938\n",
      "Recall = 0.11688311688311688\n",
      "Precision = 0.6666666666666666\n",
      "Epoch: 10, Loss: 0.5657\n",
      "Epoch: 20, Loss: 0.4801\n",
      "Epoch: 30, Loss: 0.4254\n",
      "Epoch: 40, Loss: 0.3876\n",
      "Epoch: 50, Loss: 0.3600\n",
      "auc_score = 0.5773714790956171\n",
      "F1_score = 0.24113475177304966\n",
      "Recall = 0.19540229885057472\n",
      "Precision = 0.3148148148148148\n",
      "Epoch: 10, Loss: 0.6406\n",
      "Epoch: 20, Loss: 0.6168\n",
      "Epoch: 30, Loss: 0.5954\n",
      "Epoch: 40, Loss: 0.5762\n",
      "Epoch: 50, Loss: 0.5588\n",
      "Epoch: 60, Loss: 0.5429\n",
      "Epoch: 70, Loss: 0.5283\n",
      "Epoch: 80, Loss: 0.5149\n",
      "Epoch: 90, Loss: 0.5024\n",
      "Epoch: 100, Loss: 0.4909\n",
      "Epoch: 110, Loss: 0.4802\n",
      "auc_score = 0.5256767087299195\n",
      "F1_score = 0.152317880794702\n",
      "Recall = 0.09274193548387097\n",
      "Precision = 0.42592592592592593\n",
      "Epoch: 10, Loss: 0.6345\n",
      "Epoch: 20, Loss: 0.5260\n",
      "Epoch: 30, Loss: 0.4610\n",
      "Epoch: 40, Loss: 0.4169\n",
      "Epoch: 50, Loss: 0.3848\n",
      "Epoch: 60, Loss: 0.3604\n",
      "Epoch: 70, Loss: 0.3411\n",
      "Epoch: 80, Loss: 0.3255\n",
      "Epoch: 90, Loss: 0.3126\n",
      "auc_score = 0.5656276536558227\n",
      "F1_score = 0.203125\n",
      "Recall = 0.17567567567567569\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.5416\n",
      "Epoch: 20, Loss: 0.4739\n",
      "Epoch: 30, Loss: 0.4277\n",
      "Epoch: 40, Loss: 0.3942\n",
      "Epoch: 50, Loss: 0.3688\n",
      "Epoch: 60, Loss: 0.3488\n",
      "Epoch: 70, Loss: 0.3326\n",
      "Epoch: 80, Loss: 0.3193\n",
      "Epoch: 90, Loss: 0.3080\n",
      "Epoch: 100, Loss: 0.2984\n",
      "Epoch: 110, Loss: 0.2901\n",
      "Epoch: 120, Loss: 0.2828\n",
      "Epoch: 130, Loss: 0.2764\n",
      "Epoch: 140, Loss: 0.2707\n",
      "auc_score = 0.5810840586096728\n",
      "F1_score = 0.2142857142857143\n",
      "Recall = 0.20689655172413793\n",
      "Precision = 0.2222222222222222\n",
      "Epoch: 10, Loss: 0.6333\n",
      "Epoch: 20, Loss: 0.5310\n",
      "Epoch: 30, Loss: 0.4665\n",
      "Epoch: 40, Loss: 0.4217\n",
      "Epoch: 50, Loss: 0.3886\n",
      "Epoch: 60, Loss: 0.3632\n",
      "Epoch: 70, Loss: 0.3430\n",
      "Epoch: 80, Loss: 0.3266\n",
      "Epoch: 90, Loss: 0.3130\n",
      "Epoch: 100, Loss: 0.3016\n",
      "Epoch: 110, Loss: 0.2918\n",
      "Epoch: 120, Loss: 0.2834\n",
      "auc_score = 0.5668549487042638\n",
      "F1_score = 0.2047244094488189\n",
      "Recall = 0.1780821917808219\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.6313\n",
      "Epoch: 20, Loss: 0.5618\n",
      "Epoch: 30, Loss: 0.5112\n",
      "Epoch: 40, Loss: 0.4727\n",
      "Epoch: 50, Loss: 0.4424\n",
      "Epoch: 60, Loss: 0.4179\n",
      "Epoch: 70, Loss: 0.3976\n",
      "Epoch: 80, Loss: 0.3806\n",
      "Epoch: 90, Loss: 0.3660\n",
      "Epoch: 100, Loss: 0.3535\n",
      "Epoch: 110, Loss: 0.3425\n",
      "Epoch: 120, Loss: 0.3329\n",
      "Epoch: 130, Loss: 0.3243\n",
      "Epoch: 140, Loss: 0.3166\n",
      "Epoch: 150, Loss: 0.3097\n",
      "Epoch: 160, Loss: 0.3034\n",
      "auc_score = 0.5756006006006006\n",
      "F1_score = 0.2222222222222222\n",
      "Recall = 0.19444444444444445\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.6054\n",
      "Epoch: 20, Loss: 0.5557\n",
      "Epoch: 30, Loss: 0.5177\n",
      "Epoch: 40, Loss: 0.4876\n",
      "Epoch: 50, Loss: 0.4630\n",
      "Epoch: 60, Loss: 0.4424\n",
      "Epoch: 70, Loss: 0.4248\n",
      "Epoch: 80, Loss: 0.4096\n",
      "Epoch: 90, Loss: 0.3962\n",
      "Epoch: 100, Loss: 0.3843\n",
      "Epoch: 110, Loss: 0.3737\n",
      "Epoch: 120, Loss: 0.3641\n",
      "Epoch: 130, Loss: 0.3555\n",
      "Epoch: 140, Loss: 0.3476\n",
      "auc_score = 0.53819382825594\n",
      "F1_score = 0.16568047337278105\n",
      "Recall = 0.12173913043478261\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.6230\n",
      "Epoch: 20, Loss: 0.5861\n",
      "Epoch: 30, Loss: 0.5542\n",
      "Epoch: 40, Loss: 0.5264\n",
      "Epoch: 50, Loss: 0.5020\n",
      "Epoch: 60, Loss: 0.4805\n",
      "Epoch: 70, Loss: 0.4615\n",
      "Epoch: 80, Loss: 0.4446\n",
      "Epoch: 90, Loss: 0.4294\n",
      "Epoch: 100, Loss: 0.4158\n",
      "Epoch: 110, Loss: 0.4035\n",
      "Epoch: 120, Loss: 0.3924\n",
      "Epoch: 130, Loss: 0.3823\n",
      "Epoch: 140, Loss: 0.3730\n",
      "Epoch: 150, Loss: 0.3646\n",
      "Epoch: 160, Loss: 0.3568\n",
      "Epoch: 170, Loss: 0.3496\n",
      "auc_score = 0.5519620884602594\n",
      "F1_score = 0.20224719101123595\n",
      "Recall = 0.14516129032258066\n",
      "Precision = 0.3333333333333333\n",
      "Epoch: 10, Loss: 0.6056\n",
      "Epoch: 20, Loss: 0.5451\n",
      "Epoch: 30, Loss: 0.5010\n",
      "Epoch: 40, Loss: 0.4670\n",
      "Epoch: 50, Loss: 0.4399\n",
      "auc_score = 0.5675255322209436\n",
      "F1_score = 0.2417582417582417\n",
      "Recall = 0.171875\n",
      "Precision = 0.4074074074074074\n",
      "Epoch: 10, Loss: 0.7776\n",
      "Epoch: 20, Loss: 0.7705\n",
      "Epoch: 30, Loss: 0.7636\n",
      "Epoch: 40, Loss: 0.7569\n",
      "Epoch: 50, Loss: 0.7503\n",
      "Epoch: 60, Loss: 0.7439\n",
      "Epoch: 70, Loss: 0.7377\n",
      "Epoch: 80, Loss: 0.7316\n",
      "Epoch: 90, Loss: 0.7256\n",
      "Epoch: 100, Loss: 0.7197\n",
      "auc_score = 0.5149319520617509\n",
      "F1_score = 0.12312811980033278\n",
      "Recall = 0.06764168190127971\n",
      "Precision = 0.6851851851851852\n",
      "Epoch: 10, Loss: 0.6604\n",
      "Epoch: 20, Loss: 0.6201\n",
      "Epoch: 30, Loss: 0.5865\n",
      "Epoch: 40, Loss: 0.5581\n",
      "Epoch: 50, Loss: 0.5336\n",
      "Epoch: 60, Loss: 0.5123\n",
      "auc_score = 0.5357480396738847\n",
      "F1_score = 0.17721518987341772\n",
      "Recall = 0.10687022900763359\n",
      "Precision = 0.5185185185185185\n",
      "Epoch: 10, Loss: 0.6971\n",
      "Epoch: 20, Loss: 0.6123\n",
      "Epoch: 30, Loss: 0.5522\n",
      "Epoch: 40, Loss: 0.5074\n",
      "Epoch: 50, Loss: 0.4724\n",
      "Epoch: 60, Loss: 0.4442\n",
      "Epoch: 70, Loss: 0.4210\n",
      "Epoch: 80, Loss: 0.4015\n",
      "Epoch: 90, Loss: 0.3849\n",
      "Epoch: 100, Loss: 0.3705\n",
      "auc_score = 0.5675255322209436\n",
      "F1_score = 0.2417582417582417\n",
      "Recall = 0.171875\n",
      "Precision = 0.4074074074074074\n",
      "Epoch: 10, Loss: 0.6804\n",
      "Epoch: 20, Loss: 0.6418\n",
      "Epoch: 30, Loss: 0.6093\n",
      "Epoch: 40, Loss: 0.5814\n",
      "Epoch: 50, Loss: 0.5572\n",
      "Epoch: 60, Loss: 0.5360\n",
      "Epoch: 70, Loss: 0.5171\n",
      "Epoch: 80, Loss: 0.5003\n",
      "auc_score = 0.5321162947937795\n",
      "F1_score = 0.16783216783216784\n",
      "Recall = 0.10344827586206896\n",
      "Precision = 0.4444444444444444\n",
      "Epoch: 10, Loss: 0.6901\n",
      "Epoch: 20, Loss: 0.6483\n",
      "Epoch: 30, Loss: 0.6129\n",
      "Epoch: 40, Loss: 0.5826\n",
      "Epoch: 50, Loss: 0.5562\n",
      "Epoch: 60, Loss: 0.5331\n",
      "Epoch: 70, Loss: 0.5127\n",
      "Epoch: 80, Loss: 0.4945\n",
      "Epoch: 90, Loss: 0.4782\n",
      "Epoch: 100, Loss: 0.4635\n",
      "Epoch: 110, Loss: 0.4501\n",
      "Epoch: 120, Loss: 0.4380\n",
      "Epoch: 130, Loss: 0.4268\n",
      "Epoch: 140, Loss: 0.4166\n",
      "Epoch: 150, Loss: 0.4072\n",
      "Epoch: 160, Loss: 0.3985\n",
      "Epoch: 170, Loss: 0.3904\n",
      "Epoch: 180, Loss: 0.3829\n",
      "Epoch: 190, Loss: 0.3759\n",
      "auc_score = 0.5517384830968647\n",
      "F1_score = 0.20430107526881722\n",
      "Recall = 0.14393939393939395\n",
      "Precision = 0.35185185185185186\n",
      "Epoch: 10, Loss: 0.7586\n",
      "Epoch: 20, Loss: 0.7483\n",
      "Epoch: 30, Loss: 0.7384\n",
      "Epoch: 40, Loss: 0.7288\n",
      "Epoch: 50, Loss: 0.7196\n",
      "Epoch: 60, Loss: 0.7107\n",
      "Epoch: 70, Loss: 0.7020\n",
      "Epoch: 80, Loss: 0.6936\n",
      "Epoch: 90, Loss: 0.6856\n",
      "Epoch: 100, Loss: 0.6777\n",
      "Epoch: 110, Loss: 0.6702\n",
      "Epoch: 120, Loss: 0.6628\n",
      "Epoch: 130, Loss: 0.6557\n",
      "Epoch: 140, Loss: 0.6488\n",
      "auc_score = 0.49434678550796407\n",
      "F1_score = 0.08438818565400844\n",
      "Recall = 0.047619047619047616\n",
      "Precision = 0.37037037037037035\n",
      "Epoch: 10, Loss: 0.6421\n",
      "Epoch: 20, Loss: 0.5275\n",
      "Epoch: 30, Loss: 0.4597\n",
      "Epoch: 40, Loss: 0.4145\n",
      "Epoch: 50, Loss: 0.3821\n",
      "Epoch: 60, Loss: 0.3576\n",
      "Epoch: 70, Loss: 0.3384\n",
      "Epoch: 80, Loss: 0.3230\n",
      "Epoch: 90, Loss: 0.3103\n",
      "Epoch: 100, Loss: 0.2996\n",
      "Epoch: 110, Loss: 0.2905\n",
      "Epoch: 120, Loss: 0.2827\n",
      "Epoch: 130, Loss: 0.2758\n",
      "Epoch: 140, Loss: 0.2698\n",
      "Epoch: 150, Loss: 0.2644\n",
      "Epoch: 160, Loss: 0.2596\n",
      "Epoch: 170, Loss: 0.2553\n",
      "auc_score = 0.589565573064669\n",
      "F1_score = 0.21359223300970873\n",
      "Recall = 0.22448979591836735\n",
      "Precision = 0.2037037037037037\n",
      "Epoch: 10, Loss: 0.6024\n",
      "Epoch: 20, Loss: 0.5075\n",
      "Epoch: 30, Loss: 0.4464\n",
      "Epoch: 40, Loss: 0.4037\n",
      "Epoch: 50, Loss: 0.3724\n",
      "Epoch: 60, Loss: 0.3486\n",
      "Epoch: 70, Loss: 0.3299\n",
      "Epoch: 80, Loss: 0.3148\n",
      "Epoch: 90, Loss: 0.3024\n",
      "Epoch: 100, Loss: 0.2920\n",
      "auc_score = 0.5756006006006006\n",
      "F1_score = 0.2222222222222222\n",
      "Recall = 0.19444444444444445\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.5115\n",
      "Epoch: 20, Loss: 0.4415\n",
      "Epoch: 30, Loss: 0.3977\n",
      "Epoch: 40, Loss: 0.3672\n",
      "Epoch: 50, Loss: 0.3445\n",
      "Epoch: 60, Loss: 0.3267\n",
      "Epoch: 70, Loss: 0.3124\n",
      "Epoch: 80, Loss: 0.3006\n",
      "Epoch: 90, Loss: 0.2907\n",
      "Epoch: 100, Loss: 0.2822\n",
      "auc_score = 0.5810840586096728\n",
      "F1_score = 0.2142857142857143\n",
      "Recall = 0.20689655172413793\n",
      "Precision = 0.2222222222222222\n",
      "Epoch: 10, Loss: 0.7162\n",
      "Epoch: 20, Loss: 0.6667\n",
      "Epoch: 30, Loss: 0.6256\n",
      "Epoch: 40, Loss: 0.5911\n",
      "Epoch: 50, Loss: 0.5617\n",
      "Epoch: 60, Loss: 0.5363\n",
      "Epoch: 70, Loss: 0.5141\n",
      "auc_score = 0.5373995819998694\n",
      "F1_score = 0.18120805369127518\n",
      "Recall = 0.11065573770491803\n",
      "Precision = 0.5\n",
      "Epoch: 10, Loss: 0.5933\n",
      "Epoch: 20, Loss: 0.4922\n",
      "Epoch: 30, Loss: 0.4328\n",
      "Epoch: 40, Loss: 0.3927\n",
      "Epoch: 50, Loss: 0.3636\n",
      "Epoch: 60, Loss: 0.3414\n",
      "Epoch: 70, Loss: 0.3239\n",
      "Epoch: 80, Loss: 0.3097\n",
      "Epoch: 90, Loss: 0.2979\n",
      "Epoch: 100, Loss: 0.2880\n",
      "Epoch: 110, Loss: 0.2795\n",
      "Epoch: 120, Loss: 0.2722\n",
      "Epoch: 130, Loss: 0.2658\n",
      "Epoch: 140, Loss: 0.2601\n",
      "auc_score = 0.5710345378957467\n",
      "F1_score = 0.1869158878504673\n",
      "Recall = 0.18867924528301888\n",
      "Precision = 0.18518518518518517\n",
      "Epoch: 10, Loss: 0.6566\n",
      "Epoch: 20, Loss: 0.5913\n",
      "Epoch: 30, Loss: 0.5420\n",
      "Epoch: 40, Loss: 0.5035\n",
      "Epoch: 50, Loss: 0.4726\n",
      "Epoch: 60, Loss: 0.4472\n",
      "Epoch: 70, Loss: 0.4259\n",
      "Epoch: 80, Loss: 0.4078\n",
      "Epoch: 90, Loss: 0.3921\n",
      "Epoch: 100, Loss: 0.3785\n",
      "Epoch: 110, Loss: 0.3665\n",
      "Epoch: 120, Loss: 0.3559\n",
      "Epoch: 130, Loss: 0.3464\n",
      "Epoch: 140, Loss: 0.3379\n",
      "Epoch: 150, Loss: 0.3301\n",
      "Epoch: 160, Loss: 0.3231\n",
      "auc_score = 0.5980555555555556\n",
      "F1_score = 0.2698412698412698\n",
      "Recall = 0.2361111111111111\n",
      "Precision = 0.3148148148148148\n",
      "Epoch: 10, Loss: 0.5659\n",
      "Epoch: 20, Loss: 0.4951\n",
      "Epoch: 30, Loss: 0.4458\n",
      "Epoch: 40, Loss: 0.4095\n",
      "Epoch: 50, Loss: 0.3816\n",
      "Epoch: 60, Loss: 0.3595\n",
      "auc_score = 0.5538322200837767\n",
      "F1_score = 0.20571428571428574\n",
      "Recall = 0.1487603305785124\n",
      "Precision = 0.3333333333333333\n",
      "Epoch: 10, Loss: 0.5879\n",
      "Epoch: 20, Loss: 0.5059\n",
      "Epoch: 30, Loss: 0.4546\n",
      "Epoch: 40, Loss: 0.4183\n",
      "Epoch: 50, Loss: 0.3908\n",
      "Epoch: 60, Loss: 0.3689\n",
      "Epoch: 70, Loss: 0.3511\n",
      "Epoch: 80, Loss: 0.3363\n",
      "Epoch: 90, Loss: 0.3238\n",
      "auc_score = 0.5607650539930451\n",
      "F1_score = 0.2181818181818182\n",
      "Recall = 0.16216216216216217\n",
      "Precision = 0.3333333333333333\n",
      "Epoch: 10, Loss: 0.8098\n",
      "Epoch: 20, Loss: 0.7748\n",
      "Epoch: 30, Loss: 0.7433\n",
      "Epoch: 40, Loss: 0.7149\n",
      "Epoch: 50, Loss: 0.6893\n",
      "Epoch: 60, Loss: 0.6661\n",
      "Epoch: 70, Loss: 0.6451\n",
      "Epoch: 80, Loss: 0.6261\n",
      "Epoch: 90, Loss: 0.6087\n",
      "Epoch: 100, Loss: 0.5927\n",
      "Epoch: 110, Loss: 0.5781\n",
      "Epoch: 120, Loss: 0.5645\n",
      "Epoch: 130, Loss: 0.5520\n",
      "Epoch: 140, Loss: 0.5403\n",
      "Epoch: 150, Loss: 0.5295\n",
      "Epoch: 160, Loss: 0.5193\n",
      "Epoch: 170, Loss: 0.5098\n",
      "Epoch: 180, Loss: 0.5008\n",
      "auc_score = 0.5696212222074292\n",
      "F1_score = 0.2594142259414226\n",
      "Recall = 0.16756756756756758\n",
      "Precision = 0.5740740740740741\n",
      "Epoch: 10, Loss: 0.6393\n",
      "Epoch: 20, Loss: 0.5514\n",
      "Epoch: 30, Loss: 0.4929\n",
      "Epoch: 40, Loss: 0.4508\n",
      "Epoch: 50, Loss: 0.4187\n",
      "Epoch: 60, Loss: 0.3934\n",
      "Epoch: 70, Loss: 0.3729\n",
      "Epoch: 80, Loss: 0.3560\n",
      "Epoch: 90, Loss: 0.3418\n",
      "Epoch: 100, Loss: 0.3296\n",
      "Epoch: 110, Loss: 0.3191\n",
      "Epoch: 120, Loss: 0.3099\n",
      "Epoch: 130, Loss: 0.3018\n",
      "Epoch: 140, Loss: 0.2946\n",
      "Epoch: 150, Loss: 0.2882\n",
      "Epoch: 160, Loss: 0.2824\n",
      "Epoch: 170, Loss: 0.2772\n",
      "auc_score = 0.5719308875913481\n",
      "F1_score = 0.19642857142857142\n",
      "Recall = 0.1896551724137931\n",
      "Precision = 0.2037037037037037\n",
      "Epoch: 10, Loss: 0.5352\n",
      "Epoch: 20, Loss: 0.4814\n",
      "Epoch: 30, Loss: 0.4414\n",
      "Epoch: 40, Loss: 0.4105\n",
      "Epoch: 50, Loss: 0.3858\n",
      "Epoch: 60, Loss: 0.3657\n",
      "Epoch: 70, Loss: 0.3489\n",
      "Epoch: 80, Loss: 0.3348\n",
      "Epoch: 90, Loss: 0.3227\n",
      "Epoch: 100, Loss: 0.3123\n",
      "Epoch: 110, Loss: 0.3032\n",
      "Epoch: 120, Loss: 0.2951\n",
      "Epoch: 130, Loss: 0.2880\n",
      "Epoch: 140, Loss: 0.2817\n",
      "Epoch: 150, Loss: 0.2759\n",
      "auc_score = 0.5627777165730234\n",
      "F1_score = 0.17857142857142858\n",
      "Recall = 0.1724137931034483\n",
      "Precision = 0.18518518518518517\n",
      "Epoch: 10, Loss: 0.5757\n",
      "Epoch: 20, Loss: 0.4841\n",
      "Epoch: 30, Loss: 0.4291\n",
      "Epoch: 40, Loss: 0.3913\n",
      "Epoch: 50, Loss: 0.3636\n",
      "Epoch: 60, Loss: 0.3421\n",
      "Epoch: 70, Loss: 0.3251\n",
      "Epoch: 80, Loss: 0.3112\n",
      "Epoch: 90, Loss: 0.2996\n",
      "auc_score = 0.5762069452286843\n",
      "F1_score = 0.22900763358778628\n",
      "Recall = 0.19480519480519481\n",
      "Precision = 0.2777777777777778\n",
      "Epoch: 10, Loss: 0.6274\n",
      "Epoch: 20, Loss: 0.5363\n",
      "Epoch: 30, Loss: 0.4770\n",
      "Epoch: 40, Loss: 0.4345\n",
      "Epoch: 50, Loss: 0.4024\n",
      "auc_score = 0.5589029061668989\n",
      "F1_score = 0.2266009852216749\n",
      "Recall = 0.15436241610738255\n",
      "Precision = 0.42592592592592593\n",
      "Epoch: 10, Loss: 0.6506\n",
      "Epoch: 20, Loss: 0.6144\n",
      "Epoch: 30, Loss: 0.5833\n",
      "Epoch: 40, Loss: 0.5562\n",
      "Epoch: 50, Loss: 0.5325\n",
      "Epoch: 60, Loss: 0.5114\n",
      "Epoch: 70, Loss: 0.4927\n",
      "Epoch: 80, Loss: 0.4759\n",
      "auc_score = 0.5417788233774065\n",
      "F1_score = 0.1920529801324503\n",
      "Recall = 0.11693548387096774\n",
      "Precision = 0.5370370370370371\n",
      "Epoch: 10, Loss: 0.5353\n",
      "Epoch: 20, Loss: 0.4566\n",
      "Epoch: 30, Loss: 0.4078\n",
      "Epoch: 40, Loss: 0.3742\n",
      "Epoch: 50, Loss: 0.3495\n",
      "Epoch: 60, Loss: 0.3304\n",
      "Epoch: 70, Loss: 0.3152\n",
      "Epoch: 80, Loss: 0.3027\n",
      "Epoch: 90, Loss: 0.2923\n",
      "Epoch: 100, Loss: 0.2834\n",
      "Epoch: 110, Loss: 0.2758\n",
      "Epoch: 120, Loss: 0.2691\n",
      "Epoch: 130, Loss: 0.2632\n",
      "Epoch: 140, Loss: 0.2580\n",
      "Epoch: 150, Loss: 0.2533\n",
      "Epoch: 160, Loss: 0.2491\n",
      "Epoch: 170, Loss: 0.2453\n",
      "auc_score = 0.5909617844579469\n",
      "F1_score = 0.22429906542056074\n",
      "Recall = 0.22641509433962265\n",
      "Precision = 0.2222222222222222\n",
      "Epoch: 10, Loss: 0.5992\n",
      "Epoch: 20, Loss: 0.5028\n",
      "Epoch: 30, Loss: 0.4442\n",
      "Epoch: 40, Loss: 0.4039\n",
      "Epoch: 50, Loss: 0.3742\n",
      "Epoch: 60, Loss: 0.3514\n",
      "Epoch: 70, Loss: 0.3332\n",
      "Epoch: 80, Loss: 0.3184\n",
      "Epoch: 90, Loss: 0.3060\n",
      "auc_score = 0.5716413593637021\n",
      "F1_score = 0.21705426356589147\n",
      "Recall = 0.18666666666666668\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.6961\n",
      "Epoch: 20, Loss: 0.6298\n",
      "Epoch: 30, Loss: 0.5794\n",
      "Epoch: 40, Loss: 0.5398\n",
      "Epoch: 50, Loss: 0.5077\n",
      "Epoch: 60, Loss: 0.4811\n",
      "Epoch: 70, Loss: 0.4586\n",
      "Epoch: 80, Loss: 0.4393\n",
      "Epoch: 90, Loss: 0.4225\n",
      "Epoch: 100, Loss: 0.4078\n",
      "Epoch: 110, Loss: 0.3948\n",
      "Epoch: 120, Loss: 0.3831\n",
      "Epoch: 130, Loss: 0.3727\n",
      "Epoch: 140, Loss: 0.3632\n",
      "Epoch: 150, Loss: 0.3546\n",
      "Epoch: 160, Loss: 0.3468\n",
      "Epoch: 170, Loss: 0.3396\n",
      "Epoch: 180, Loss: 0.3330\n",
      "auc_score = 0.5414769713578501\n",
      "F1_score = 0.16774193548387098\n",
      "Recall = 0.12871287128712872\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.8969\n",
      "Epoch: 20, Loss: 0.8903\n",
      "Epoch: 30, Loss: 0.8838\n",
      "Epoch: 40, Loss: 0.8774\n",
      "Epoch: 50, Loss: 0.8711\n",
      "Epoch: 60, Loss: 0.8649\n",
      "Epoch: 70, Loss: 0.8588\n",
      "Epoch: 80, Loss: 0.8528\n",
      "Epoch: 90, Loss: 0.8468\n",
      "Epoch: 100, Loss: 0.8410\n",
      "auc_score = 0.4774388623072834\n",
      "F1_score = 0.0749665327978581\n",
      "Recall = 0.04040404040404041\n",
      "Precision = 0.5185185185185185\n",
      "Epoch: 10, Loss: 0.7180\n",
      "Epoch: 20, Loss: 0.6160\n",
      "Epoch: 30, Loss: 0.5482\n",
      "Epoch: 40, Loss: 0.5006\n",
      "Epoch: 50, Loss: 0.4654\n",
      "Epoch: 60, Loss: 0.4380\n",
      "Epoch: 70, Loss: 0.4160\n",
      "Epoch: 80, Loss: 0.3978\n",
      "Epoch: 90, Loss: 0.3824\n",
      "Epoch: 100, Loss: 0.3692\n",
      "Epoch: 110, Loss: 0.3577\n",
      "Epoch: 120, Loss: 0.3476\n",
      "Epoch: 130, Loss: 0.3386\n",
      "Epoch: 140, Loss: 0.3305\n",
      "auc_score = 0.563146224763683\n",
      "F1_score = 0.21476510067114096\n",
      "Recall = 0.16842105263157894\n",
      "Precision = 0.2962962962962963\n",
      "Epoch: 10, Loss: 0.6006\n",
      "Epoch: 20, Loss: 0.4808\n",
      "Epoch: 30, Loss: 0.4167\n",
      "Epoch: 40, Loss: 0.3758\n",
      "Epoch: 50, Loss: 0.3472\n",
      "Epoch: 60, Loss: 0.3258\n",
      "Epoch: 70, Loss: 0.3093\n",
      "Epoch: 80, Loss: 0.2962\n",
      "Epoch: 90, Loss: 0.2854\n",
      "Epoch: 100, Loss: 0.2763\n",
      "Epoch: 110, Loss: 0.2687\n",
      "Epoch: 120, Loss: 0.2621\n",
      "Epoch: 130, Loss: 0.2563\n",
      "auc_score = 0.5809981611768468\n",
      "F1_score = 0.20560747663551404\n",
      "Recall = 0.20754716981132076\n",
      "Precision = 0.2037037037037037\n",
      "Epoch: 10, Loss: 0.6052\n",
      "Epoch: 20, Loss: 0.4955\n",
      "Epoch: 30, Loss: 0.4333\n",
      "Epoch: 40, Loss: 0.3924\n",
      "Epoch: 50, Loss: 0.3632\n",
      "Epoch: 60, Loss: 0.3411\n",
      "Epoch: 70, Loss: 0.3237\n",
      "Epoch: 80, Loss: 0.3096\n",
      "Epoch: 90, Loss: 0.2980\n",
      "auc_score = 0.5769932771575457\n",
      "F1_score = 0.22399999999999998\n",
      "Recall = 0.19718309859154928\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.5921\n",
      "Epoch: 20, Loss: 0.4849\n",
      "Epoch: 30, Loss: 0.4249\n",
      "Epoch: 40, Loss: 0.3856\n",
      "Epoch: 50, Loss: 0.3574\n",
      "Epoch: 60, Loss: 0.3362\n",
      "Epoch: 70, Loss: 0.3195\n",
      "Epoch: 80, Loss: 0.3060\n",
      "auc_score = 0.5707427955000771\n",
      "F1_score = 0.20967741935483872\n",
      "Recall = 0.18571428571428572\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.5582\n",
      "Epoch: 20, Loss: 0.5174\n",
      "Epoch: 30, Loss: 0.4849\n",
      "Epoch: 40, Loss: 0.4585\n",
      "Epoch: 50, Loss: 0.4364\n",
      "Epoch: 60, Loss: 0.4178\n",
      "Epoch: 70, Loss: 0.4018\n",
      "Epoch: 80, Loss: 0.3879\n",
      "Epoch: 90, Loss: 0.3757\n",
      "Epoch: 100, Loss: 0.3650\n",
      "Epoch: 110, Loss: 0.3553\n",
      "Epoch: 120, Loss: 0.3467\n",
      "Epoch: 130, Loss: 0.3389\n",
      "Epoch: 140, Loss: 0.3318\n",
      "Epoch: 150, Loss: 0.3253\n",
      "Epoch: 160, Loss: 0.3193\n",
      "Epoch: 170, Loss: 0.3138\n",
      "Epoch: 180, Loss: 0.3087\n",
      "auc_score = 0.5558104755106896\n",
      "F1_score = 0.17094017094017092\n",
      "Recall = 0.15873015873015872\n",
      "Precision = 0.18518518518518517\n",
      "Epoch: 10, Loss: 0.6436\n",
      "Epoch: 20, Loss: 0.5944\n",
      "Epoch: 30, Loss: 0.5543\n",
      "Epoch: 40, Loss: 0.5208\n",
      "Epoch: 50, Loss: 0.4925\n",
      "Epoch: 60, Loss: 0.4684\n",
      "Epoch: 70, Loss: 0.4475\n",
      "Epoch: 80, Loss: 0.4293\n",
      "Epoch: 90, Loss: 0.4133\n",
      "Epoch: 100, Loss: 0.3992\n",
      "Epoch: 110, Loss: 0.3866\n",
      "Epoch: 120, Loss: 0.3753\n",
      "Epoch: 130, Loss: 0.3652\n",
      "Epoch: 140, Loss: 0.3560\n",
      "Epoch: 150, Loss: 0.3477\n",
      "Epoch: 160, Loss: 0.3401\n",
      "auc_score = 0.5529379867889185\n",
      "F1_score = 0.20118343195266275\n",
      "Recall = 0.14782608695652175\n",
      "Precision = 0.3148148148148148\n",
      "Epoch: 10, Loss: 0.7447\n",
      "Epoch: 20, Loss: 0.7398\n",
      "Epoch: 30, Loss: 0.7350\n",
      "Epoch: 40, Loss: 0.7303\n",
      "Epoch: 50, Loss: 0.7256\n",
      "Epoch: 60, Loss: 0.7210\n",
      "Epoch: 70, Loss: 0.7165\n",
      "Epoch: 80, Loss: 0.7121\n",
      "Epoch: 90, Loss: 0.7077\n",
      "Epoch: 100, Loss: 0.7034\n",
      "Epoch: 110, Loss: 0.6992\n",
      "Epoch: 120, Loss: 0.6950\n",
      "Epoch: 130, Loss: 0.6910\n",
      "Epoch: 140, Loss: 0.6869\n",
      "Epoch: 150, Loss: 0.6830\n",
      "Epoch: 160, Loss: 0.6791\n",
      "auc_score = 0.5102829073417309\n",
      "F1_score = 0.11693548387096774\n",
      "Recall = 0.06561085972850679\n",
      "Precision = 0.5370370370370371\n",
      "Epoch: 10, Loss: 0.6190\n",
      "Epoch: 20, Loss: 0.5591\n",
      "Epoch: 30, Loss: 0.5140\n",
      "Epoch: 40, Loss: 0.4788\n",
      "Epoch: 50, Loss: 0.4506\n",
      "Epoch: 60, Loss: 0.4274\n",
      "Epoch: 70, Loss: 0.4080\n",
      "auc_score = 0.5717885240126815\n",
      "F1_score = 0.24705882352941175\n",
      "Recall = 0.1810344827586207\n",
      "Precision = 0.3888888888888889\n",
      "Epoch: 10, Loss: 0.6088\n",
      "Epoch: 20, Loss: 0.5329\n",
      "Epoch: 30, Loss: 0.4828\n",
      "Epoch: 40, Loss: 0.4470\n",
      "Epoch: 50, Loss: 0.4199\n",
      "Epoch: 60, Loss: 0.3984\n",
      "Epoch: 70, Loss: 0.3809\n",
      "Epoch: 80, Loss: 0.3663\n",
      "Epoch: 90, Loss: 0.3537\n",
      "Epoch: 100, Loss: 0.3429\n",
      "Epoch: 110, Loss: 0.3333\n",
      "Epoch: 120, Loss: 0.3249\n",
      "Epoch: 130, Loss: 0.3173\n",
      "Epoch: 140, Loss: 0.3105\n",
      "auc_score = 0.5668537151702787\n",
      "F1_score = 0.2158273381294964\n",
      "Recall = 0.17647058823529413\n",
      "Precision = 0.2777777777777778\n",
      "Epoch: 10, Loss: 0.5830\n",
      "Epoch: 20, Loss: 0.4821\n",
      "Epoch: 30, Loss: 0.4227\n",
      "Epoch: 40, Loss: 0.3831\n",
      "Epoch: 50, Loss: 0.3546\n",
      "Epoch: 60, Loss: 0.3330\n",
      "Epoch: 70, Loss: 0.3161\n",
      "Epoch: 80, Loss: 0.3025\n",
      "Epoch: 90, Loss: 0.2912\n",
      "Epoch: 100, Loss: 0.2818\n",
      "Epoch: 110, Loss: 0.2737\n",
      "Epoch: 120, Loss: 0.2667\n",
      "auc_score = 0.5767687434002112\n",
      "F1_score = 0.1923076923076923\n",
      "Recall = 0.2\n",
      "Precision = 0.18518518518518517\n",
      "Epoch: 10, Loss: 0.6439\n",
      "Epoch: 20, Loss: 0.5625\n",
      "Epoch: 30, Loss: 0.5052\n",
      "Epoch: 40, Loss: 0.4627\n",
      "Epoch: 50, Loss: 0.4300\n",
      "Epoch: 60, Loss: 0.4041\n",
      "Epoch: 70, Loss: 0.3831\n",
      "Epoch: 80, Loss: 0.3656\n",
      "Epoch: 90, Loss: 0.3509\n",
      "Epoch: 100, Loss: 0.3383\n",
      "Epoch: 110, Loss: 0.3274\n",
      "auc_score = 0.5888437822605397\n",
      "F1_score = 0.25757575757575757\n",
      "Recall = 0.21794871794871795\n",
      "Precision = 0.3148148148148148\n",
      "Epoch: 10, Loss: 0.6532\n",
      "Epoch: 20, Loss: 0.5695\n",
      "Epoch: 30, Loss: 0.5123\n",
      "Epoch: 40, Loss: 0.4706\n",
      "Epoch: 50, Loss: 0.4387\n",
      "Epoch: 60, Loss: 0.4134\n",
      "Epoch: 70, Loss: 0.3928\n",
      "Epoch: 80, Loss: 0.3756\n",
      "Epoch: 90, Loss: 0.3610\n",
      "Epoch: 100, Loss: 0.3485\n",
      "Epoch: 110, Loss: 0.3376\n",
      "Epoch: 120, Loss: 0.3280\n",
      "Epoch: 130, Loss: 0.3195\n",
      "Epoch: 140, Loss: 0.3118\n",
      "Epoch: 150, Loss: 0.3050\n",
      "Epoch: 160, Loss: 0.2988\n",
      "Epoch: 170, Loss: 0.2932\n",
      "auc_score = 0.5867979154603359\n",
      "F1_score = 0.2201834862385321\n",
      "Recall = 0.21818181818181817\n",
      "Precision = 0.2222222222222222\n",
      "Epoch: 10, Loss: 0.6050\n",
      "Epoch: 20, Loss: 0.4899\n",
      "Epoch: 30, Loss: 0.4303\n",
      "Epoch: 40, Loss: 0.3920\n",
      "Epoch: 50, Loss: 0.3645\n",
      "Epoch: 60, Loss: 0.3434\n",
      "Epoch: 70, Loss: 0.3267\n",
      "auc_score = 0.5784936998854524\n",
      "F1_score = 0.25165562913907286\n",
      "Recall = 0.1958762886597938\n",
      "Precision = 0.35185185185185186\n",
      "Epoch: 10, Loss: 0.8060\n",
      "Epoch: 20, Loss: 0.7588\n",
      "Epoch: 30, Loss: 0.7181\n",
      "Epoch: 40, Loss: 0.6828\n",
      "Epoch: 50, Loss: 0.6520\n",
      "Epoch: 60, Loss: 0.6248\n",
      "Epoch: 70, Loss: 0.6007\n",
      "Epoch: 80, Loss: 0.5791\n",
      "Epoch: 90, Loss: 0.5596\n",
      "auc_score = 0.5396137150660879\n",
      "F1_score = 0.18604651162790697\n",
      "Recall = 0.1103448275862069\n",
      "Precision = 0.5925925925925926\n",
      "Epoch: 10, Loss: 0.5321\n",
      "Epoch: 20, Loss: 0.4760\n",
      "Epoch: 30, Loss: 0.4343\n",
      "Epoch: 40, Loss: 0.4023\n",
      "Epoch: 50, Loss: 0.3772\n",
      "Epoch: 60, Loss: 0.3569\n",
      "Epoch: 70, Loss: 0.3403\n",
      "Epoch: 80, Loss: 0.3264\n",
      "Epoch: 90, Loss: 0.3146\n",
      "Epoch: 100, Loss: 0.3045\n",
      "Epoch: 110, Loss: 0.2957\n",
      "Epoch: 120, Loss: 0.2880\n",
      "auc_score = 0.5656897491821156\n",
      "F1_score = 0.208955223880597\n",
      "Recall = 0.175\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.6876\n",
      "Epoch: 20, Loss: 0.5912\n",
      "Epoch: 30, Loss: 0.5262\n",
      "Epoch: 40, Loss: 0.4791\n",
      "Epoch: 50, Loss: 0.4432\n",
      "Epoch: 60, Loss: 0.4149\n",
      "Epoch: 70, Loss: 0.3920\n",
      "Epoch: 80, Loss: 0.3731\n",
      "auc_score = 0.5605994870904919\n",
      "F1_score = 0.2209302325581395\n",
      "Recall = 0.16101694915254236\n",
      "Precision = 0.35185185185185186\n",
      "Epoch: 10, Loss: 0.7013\n",
      "Epoch: 20, Loss: 0.6021\n",
      "Epoch: 30, Loss: 0.5339\n",
      "Epoch: 40, Loss: 0.4847\n",
      "Epoch: 50, Loss: 0.4476\n",
      "Epoch: 60, Loss: 0.4187\n",
      "Epoch: 70, Loss: 0.3955\n",
      "Epoch: 80, Loss: 0.3765\n",
      "auc_score = 0.5771168920665002\n",
      "F1_score = 0.25316455696202533\n",
      "Recall = 0.19230769230769232\n",
      "Precision = 0.37037037037037035\n",
      "Epoch: 10, Loss: 0.5458\n",
      "Epoch: 20, Loss: 0.5236\n",
      "Epoch: 30, Loss: 0.5042\n",
      "Epoch: 40, Loss: 0.4869\n",
      "Epoch: 50, Loss: 0.4715\n",
      "Epoch: 60, Loss: 0.4576\n",
      "Epoch: 70, Loss: 0.4450\n",
      "Epoch: 80, Loss: 0.4336\n",
      "Epoch: 90, Loss: 0.4231\n",
      "Epoch: 100, Loss: 0.4134\n",
      "Epoch: 110, Loss: 0.4045\n",
      "Epoch: 120, Loss: 0.3963\n",
      "Epoch: 130, Loss: 0.3886\n",
      "Epoch: 140, Loss: 0.3815\n",
      "Epoch: 150, Loss: 0.3748\n",
      "Epoch: 160, Loss: 0.3686\n",
      "Epoch: 170, Loss: 0.3627\n",
      "Epoch: 180, Loss: 0.3572\n",
      "auc_score = 0.5620327605777135\n",
      "F1_score = 0.2235294117647059\n",
      "Recall = 0.16379310344827586\n",
      "Precision = 0.35185185185185186\n",
      "Epoch: 10, Loss: 0.5831\n",
      "Epoch: 20, Loss: 0.5076\n",
      "Epoch: 30, Loss: 0.4550\n",
      "Epoch: 40, Loss: 0.4162\n",
      "Epoch: 50, Loss: 0.3865\n",
      "Epoch: 60, Loss: 0.3632\n",
      "Epoch: 70, Loss: 0.3443\n",
      "Epoch: 80, Loss: 0.3289\n",
      "auc_score = 0.5510034534436697\n",
      "F1_score = 0.19108280254777069\n",
      "Recall = 0.14563106796116504\n",
      "Precision = 0.2777777777777778\n",
      "Epoch: 10, Loss: 0.7543\n",
      "Epoch: 20, Loss: 0.7011\n",
      "Epoch: 30, Loss: 0.6555\n",
      "Epoch: 40, Loss: 0.6161\n",
      "Epoch: 50, Loss: 0.5819\n",
      "Epoch: 60, Loss: 0.5520\n",
      "Epoch: 70, Loss: 0.5257\n",
      "Epoch: 80, Loss: 0.5025\n",
      "Epoch: 90, Loss: 0.4818\n",
      "Epoch: 100, Loss: 0.4634\n",
      "Epoch: 110, Loss: 0.4469\n",
      "Epoch: 120, Loss: 0.4321\n",
      "Epoch: 130, Loss: 0.4187\n",
      "Epoch: 140, Loss: 0.4065\n",
      "Epoch: 150, Loss: 0.3955\n",
      "Epoch: 160, Loss: 0.3854\n",
      "auc_score = 0.5704861428702095\n",
      "F1_score = 0.2571428571428571\n",
      "Recall = 0.17307692307692307\n",
      "Precision = 0.5\n",
      "Epoch: 10, Loss: 0.6523\n",
      "Epoch: 20, Loss: 0.5882\n",
      "Epoch: 30, Loss: 0.5395\n",
      "Epoch: 40, Loss: 0.5015\n",
      "Epoch: 50, Loss: 0.4710\n",
      "Epoch: 60, Loss: 0.4461\n",
      "Epoch: 70, Loss: 0.4252\n",
      "Epoch: 80, Loss: 0.4075\n",
      "auc_score = 0.5397231971017775\n",
      "F1_score = 0.1714285714285714\n",
      "Recall = 0.12396694214876033\n",
      "Precision = 0.2777777777777778\n",
      "Epoch: 10, Loss: 0.5888\n",
      "Epoch: 20, Loss: 0.5192\n",
      "Epoch: 30, Loss: 0.4725\n",
      "Epoch: 40, Loss: 0.4385\n",
      "Epoch: 50, Loss: 0.4123\n",
      "Epoch: 60, Loss: 0.3913\n",
      "Epoch: 70, Loss: 0.3739\n",
      "Epoch: 80, Loss: 0.3592\n",
      "Epoch: 90, Loss: 0.3466\n",
      "Epoch: 100, Loss: 0.3357\n",
      "Epoch: 110, Loss: 0.3261\n",
      "Epoch: 120, Loss: 0.3175\n",
      "Epoch: 130, Loss: 0.3099\n",
      "Epoch: 140, Loss: 0.3031\n",
      "Epoch: 150, Loss: 0.2969\n",
      "Epoch: 160, Loss: 0.2913\n",
      "Epoch: 170, Loss: 0.2861\n",
      "auc_score = 0.5788503253796095\n",
      "F1_score = 0.23255813953488372\n",
      "Recall = 0.2\n",
      "Precision = 0.2777777777777778\n",
      "Epoch: 10, Loss: 0.7287\n",
      "Epoch: 20, Loss: 0.7135\n",
      "Epoch: 30, Loss: 0.6991\n",
      "Epoch: 40, Loss: 0.6854\n",
      "Epoch: 50, Loss: 0.6724\n",
      "auc_score = 0.5231350074299167\n",
      "F1_score = 0.1441048034934498\n",
      "Recall = 0.08168316831683169\n",
      "Precision = 0.6111111111111112\n",
      "Epoch: 10, Loss: 0.5852\n",
      "Epoch: 20, Loss: 0.4882\n",
      "Epoch: 30, Loss: 0.4298\n",
      "Epoch: 40, Loss: 0.3901\n",
      "Epoch: 50, Loss: 0.3612\n",
      "Epoch: 60, Loss: 0.3392\n",
      "Epoch: 70, Loss: 0.3218\n",
      "Epoch: 80, Loss: 0.3076\n",
      "Epoch: 90, Loss: 0.2960\n",
      "Epoch: 100, Loss: 0.2861\n",
      "Epoch: 110, Loss: 0.2777\n",
      "Epoch: 120, Loss: 0.2704\n",
      "Epoch: 130, Loss: 0.2641\n",
      "auc_score = 0.5719308875913481\n",
      "F1_score = 0.19642857142857142\n",
      "Recall = 0.1896551724137931\n",
      "Precision = 0.2037037037037037\n",
      "Epoch: 10, Loss: 0.5633\n",
      "Epoch: 20, Loss: 0.4794\n",
      "Epoch: 30, Loss: 0.4281\n",
      "Epoch: 40, Loss: 0.3928\n",
      "Epoch: 50, Loss: 0.3667\n",
      "Epoch: 60, Loss: 0.3464\n",
      "Epoch: 70, Loss: 0.3301\n",
      "Epoch: 80, Loss: 0.3167\n",
      "Epoch: 90, Loss: 0.3054\n",
      "Epoch: 100, Loss: 0.2958\n",
      "auc_score = 0.5549275022166588\n",
      "F1_score = 0.18840579710144928\n",
      "Recall = 0.15476190476190477\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.6254\n",
      "Epoch: 20, Loss: 0.5860\n",
      "Epoch: 30, Loss: 0.5531\n",
      "Epoch: 40, Loss: 0.5253\n",
      "Epoch: 50, Loss: 0.5013\n",
      "Epoch: 60, Loss: 0.4805\n",
      "Epoch: 70, Loss: 0.4623\n",
      "Epoch: 80, Loss: 0.4462\n",
      "Epoch: 90, Loss: 0.4318\n",
      "Epoch: 100, Loss: 0.4190\n",
      "auc_score = 0.5637116481129514\n",
      "F1_score = 0.23204419889502764\n",
      "Recall = 0.16535433070866143\n",
      "Precision = 0.3888888888888889\n",
      "Epoch: 10, Loss: 0.6569\n",
      "Epoch: 20, Loss: 0.5324\n",
      "Epoch: 30, Loss: 0.4613\n",
      "Epoch: 40, Loss: 0.4148\n",
      "Epoch: 50, Loss: 0.3818\n",
      "Epoch: 60, Loss: 0.3569\n",
      "Epoch: 70, Loss: 0.3375\n",
      "Epoch: 80, Loss: 0.3219\n",
      "Epoch: 90, Loss: 0.3090\n",
      "Epoch: 100, Loss: 0.2982\n",
      "Epoch: 110, Loss: 0.2890\n",
      "auc_score = 0.5729261222218969\n",
      "F1_score = 0.21875\n",
      "Recall = 0.1891891891891892\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.5980\n",
      "Epoch: 20, Loss: 0.4871\n",
      "Epoch: 30, Loss: 0.4231\n",
      "Epoch: 40, Loss: 0.3810\n",
      "Epoch: 50, Loss: 0.3513\n",
      "auc_score = 0.5862611784883008\n",
      "F1_score = 0.26388888888888884\n",
      "Recall = 0.2111111111111111\n",
      "Precision = 0.35185185185185186\n",
      "Epoch: 10, Loss: 0.5401\n",
      "Epoch: 20, Loss: 0.4661\n",
      "Epoch: 30, Loss: 0.4176\n",
      "Epoch: 40, Loss: 0.3833\n",
      "Epoch: 50, Loss: 0.3577\n",
      "Epoch: 60, Loss: 0.3378\n",
      "Epoch: 70, Loss: 0.3219\n",
      "Epoch: 80, Loss: 0.3088\n",
      "Epoch: 90, Loss: 0.2979\n",
      "Epoch: 100, Loss: 0.2887\n",
      "Epoch: 110, Loss: 0.2807\n",
      "auc_score = 0.5749719146204462\n",
      "F1_score = 0.21487603305785125\n",
      "Recall = 0.19402985074626866\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.5641\n",
      "Epoch: 20, Loss: 0.4832\n",
      "Epoch: 30, Loss: 0.4304\n",
      "Epoch: 40, Loss: 0.3933\n",
      "Epoch: 50, Loss: 0.3657\n",
      "Epoch: 60, Loss: 0.3443\n",
      "Epoch: 70, Loss: 0.3272\n",
      "Epoch: 80, Loss: 0.3133\n",
      "Epoch: 90, Loss: 0.3016\n",
      "Epoch: 100, Loss: 0.2917\n",
      "Epoch: 110, Loss: 0.2833\n",
      "Epoch: 120, Loss: 0.2759\n",
      "Epoch: 130, Loss: 0.2694\n",
      "Epoch: 140, Loss: 0.2637\n",
      "Epoch: 150, Loss: 0.2585\n",
      "auc_score = 0.5775880469583778\n",
      "F1_score = 0.2105263157894737\n",
      "Recall = 0.2\n",
      "Precision = 0.2222222222222222\n",
      "Epoch: 10, Loss: 0.6185\n",
      "Epoch: 20, Loss: 0.5872\n",
      "Epoch: 30, Loss: 0.5599\n",
      "Epoch: 40, Loss: 0.5360\n",
      "Epoch: 50, Loss: 0.5149\n",
      "Epoch: 60, Loss: 0.4960\n",
      "auc_score = 0.5329287758696609\n",
      "F1_score = 0.17006802721088435\n",
      "Recall = 0.10416666666666667\n",
      "Precision = 0.46296296296296297\n",
      "Epoch: 10, Loss: 0.5968\n",
      "Epoch: 20, Loss: 0.5188\n",
      "Epoch: 30, Loss: 0.4642\n",
      "Epoch: 40, Loss: 0.4242\n",
      "Epoch: 50, Loss: 0.3938\n",
      "Epoch: 60, Loss: 0.3699\n",
      "Epoch: 70, Loss: 0.3507\n",
      "Epoch: 80, Loss: 0.3350\n",
      "Epoch: 90, Loss: 0.3218\n",
      "Epoch: 100, Loss: 0.3107\n",
      "auc_score = 0.5578670009164914\n",
      "F1_score = 0.19259259259259257\n",
      "Recall = 0.16049382716049382\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.6427\n",
      "Epoch: 20, Loss: 0.5635\n",
      "Epoch: 30, Loss: 0.5105\n",
      "Epoch: 40, Loss: 0.4722\n",
      "Epoch: 50, Loss: 0.4425\n",
      "Epoch: 60, Loss: 0.4186\n",
      "Epoch: 70, Loss: 0.3988\n",
      "auc_score = 0.5682459677419355\n",
      "F1_score = 0.25233644859813087\n",
      "Recall = 0.16875\n",
      "Precision = 0.5\n",
      "Epoch: 10, Loss: 0.5699\n",
      "Epoch: 20, Loss: 0.4827\n",
      "Epoch: 30, Loss: 0.4278\n",
      "Epoch: 40, Loss: 0.3900\n",
      "Epoch: 50, Loss: 0.3623\n",
      "Epoch: 60, Loss: 0.3411\n",
      "Epoch: 70, Loss: 0.3243\n",
      "Epoch: 80, Loss: 0.3106\n",
      "Epoch: 90, Loss: 0.2993\n",
      "Epoch: 100, Loss: 0.2897\n",
      "Epoch: 110, Loss: 0.2815\n",
      "Epoch: 120, Loss: 0.2743\n",
      "Epoch: 130, Loss: 0.2681\n",
      "Epoch: 140, Loss: 0.2625\n",
      "auc_score = 0.582922732362822\n",
      "F1_score = 0.21621621621621623\n",
      "Recall = 0.21052631578947367\n",
      "Precision = 0.2222222222222222\n",
      "Epoch: 10, Loss: 0.5844\n",
      "Epoch: 20, Loss: 0.5200\n",
      "Epoch: 30, Loss: 0.4737\n",
      "Epoch: 40, Loss: 0.4388\n",
      "Epoch: 50, Loss: 0.4115\n",
      "Epoch: 60, Loss: 0.3895\n",
      "Epoch: 70, Loss: 0.3713\n",
      "Epoch: 80, Loss: 0.3561\n",
      "Epoch: 90, Loss: 0.3431\n",
      "Epoch: 100, Loss: 0.3318\n",
      "Epoch: 110, Loss: 0.3220\n",
      "Epoch: 120, Loss: 0.3134\n",
      "Epoch: 130, Loss: 0.3057\n",
      "Epoch: 140, Loss: 0.2989\n",
      "Epoch: 150, Loss: 0.2927\n",
      "Epoch: 160, Loss: 0.2871\n",
      "Epoch: 170, Loss: 0.2820\n",
      "auc_score = 0.5669715936446799\n",
      "F1_score = 0.1983471074380165\n",
      "Recall = 0.1791044776119403\n",
      "Precision = 0.2222222222222222\n",
      "Epoch: 10, Loss: 0.6086\n",
      "Epoch: 20, Loss: 0.5130\n",
      "Epoch: 30, Loss: 0.4518\n",
      "Epoch: 40, Loss: 0.4092\n",
      "Epoch: 50, Loss: 0.3779\n",
      "Epoch: 60, Loss: 0.3540\n",
      "Epoch: 70, Loss: 0.3351\n",
      "Epoch: 80, Loss: 0.3198\n",
      "Epoch: 90, Loss: 0.3071\n",
      "Epoch: 100, Loss: 0.2965\n",
      "auc_score = 0.5784250269687162\n",
      "F1_score = 0.22580645161290322\n",
      "Recall = 0.2\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.6075\n",
      "Epoch: 20, Loss: 0.5409\n",
      "Epoch: 30, Loss: 0.4922\n",
      "Epoch: 40, Loss: 0.4550\n",
      "Epoch: 50, Loss: 0.4256\n",
      "auc_score = 0.5634291940745494\n",
      "F1_score = 0.24369747899159666\n",
      "Recall = 0.15760869565217392\n",
      "Precision = 0.5370370370370371\n",
      "Epoch: 10, Loss: 0.6231\n",
      "Epoch: 20, Loss: 0.5238\n",
      "Epoch: 30, Loss: 0.4618\n",
      "Epoch: 40, Loss: 0.4190\n",
      "Epoch: 50, Loss: 0.3875\n",
      "Epoch: 60, Loss: 0.3633\n",
      "Epoch: 70, Loss: 0.3440\n",
      "Epoch: 80, Loss: 0.3283\n",
      "Epoch: 90, Loss: 0.3152\n",
      "auc_score = 0.5608944036096355\n",
      "F1_score = 0.20689655172413796\n",
      "Recall = 0.16483516483516483\n",
      "Precision = 0.2777777777777778\n",
      "Epoch: 10, Loss: 0.6561\n",
      "Epoch: 20, Loss: 0.5530\n",
      "Epoch: 30, Loss: 0.4893\n",
      "Epoch: 40, Loss: 0.4453\n",
      "Epoch: 50, Loss: 0.4128\n",
      "Epoch: 60, Loss: 0.3875\n",
      "Epoch: 70, Loss: 0.3673\n",
      "Epoch: 80, Loss: 0.3506\n",
      "Epoch: 90, Loss: 0.3366\n",
      "Epoch: 100, Loss: 0.3247\n",
      "Epoch: 110, Loss: 0.3144\n",
      "Epoch: 120, Loss: 0.3054\n",
      "Epoch: 130, Loss: 0.2975\n",
      "auc_score = 0.5644323933477946\n",
      "F1_score = 0.20155038759689925\n",
      "Recall = 0.17333333333333334\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.5892\n",
      "Epoch: 20, Loss: 0.5404\n",
      "Epoch: 30, Loss: 0.5040\n",
      "Epoch: 40, Loss: 0.4758\n",
      "Epoch: 50, Loss: 0.4531\n",
      "Epoch: 60, Loss: 0.4344\n",
      "auc_score = 0.5442627929341498\n",
      "F1_score = 0.18750000000000003\n",
      "Recall = 0.13043478260869565\n",
      "Precision = 0.3333333333333333\n",
      "Epoch: 10, Loss: 0.6495\n",
      "Epoch: 20, Loss: 0.5886\n",
      "Epoch: 30, Loss: 0.5419\n",
      "Epoch: 40, Loss: 0.5051\n",
      "Epoch: 50, Loss: 0.4753\n",
      "Epoch: 60, Loss: 0.4506\n",
      "Epoch: 70, Loss: 0.4300\n",
      "Epoch: 80, Loss: 0.4123\n",
      "Epoch: 90, Loss: 0.3971\n",
      "Epoch: 100, Loss: 0.3837\n",
      "Epoch: 110, Loss: 0.3720\n",
      "Epoch: 120, Loss: 0.3615\n",
      "auc_score = 0.5851644471347861\n",
      "F1_score = 0.27710843373493976\n",
      "Recall = 0.20535714285714285\n",
      "Precision = 0.42592592592592593\n",
      "Epoch: 10, Loss: 0.6822\n",
      "Epoch: 20, Loss: 0.6447\n",
      "Epoch: 30, Loss: 0.6125\n",
      "Epoch: 40, Loss: 0.5846\n",
      "Epoch: 50, Loss: 0.5601\n",
      "Epoch: 60, Loss: 0.5385\n",
      "Epoch: 70, Loss: 0.5193\n",
      "Epoch: 80, Loss: 0.5021\n",
      "Epoch: 90, Loss: 0.4866\n",
      "Epoch: 100, Loss: 0.4726\n",
      "Epoch: 110, Loss: 0.4599\n",
      "Epoch: 120, Loss: 0.4482\n",
      "Epoch: 130, Loss: 0.4375\n",
      "Epoch: 140, Loss: 0.4277\n",
      "Epoch: 150, Loss: 0.4186\n",
      "Epoch: 160, Loss: 0.4102\n",
      "auc_score = 0.5675255322209436\n",
      "F1_score = 0.2417582417582417\n",
      "Recall = 0.171875\n",
      "Precision = 0.4074074074074074\n",
      "Epoch: 10, Loss: 0.6010\n",
      "Epoch: 20, Loss: 0.4923\n",
      "Epoch: 30, Loss: 0.4297\n",
      "Epoch: 40, Loss: 0.3879\n",
      "Epoch: 50, Loss: 0.3579\n",
      "Epoch: 60, Loss: 0.3352\n",
      "Epoch: 70, Loss: 0.3175\n",
      "Epoch: 80, Loss: 0.3033\n",
      "Epoch: 90, Loss: 0.2916\n",
      "Epoch: 100, Loss: 0.2819\n",
      "Epoch: 110, Loss: 0.2736\n",
      "Epoch: 120, Loss: 0.2665\n",
      "Epoch: 130, Loss: 0.2602\n",
      "Epoch: 140, Loss: 0.2548\n",
      "Epoch: 150, Loss: 0.2499\n",
      "Epoch: 160, Loss: 0.2456\n",
      "Epoch: 170, Loss: 0.2417\n",
      "auc_score = 0.589565573064669\n",
      "F1_score = 0.21359223300970873\n",
      "Recall = 0.22448979591836735\n",
      "Precision = 0.2037037037037037\n",
      "Epoch: 10, Loss: 0.6628\n",
      "Epoch: 20, Loss: 0.5945\n",
      "Epoch: 30, Loss: 0.5435\n",
      "Epoch: 40, Loss: 0.5039\n",
      "Epoch: 50, Loss: 0.4722\n",
      "Epoch: 60, Loss: 0.4463\n",
      "Epoch: 70, Loss: 0.4247\n",
      "Epoch: 80, Loss: 0.4064\n",
      "Epoch: 90, Loss: 0.3907\n",
      "Epoch: 100, Loss: 0.3771\n",
      "Epoch: 110, Loss: 0.3651\n",
      "Epoch: 120, Loss: 0.3545\n",
      "Epoch: 130, Loss: 0.3451\n",
      "Epoch: 140, Loss: 0.3366\n",
      "Epoch: 150, Loss: 0.3290\n",
      "Epoch: 160, Loss: 0.3220\n",
      "Epoch: 170, Loss: 0.3157\n",
      "Epoch: 180, Loss: 0.3099\n",
      "auc_score = 0.5875230593540453\n",
      "F1_score = 0.25\n",
      "Recall = 0.21621621621621623\n",
      "Precision = 0.2962962962962963\n",
      "Epoch: 10, Loss: 0.5363\n",
      "Epoch: 20, Loss: 0.4604\n",
      "Epoch: 30, Loss: 0.4136\n",
      "Epoch: 40, Loss: 0.3810\n",
      "Epoch: 50, Loss: 0.3566\n",
      "Epoch: 60, Loss: 0.3374\n",
      "Epoch: 70, Loss: 0.3220\n",
      "Epoch: 80, Loss: 0.3092\n",
      "Epoch: 90, Loss: 0.2984\n",
      "Epoch: 100, Loss: 0.2891\n",
      "Epoch: 110, Loss: 0.2811\n",
      "Epoch: 120, Loss: 0.2741\n",
      "Epoch: 130, Loss: 0.2680\n",
      "Epoch: 140, Loss: 0.2624\n",
      "Epoch: 150, Loss: 0.2575\n",
      "Epoch: 160, Loss: 0.2530\n",
      "Epoch: 170, Loss: 0.2490\n",
      "auc_score = 0.5809843695117667\n",
      "F1_score = 0.19607843137254902\n",
      "Recall = 0.20833333333333334\n",
      "Precision = 0.18518518518518517\n",
      "Epoch: 10, Loss: 0.7271\n",
      "Epoch: 20, Loss: 0.7108\n",
      "Epoch: 30, Loss: 0.6954\n",
      "Epoch: 40, Loss: 0.6809\n",
      "Epoch: 50, Loss: 0.6670\n",
      "Epoch: 60, Loss: 0.6539\n",
      "Epoch: 70, Loss: 0.6415\n",
      "Epoch: 80, Loss: 0.6297\n",
      "Epoch: 90, Loss: 0.6184\n",
      "auc_score = 0.5364312680435265\n",
      "F1_score = 0.17869415807560135\n",
      "Recall = 0.10970464135021098\n",
      "Precision = 0.48148148148148145\n",
      "Epoch: 10, Loss: 0.6945\n",
      "Epoch: 20, Loss: 0.5861\n",
      "Epoch: 30, Loss: 0.5183\n",
      "Epoch: 40, Loss: 0.4719\n",
      "Epoch: 50, Loss: 0.4378\n",
      "Epoch: 60, Loss: 0.4114\n",
      "Epoch: 70, Loss: 0.3902\n",
      "Epoch: 80, Loss: 0.3726\n",
      "Epoch: 90, Loss: 0.3579\n",
      "Epoch: 100, Loss: 0.3452\n",
      "Epoch: 110, Loss: 0.3343\n",
      "Epoch: 120, Loss: 0.3247\n",
      "Epoch: 130, Loss: 0.3162\n",
      "Epoch: 140, Loss: 0.3086\n",
      "Epoch: 150, Loss: 0.3018\n",
      "auc_score = 0.5829722355962125\n",
      "F1_score = 0.23140495867768596\n",
      "Recall = 0.208955223880597\n",
      "Precision = 0.25925925925925924\n",
      "Epoch: 10, Loss: 0.7148\n",
      "Epoch: 20, Loss: 0.6799\n",
      "Epoch: 30, Loss: 0.6492\n",
      "Epoch: 40, Loss: 0.6221\n",
      "Epoch: 50, Loss: 0.5979\n",
      "Epoch: 60, Loss: 0.5762\n",
      "Epoch: 70, Loss: 0.5567\n",
      "Epoch: 80, Loss: 0.5390\n",
      "auc_score = 0.5029942389326865\n",
      "F1_score = 0.09454545454545454\n",
      "Recall = 0.058823529411764705\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.5194\n",
      "Epoch: 20, Loss: 0.4327\n",
      "Epoch: 30, Loss: 0.3839\n",
      "Epoch: 40, Loss: 0.3519\n",
      "Epoch: 50, Loss: 0.3289\n",
      "auc_score = 0.5450891383294816\n",
      "F1_score = 0.15126050420168066\n",
      "Recall = 0.13846153846153847\n",
      "Precision = 0.16666666666666666\n",
      "Epoch: 10, Loss: 0.5255\n",
      "Epoch: 20, Loss: 0.4620\n",
      "Epoch: 30, Loss: 0.4184\n",
      "Epoch: 40, Loss: 0.3864\n",
      "Epoch: 50, Loss: 0.3620\n",
      "Epoch: 60, Loss: 0.3427\n",
      "Epoch: 70, Loss: 0.3270\n",
      "Epoch: 80, Loss: 0.3141\n",
      "Epoch: 90, Loss: 0.3031\n",
      "Epoch: 100, Loss: 0.2938\n",
      "Epoch: 110, Loss: 0.2857\n",
      "auc_score = 0.5644323933477946\n",
      "F1_score = 0.20155038759689925\n",
      "Recall = 0.17333333333333334\n",
      "Precision = 0.24074074074074073\n",
      "Epoch: 10, Loss: 0.6177\n",
      "Epoch: 20, Loss: 0.5061\n",
      "Epoch: 30, Loss: 0.4429\n",
      "Epoch: 40, Loss: 0.4006\n",
      "Epoch: 50, Loss: 0.3700\n",
      "Epoch: 60, Loss: 0.3467\n",
      "Epoch: 70, Loss: 0.3283\n",
      "Epoch: 80, Loss: 0.3133\n",
      "Epoch: 90, Loss: 0.3010\n",
      "Epoch: 100, Loss: 0.2906\n",
      "Epoch: 110, Loss: 0.2817\n",
      "Epoch: 120, Loss: 0.2741\n",
      "Epoch: 130, Loss: 0.2674\n",
      "Epoch: 140, Loss: 0.2615\n",
      "Epoch: 150, Loss: 0.2563\n",
      "Epoch: 160, Loss: 0.2516\n",
      "Epoch: 170, Loss: 0.2474\n",
      "Epoch: 180, Loss: 0.2436\n",
      "Epoch: 190, Loss: 0.2401\n",
      "auc_score = 0.589565573064669\n",
      "F1_score = 0.21359223300970873\n",
      "Recall = 0.22448979591836735\n",
      "Precision = 0.2037037037037037\n",
      "Epoch: 10, Loss: 0.6613\n",
      "Epoch: 20, Loss: 0.6148\n",
      "Epoch: 30, Loss: 0.5763\n",
      "Epoch: 40, Loss: 0.5439\n",
      "Epoch: 50, Loss: 0.5164\n",
      "Epoch: 60, Loss: 0.4926\n",
      "auc_score = 0.5546131191432396\n",
      "F1_score = 0.2236842105263158\n",
      "Recall = 0.136\n",
      "Precision = 0.6296296296296297\n",
      "Epoch: 10, Loss: 0.6882\n",
      "Epoch: 20, Loss: 0.6840\n",
      "Epoch: 30, Loss: 0.6799\n",
      "Epoch: 40, Loss: 0.6759\n",
      "Epoch: 50, Loss: 0.6720\n",
      "Epoch: 60, Loss: 0.6681\n",
      "Epoch: 70, Loss: 0.6643\n",
      "Epoch: 80, Loss: 0.6606\n",
      "Epoch: 90, Loss: 0.6569\n",
      "Epoch: 100, Loss: 0.6532\n",
      "Epoch: 110, Loss: 0.6496\n",
      "Epoch: 120, Loss: 0.6461\n",
      "Epoch: 130, Loss: 0.6426\n",
      "Epoch: 140, Loss: 0.6392\n",
      "Epoch: 150, Loss: 0.6359\n",
      "Epoch: 160, Loss: 0.6325\n",
      "Epoch: 170, Loss: 0.6293\n",
      "auc_score = 0.5263270733825445\n",
      "F1_score = 0.15384615384615383\n",
      "Recall = 0.09387755102040816\n",
      "Precision = 0.42592592592592593\n"
     ]
    }
   ],
   "source": [
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression,self).__init__()\n",
    "        self.linear=nn.Linear(n_input_features,1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "model=LogisticRegression(num_features)\n",
    "\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, learning_rate=0.01, num_epochs=100):\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    lossesLog=[]\n",
    "    for epoch in range(num_epochs):\n",
    "        y_predicted = model(X_train)\n",
    "        loss = criterion(y_predicted, y_train)        \n",
    "        loss.backward()        \n",
    "        optimizer.step()    \n",
    "        optimizer.zero_grad()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch: {epoch + 1}, Loss: {loss.item():.4f}\")\n",
    "        lossesLog.append(loss.item())\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        y_predicted = model(X_test)\n",
    "        y_predicted_cls = y_predicted.round()\n",
    "        return y_predicted_cls, lossesLog, y_predicted\n",
    "        \n",
    "num_trials = 100\n",
    "learning_rate_range = (0.001, 0.1)\n",
    "num_epochs_range = (50, 200)\n",
    "\n",
    "bestAUC = 0\n",
    "bestF1_score=0\n",
    "best_params = None\n",
    "result_arr=[]\n",
    "\n",
    "for _ in range(num_trials):\n",
    "    modeltemp = LogisticRegression(num_features)\n",
    "    learning_rate = np.random.uniform(*learning_rate_range)\n",
    "    num_epochs = np.random.randint(*num_epochs_range)\n",
    "    y_predicted_cls,_,_ = train_model(modeltemp, X_train, y_train, X_test, y_test, learning_rate, num_epochs)\n",
    "    eval = evaluateModel(y_predicted_cls,y_test)\n",
    "    auc = eval['roc_auc_score']\n",
    "    f1= eval['F1_score']\n",
    "    result_arr.append({'roc_auc_score' : auc,'F1_score':f1,'Learning Rate': learning_rate, 'Num Epochs': num_epochs})\n",
    "    if  auc > bestAUC and f1 > bestF1_score:\n",
    "        bestAUC = auc\n",
    "        bestF1_score=f1\n",
    "        best_params = {'Learning Rate': learning_rate, 'Num Epochs': num_epochs, 'roc_auc_score' : bestAUC,'F1_score':bestF1_score}\n",
    "        torch.save(model, './LogPredict.pth')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'roc_auc_score': 0.5488483783026319, 'F1_score': 0.20800000000000002, 'Learning Rate': 0.015897254792730096, 'Num Epochs': 152}\n",
      "{'roc_auc_score': 0.5787981651376147, 'F1_score': 0.26815642458100564, 'Learning Rate': 0.023433509804020217, 'Num Epochs': 132}\n",
      "{'roc_auc_score': 0.5902372296279975, 'F1_score': 0.23214285714285715, 'Learning Rate': 0.06013434959733099, 'Num Epochs': 163}\n",
      "{'roc_auc_score': 0.5503232533889469, 'F1_score': 0.20960698689956334, 'Learning Rate': 0.025111742664142428, 'Num Epochs': 52}\n",
      "{'roc_auc_score': 0.5555120439988861, 'F1_score': 0.21390374331550802, 'Learning Rate': 0.03483341531257046, 'Num Epochs': 119}\n",
      "{'roc_auc_score': 0.4952275249722531, 'F1_score': 0.07766990291262135, 'Learning Rate': 0.009646040079566192, 'Num Epochs': 57}\n",
      "{'roc_auc_score': 0.581412651174571, 'F1_score': 0.22950819672131148, 'Learning Rate': 0.05356410775625636, 'Num Epochs': 113}\n",
      "{'roc_auc_score': 0.5220270084056773, 'F1_score': 0.13852813852813853, 'Learning Rate': 0.04064175563671076, 'Num Epochs': 57}\n",
      "{'roc_auc_score': 0.48912499192349934, 'F1_score': 0.07648183556405354, 'Learning Rate': 0.0036364339623692643, 'Num Epochs': 64}\n",
      "{'roc_auc_score': 0.5626629422718809, 'F1_score': 0.21794871794871792, 'Learning Rate': 0.032084201010969454, 'Num Epochs': 190}\n",
      "{'roc_auc_score': 0.5621329757199321, 'F1_score': 0.1984732824427481, 'Learning Rate': 0.03178010934845021, 'Num Epochs': 178}\n",
      "{'roc_auc_score': 0.549303247507308, 'F1_score': 0.19161676646706588, 'Learning Rate': 0.04385268300008831, 'Num Epochs': 99}\n",
      "{'roc_auc_score': 0.5464468320727598, 'F1_score': 0.17567567567567569, 'Learning Rate': 0.06986396226845945, 'Num Epochs': 83}\n",
      "{'roc_auc_score': 0.545379149152734, 'F1_score': 0.19889502762430938, 'Learning Rate': 0.018639583911374685, 'Num Epochs': 88}\n",
      "{'roc_auc_score': 0.5773714790956171, 'F1_score': 0.24113475177304966, 'Learning Rate': 0.07904239718144995, 'Num Epochs': 57}\n",
      "{'roc_auc_score': 0.5256767087299195, 'F1_score': 0.152317880794702, 'Learning Rate': 0.013771826296245696, 'Num Epochs': 112}\n",
      "{'roc_auc_score': 0.5656276536558227, 'F1_score': 0.203125, 'Learning Rate': 0.07080807533129692, 'Num Epochs': 97}\n",
      "{'roc_auc_score': 0.5810840586096728, 'F1_score': 0.2142857142857143, 'Learning Rate': 0.07202110342777952, 'Num Epochs': 148}\n",
      "{'roc_auc_score': 0.5668549487042638, 'F1_score': 0.2047244094488189, 'Learning Rate': 0.08555192383432747, 'Num Epochs': 125}\n",
      "{'roc_auc_score': 0.5756006006006006, 'F1_score': 0.2222222222222222, 'Learning Rate': 0.042585168942383476, 'Num Epochs': 164}\n",
      "{'roc_auc_score': 0.53819382825594, 'F1_score': 0.16568047337278105, 'Learning Rate': 0.030754738988814073, 'Num Epochs': 143}\n",
      "{'roc_auc_score': 0.5519620884602594, 'F1_score': 0.20224719101123595, 'Learning Rate': 0.027677629017031847, 'Num Epochs': 179}\n",
      "{'roc_auc_score': 0.5675255322209436, 'F1_score': 0.2417582417582417, 'Learning Rate': 0.04350284209464669, 'Num Epochs': 54}\n",
      "{'roc_auc_score': 0.5149319520617509, 'F1_score': 0.12312811980033278, 'Learning Rate': 0.0026395308155043166, 'Num Epochs': 108}\n",
      "{'roc_auc_score': 0.5357480396738847, 'F1_score': 0.17721518987341772, 'Learning Rate': 0.02149451940605119, 'Num Epochs': 66}\n",
      "{'roc_auc_score': 0.5675255322209436, 'F1_score': 0.2417582417582417, 'Learning Rate': 0.046759475759009496, 'Num Epochs': 103}\n",
      "{'roc_auc_score': 0.5321162947937795, 'F1_score': 0.16783216783216784, 'Learning Rate': 0.018951969188642007, 'Num Epochs': 87}\n",
      "{'roc_auc_score': 0.5517384830968647, 'F1_score': 0.20430107526881722, 'Learning Rate': 0.02097209311546946, 'Num Epochs': 199}\n",
      "{'roc_auc_score': 0.49434678550796407, 'F1_score': 0.08438818565400844, 'Learning Rate': 0.0033134723124056244, 'Num Epochs': 146}\n",
      "{'roc_auc_score': 0.589565573064669, 'F1_score': 0.21359223300970873, 'Learning Rate': 0.0699738205767538, 'Num Epochs': 176}\n",
      "{'roc_auc_score': 0.5756006006006006, 'F1_score': 0.2222222222222222, 'Learning Rate': 0.08217853574231336, 'Num Epochs': 100}\n",
      "{'roc_auc_score': 0.5810840586096728, 'F1_score': 0.2142857142857143, 'Learning Rate': 0.08275900686593686, 'Num Epochs': 107}\n",
      "{'roc_auc_score': 0.5373995819998694, 'F1_score': 0.18120805369127518, 'Learning Rate': 0.021696598840704504, 'Num Epochs': 77}\n",
      "{'roc_auc_score': 0.5710345378957467, 'F1_score': 0.1869158878504673, 'Learning Rate': 0.08910623145086907, 'Num Epochs': 146}\n",
      "{'roc_auc_score': 0.5980555555555556, 'F1_score': 0.2698412698412698, 'Learning Rate': 0.0374657392313398, 'Num Epochs': 168}\n",
      "{'roc_auc_score': 0.5538322200837767, 'F1_score': 0.20571428571428574, 'Learning Rate': 0.07827801810585669, 'Num Epochs': 67}\n",
      "{'roc_auc_score': 0.5607650539930451, 'F1_score': 0.2181818181818182, 'Learning Rate': 0.06772044588678747, 'Num Epochs': 95}\n",
      "{'roc_auc_score': 0.5696212222074292, 'F1_score': 0.2594142259414226, 'Learning Rate': 0.009556689107969762, 'Num Epochs': 188}\n",
      "{'roc_auc_score': 0.5719308875913481, 'F1_score': 0.19642857142857142, 'Learning Rate': 0.058285908835588846, 'Num Epochs': 173}\n",
      "{'roc_auc_score': 0.5627777165730234, 'F1_score': 0.17857142857142858, 'Learning Rate': 0.06522299070498529, 'Num Epochs': 153}\n",
      "{'roc_auc_score': 0.5762069452286843, 'F1_score': 0.22900763358778628, 'Learning Rate': 0.08166928902725418, 'Num Epochs': 96}\n",
      "{'roc_auc_score': 0.5589029061668989, 'F1_score': 0.2266009852216749, 'Learning Rate': 0.06961641626447623, 'Num Epochs': 56}\n",
      "{'roc_auc_score': 0.5417788233774065, 'F1_score': 0.1920529801324503, 'Learning Rate': 0.022813918639779215, 'Num Epochs': 80}\n",
      "{'roc_auc_score': 0.5909617844579469, 'F1_score': 0.22429906542056074, 'Learning Rate': 0.08493517217784347, 'Num Epochs': 174}\n",
      "{'roc_auc_score': 0.5716413593637021, 'F1_score': 0.21705426356589147, 'Learning Rate': 0.07853674975654844, 'Num Epochs': 99}\n",
      "{'roc_auc_score': 0.5414769713578501, 'F1_score': 0.16774193548387098, 'Learning Rate': 0.03173951144781794, 'Num Epochs': 184}\n",
      "{'roc_auc_score': 0.4774388623072834, 'F1_score': 0.0749665327978581, 'Learning Rate': 0.0015365301768660287, 'Num Epochs': 102}\n",
      "{'roc_auc_score': 0.563146224763683, 'F1_score': 0.21476510067114096, 'Learning Rate': 0.037782405358433094, 'Num Epochs': 145}\n",
      "{'roc_auc_score': 0.5809981611768468, 'F1_score': 0.20560747663551404, 'Learning Rate': 0.09452175636677813, 'Num Epochs': 131}\n",
      "{'roc_auc_score': 0.5769932771575457, 'F1_score': 0.22399999999999998, 'Learning Rate': 0.08714422113197497, 'Num Epochs': 96}\n",
      "{'roc_auc_score': 0.5707427955000771, 'F1_score': 0.20967741935483872, 'Learning Rate': 0.08192514604099696, 'Num Epochs': 84}\n",
      "{'roc_auc_score': 0.5558104755106896, 'F1_score': 0.17094017094017092, 'Learning Rate': 0.032059364068738445, 'Num Epochs': 188}\n",
      "{'roc_auc_score': 0.5529379867889185, 'F1_score': 0.20118343195266275, 'Learning Rate': 0.03398514779550116, 'Num Epochs': 160}\n",
      "{'roc_auc_score': 0.5102829073417309, 'F1_score': 0.11693548387096774, 'Learning Rate': 0.0015483570449693102, 'Num Epochs': 165}\n",
      "{'roc_auc_score': 0.5717885240126815, 'F1_score': 0.24705882352941175, 'Learning Rate': 0.03842923533981781, 'Num Epochs': 76}\n",
      "{'roc_auc_score': 0.5668537151702787, 'F1_score': 0.2158273381294964, 'Learning Rate': 0.04351234251385646, 'Num Epochs': 146}\n",
      "{'roc_auc_score': 0.5767687434002112, 'F1_score': 0.1923076923076923, 'Learning Rate': 0.09474152418802238, 'Num Epochs': 129}\n",
      "{'roc_auc_score': 0.5888437822605397, 'F1_score': 0.25757575757575757, 'Learning Rate': 0.04967417555367775, 'Num Epochs': 115}\n",
      "{'roc_auc_score': 0.5867979154603359, 'F1_score': 0.2201834862385321, 'Learning Rate': 0.0458056746834299, 'Num Epochs': 177}\n",
      "{'roc_auc_score': 0.5784936998854524, 'F1_score': 0.25165562913907286, 'Learning Rate': 0.07743066302341262, 'Num Epochs': 74}\n",
      "{'roc_auc_score': 0.5396137150660879, 'F1_score': 0.18604651162790697, 'Learning Rate': 0.01496134402630149, 'Num Epochs': 99}\n",
      "{'roc_auc_score': 0.5656897491821156, 'F1_score': 0.208955223880597, 'Learning Rate': 0.07160444257989762, 'Num Epochs': 123}\n",
      "{'roc_auc_score': 0.5605994870904919, 'F1_score': 0.2209302325581395, 'Learning Rate': 0.05217885135707903, 'Num Epochs': 84}\n",
      "{'roc_auc_score': 0.5771168920665002, 'F1_score': 0.25316455696202533, 'Learning Rate': 0.048314398156993836, 'Num Epochs': 88}\n",
      "{'roc_auc_score': 0.5620327605777135, 'F1_score': 0.2235294117647059, 'Learning Rate': 0.019831918971597924, 'Num Epochs': 187}\n",
      "{'roc_auc_score': 0.5510034534436697, 'F1_score': 0.19108280254777069, 'Learning Rate': 0.0777269894679485, 'Num Epochs': 86}\n",
      "{'roc_auc_score': 0.5704861428702095, 'F1_score': 0.2571428571428571, 'Learning Rate': 0.026383453841210693, 'Num Epochs': 164}\n",
      "{'roc_auc_score': 0.5397231971017775, 'F1_score': 0.1714285714285714, 'Learning Rate': 0.037235695586961395, 'Num Epochs': 81}\n",
      "{'roc_auc_score': 0.5788503253796095, 'F1_score': 0.23255813953488372, 'Learning Rate': 0.048492304686709994, 'Num Epochs': 172}\n",
      "{'roc_auc_score': 0.5231350074299167, 'F1_score': 0.1441048034934498, 'Learning Rate': 0.006018245878202655, 'Num Epochs': 57}\n",
      "{'roc_auc_score': 0.5719308875913481, 'F1_score': 0.19642857142857142, 'Learning Rate': 0.09180594784883003, 'Num Epochs': 136}\n",
      "{'roc_auc_score': 0.5549275022166588, 'F1_score': 0.18840579710144928, 'Learning Rate': 0.07534332675606441, 'Num Epochs': 109}\n",
      "{'roc_auc_score': 0.5637116481129514, 'F1_score': 0.23204419889502764, 'Learning Rate': 0.02309685040878152, 'Num Epochs': 104}\n",
      "{'roc_auc_score': 0.5729261222218969, 'F1_score': 0.21875, 'Learning Rate': 0.07991342442672898, 'Num Epochs': 118}\n",
      "{'roc_auc_score': 0.5862611784883008, 'F1_score': 0.26388888888888884, 'Learning Rate': 0.0953952451253943, 'Num Epochs': 59}\n",
      "{'roc_auc_score': 0.5749719146204462, 'F1_score': 0.21487603305785125, 'Learning Rate': 0.07984118197858144, 'Num Epochs': 116}\n",
      "{'roc_auc_score': 0.5775880469583778, 'F1_score': 0.2105263157894737, 'Learning Rate': 0.08532525582922147, 'Num Epochs': 150}\n",
      "{'roc_auc_score': 0.5329287758696609, 'F1_score': 0.17006802721088435, 'Learning Rate': 0.021081788787370444, 'Num Epochs': 67}\n",
      "{'roc_auc_score': 0.5578670009164914, 'F1_score': 0.19259259259259257, 'Learning Rate': 0.06802460963585669, 'Num Epochs': 106}\n",
      "{'roc_auc_score': 0.5682459677419355, 'F1_score': 0.25233644859813087, 'Learning Rate': 0.04301542125924118, 'Num Epochs': 78}\n",
      "{'roc_auc_score': 0.582922732362822, 'F1_score': 0.21621621621621623, 'Learning Rate': 0.08038794508581579, 'Num Epochs': 145}\n",
      "{'roc_auc_score': 0.5669715936446799, 'F1_score': 0.1983471074380165, 'Learning Rate': 0.051384186200386005, 'Num Epochs': 179}\n",
      "{'roc_auc_score': 0.5784250269687162, 'F1_score': 0.22580645161290322, 'Learning Rate': 0.0813916771347611, 'Num Epochs': 102}\n",
      "{'roc_auc_score': 0.5634291940745494, 'F1_score': 0.24369747899159666, 'Learning Rate': 0.045625123121580104, 'Num Epochs': 51}\n",
      "{'roc_auc_score': 0.5608944036096355, 'F1_score': 0.20689655172413796, 'Learning Rate': 0.08024381616986967, 'Num Epochs': 91}\n",
      "{'roc_auc_score': 0.5644323933477946, 'F1_score': 0.20155038759689925, 'Learning Rate': 0.0624210831979025, 'Num Epochs': 131}\n",
      "{'roc_auc_score': 0.5442627929341498, 'F1_score': 0.18750000000000003, 'Learning Rate': 0.028213069169787802, 'Num Epochs': 64}\n",
      "{'roc_auc_score': 0.5851644471347861, 'F1_score': 0.27710843373493976, 'Learning Rate': 0.03520708390467898, 'Num Epochs': 121}\n",
      "{'roc_auc_score': 0.5675255322209436, 'F1_score': 0.2417582417582417, 'Learning Rate': 0.01781282890766953, 'Num Epochs': 163}\n",
      "{'roc_auc_score': 0.589565573064669, 'F1_score': 0.21359223300970873, 'Learning Rate': 0.09305929461134355, 'Num Epochs': 178}\n",
      "{'roc_auc_score': 0.5875230593540453, 'F1_score': 0.25, 'Learning Rate': 0.037799142131008406, 'Num Epochs': 184}\n",
      "{'roc_auc_score': 0.5809843695117667, 'F1_score': 0.19607843137254902, 'Learning Rate': 0.08517919791973626, 'Num Epochs': 171}\n",
      "{'roc_auc_score': 0.5364312680435265, 'F1_score': 0.17869415807560135, 'Learning Rate': 0.006559208035390725, 'Num Epochs': 91}\n",
      "{'roc_auc_score': 0.5829722355962125, 'F1_score': 0.23140495867768596, 'Learning Rate': 0.046674885164292176, 'Num Epochs': 159}\n",
      "{'roc_auc_score': 0.5029942389326865, 'F1_score': 0.09454545454545454, 'Learning Rate': 0.01493781894791956, 'Num Epochs': 81}\n",
      "{'roc_auc_score': 0.5450891383294816, 'F1_score': 0.15126050420168066, 'Learning Rate': 0.09393014518443729, 'Num Epochs': 55}\n",
      "{'roc_auc_score': 0.5644323933477946, 'F1_score': 0.20155038759689925, 'Learning Rate': 0.07462043361217428, 'Num Epochs': 110}\n",
      "{'roc_auc_score': 0.589565573064669, 'F1_score': 0.21359223300970873, 'Learning Rate': 0.08864122198316421, 'Num Epochs': 197}\n",
      "{'roc_auc_score': 0.5546131191432396, 'F1_score': 0.2236842105263158, 'Learning Rate': 0.024933286351316815, 'Num Epochs': 68}\n",
      "{'roc_auc_score': 0.5263270733825445, 'F1_score': 0.15384615384615383, 'Learning Rate': 0.0015618454955540944, 'Num Epochs': 173}\n",
      "Best parameters found: Learning rate =0.0374657392313398, Number of epochs =168, accuracy = 0.8996990972918756\n",
      "-------------------Train model with best parameter-------------------------------------\n",
      "Epoch: 10, Loss: 0.6131\n",
      "Epoch: 20, Loss: 0.5584\n",
      "Epoch: 30, Loss: 0.5163\n",
      "Epoch: 40, Loss: 0.4828\n",
      "Epoch: 50, Loss: 0.4553\n",
      "Epoch: 60, Loss: 0.4323\n",
      "Epoch: 70, Loss: 0.4127\n",
      "Epoch: 80, Loss: 0.3958\n",
      "Epoch: 90, Loss: 0.3812\n",
      "Epoch: 100, Loss: 0.3684\n",
      "Epoch: 110, Loss: 0.3570\n",
      "Epoch: 120, Loss: 0.3469\n",
      "Epoch: 130, Loss: 0.3379\n",
      "Epoch: 140, Loss: 0.3297\n",
      "Epoch: 150, Loss: 0.3224\n",
      "Epoch: 160, Loss: 0.3157\n"
     ]
    }
   ],
   "source": [
    "for result in result_arr:\n",
    "    print(result)\n",
    "if best_params != None:\n",
    "    print(f\"Best parameters found: Learning rate ={best_params['Learning Rate']}, Number of epochs ={best_params['Num Epochs']}, accuracy = {best_accuracy}\")\n",
    "    print(\"-------------------Train model with best parameter-------------------------------------\")\n",
    "    model.model = torch.load('./LogPredict.pth')\n",
    "    YResult,lossesLog,y_predicted_Log=train_model(model,X_train,y_train,X_test,y_test,best_params['Learning Rate'],best_params['Num Epochs'])\n",
    "else:\n",
    "    print(\"-------------------Train model without best parameter-------------------------------------\")\n",
    "    YResult,lossesLog,y_predicted_Log=train_model(model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tạo ma trận nhầm lẫn\n",
    "cm = confusion_matrix(YResult, y_test)\n",
    "\n",
    "# Tạo heatmap từ ma trận nhầm lẫn\n",
    "plt.figure(figsize=(5, 4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix without DP (Logistic Regression)')\n",
    "plt.savefig('../static/app/images/ConfusionMatrixLogBefore.JPG')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.6073210007462393\n",
      "F1_score = 0.21768707482993196\n",
      "Recall = 0.2962962962962963\n",
      "Precision = 0.17204301075268819\n"
     ]
    }
   ],
   "source": [
    "# Chuyển đổi kết quả dự đoán thành numpy array để sử dụng với các hàm tính toán từ sklearn.metrics\n",
    "YResult1 = YResult.cpu().numpy()\n",
    "logResult=evaluateModel(y_test,YResult1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Mô hình Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "class DecisionTreeModel:\n",
    "    def __init__(self, x_train, y_train, max_depth=None, min_samples_split=2, min_samples_leaf=1, random_state=None, criterion=\"entropy\"):\n",
    "        self.x_train = x_train\n",
    "        self.y_train = y_train\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_split = min_samples_split\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.random_state = random_state\n",
    "        self.criterion = criterion\n",
    "        self.model = None\n",
    "\n",
    "    def train(self):\n",
    "        self._train_with_random_search()\n",
    "    def _train_with_random_search(self):\n",
    "        param_dist = {\n",
    "            'max_depth': [2, 3, 5, 7,9,10],\n",
    "            'min_samples_leaf': [5, 10, 20, 50, 100],\n",
    "            'criterion': [\"gini\", \"entropy\"],\n",
    "            'min_samples_split': [2,4, 5,6, 10]\n",
    "        }\n",
    "\n",
    "        dt_classifier = DecisionTreeClassifier()\n",
    "        scorer = make_scorer(f1_score)\n",
    "        random_search = RandomizedSearchCV(\n",
    "            dt_classifier, param_distributions=param_dist, n_iter=50, cv=5, scoring=scorer, random_state=42)\n",
    "\n",
    "        random_search.fit(self.x_train, self.y_train)\n",
    "\n",
    "        self.model = random_search.best_estimator_\n",
    "        # In ra thông tin về siêu tham số tốt nhất\n",
    "        print(\"Best Parameters:\", random_search.best_params_)\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.model.predict(x_test)\n",
    "\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "\n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "\n",
    "    def get_model_parameters(self):\n",
    "        return self.model.get_params()\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        y_pred = self.predict(x_test)\n",
    "        # Tạo ma trận nhầm lẫn\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        # Tạo heatmap từ ma trận nhầm lẫn\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix (Decision Tree)')\n",
    "        plt.savefig('../static/app/images/ConfusionMatrixDec.JPG')\n",
    "        plt.show()\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'min_samples_split': 2, 'min_samples_leaf': 5, 'max_depth': 9, 'criterion': 'entropy'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.544666352460626\n",
      "F1_score = 0.1414141414141414\n",
      "Recall = 0.12962962962962962\n",
      "Precision = 0.15555555555555556\n"
     ]
    }
   ],
   "source": [
    "modelDec = DecisionTreeModel(X_train,y_train)\n",
    "modelDec.train()\n",
    "yResultDes=modelDec.evaluate(X_test,y_test)\n",
    "DesResult=evaluateModel(y_test,yResultDes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Mô hình Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "class RandomForestModel:\n",
    "    def __init__(self, n_estimators=100, max_depth=None, random_state=None):\n",
    "        self.model = RandomForestClassifier(n_estimators=n_estimators,\n",
    "                                            max_depth=max_depth,\n",
    "                                            random_state=random_state)\n",
    "        self.is_trained = False\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model has not been trained yet. Please train the model before making predictions.\")\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model has not been trained yet. Please train the model before evaluation.\")\n",
    "        y_pred = self.predict(X_test)\n",
    "        # Tạo ma trận nhầm lẫn\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        # Tạo heatmap từ ma trận nhầm lẫn\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix (Randomforest)')\n",
    "        plt.savefig('../static/app/images/ConfusionMatrixRand.JPG')\n",
    "        plt.show()\n",
    "        return y_pred\n",
    "\n",
    "    def get_feature_importance(self):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model has not been trained yet. Please train the model before getting feature importances.\")\n",
    "        return self.model.feature_importances_\n",
    "    \n",
    "    def random_search(self, X_train, y_train, param_dist, cv=5, n_iter=50, random_state=42):\n",
    "        random_search = RandomizedSearchCV(self.model, param_dist, cv=cv, n_iter=n_iter, random_state=random_state)\n",
    "        random_search.fit(X_train, y_train)\n",
    "        self.model = random_search.best_estimator_\n",
    "        self.is_trained = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:305: UserWarning: The total space of parameters 12 is smaller than n_iter=50. Running 12 iterations. For exhaustive searches, use GridSearchCV.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5110954008090804\n",
      "F1_score = 0.05714285714285714\n",
      "Recall = 0.037037037037037035\n",
      "Precision = 0.125\n"
     ]
    }
   ],
   "source": [
    "param_dist = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "modelRand = RandomForestModel()\n",
    "modelRand.random_search(X_train, y_train.ravel(), param_dist)\n",
    "yResultRand= modelRand.evaluate(X_test,y_test.ravel())\n",
    "RandResult = evaluateModel(y_test,yResultRand)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Mô hình Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "class NaiveBayesModel:\n",
    "    def __init__(self):\n",
    "        self.model = GaussianNB()\n",
    "        self.is_trained = False\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model has not been trained yet. Please train the model before making predictions.\")\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model has not been trained yet. Please train the model before evaluation.\")\n",
    "\n",
    "        y_pred = self.predict(X_test)\n",
    "        # Tạo ma trận nhầm lẫn\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        # Tạo heatmap từ ma trận nhầm lẫn\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix (Naive)')\n",
    "        plt.savefig('../static/app/images/ConfusionMatrixNaive.JPG')\n",
    "        plt.show()\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.6375535132162917\n",
      "F1_score = 0.17575757575757575\n",
      "Recall = 0.5370370370370371\n",
      "Precision = 0.10507246376811594\n"
     ]
    }
   ],
   "source": [
    "modelNaive = NaiveBayesModel()\n",
    "modelNaive.train(X_train,y_train)\n",
    "yResultNaive = modelNaive.evaluate(X_test,y_test)\n",
    "NaiveResult = evaluateModel(y_test,yResultNaive)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### V. So sánh và đánh giá các mô hình"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 30000x2000 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Đặt tên cho các model (có thể là tên của các biến chứa kết quả)\n",
    "model_names = ['LogR', 'DecTree', 'Rand', 'Naive']\n",
    "\n",
    "# Kết quả của hàm evaluateModel cho từng model\n",
    "results = [\n",
    "    logResult,DesResult,RandResult,NaiveResult\n",
    "]\n",
    "\n",
    "# Tạo DataFrame từ kết quả\n",
    "df_results = pd.DataFrame(results, index=model_names)\n",
    "\n",
    "# Vẽ biểu đồ\n",
    "plt.figure(figsize=(300, 20))\n",
    "df_results.plot(kind='bar', rot=0, colormap='viridis', width=0.5)\n",
    "plt.title('Comparison of Evaluation Metrics Across Models')\n",
    "plt.xlabel('Models')\n",
    "plt.ylabel('Score')\n",
    "plt.savefig(\"../static/app/images/ModelScoreWithoutDP.jpg\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------------------+----------------------+---------------------+\n",
      "|         |   roc_auc_score    |      F1_score       |        Recall        |      Precision      |\n",
      "+---------+--------------------+---------------------+----------------------+---------------------+\n",
      "|  LogR   | 0.6073210007462393 | 0.21768707482993196 |  0.2962962962962963  | 0.17204301075268819 |\n",
      "| DecTree | 0.544666352460626  | 0.1414141414141414  | 0.12962962962962962  | 0.15555555555555556 |\n",
      "|  Rand   | 0.5110954008090804 | 0.05714285714285714 | 0.037037037037037035 |        0.125        |\n",
      "|  Naive  | 0.6375535132162917 | 0.17575757575757575 |  0.5370370370370371  | 0.10507246376811594 |\n",
      "+---------+--------------------+---------------------+----------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "from tabulate import tabulate\n",
    "table = tabulate(df_results, headers='keys', tablefmt='pretty', showindex=True)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VI. So sánh 2 mô hình tiềm năng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predicted_Log)\n",
    "\n",
    "# Tính AUC\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Vẽ đường ROC\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (LogistcR)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"../static/app/images/ROCLogisticRegression.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkIAAAHHCAYAAABTMjf2AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACVvUlEQVR4nOzdd3xN5x/A8U8SmWQRMUPsPWOv2EGrqBq1FbVbq6092qItrdGq1RKUn91StUqNIqWNvaJEagYxsmTIvc/vj8PlSkJCkpPxfb9eXs55nnPu/ebeJPeb53zP81gopRRCCCGEEFmQpd4BCCGEEELoRRIhIYQQQmRZkggJIYQQIsuSREgIIYQQWZYkQkIIIYTIsiQREkIIIUSWJYmQEEIIIbIsSYSEEEIIkWVJIiSEEEKILEsSIZGheHp60qtXL73DyHIaNmxIw4YN9Q7jpSZPnoyFhQUhISF6h5LuWFhYMHny5BR5rKCgICwsLPD19U2RxwM4cuQINjY2/Pfffyn2mIlJjfhfx927d8mePTtbt27VO5QsSRIhYeLr64uFhYXpX7Zs2ShQoAC9evXi+vXreoeXrkVGRvLZZ59RsWJFHBwccHZ2pn79+ixfvpyMsorN2bNnmTx5MkFBQXqHEo/BYGDp0qU0bNiQnDlzYmtri6enJ7179+aff/7RO7wUsWrVKmbPnq13GGbSMqZx48bx7rvvUrhwYVNbw4YNsbCwoHXr1vGOf5LMzJw5M03iS67nf59aWFjg7u5Oo0aN2LZtm9mxuXLlom/fvkyYMEGnaLO2bHoHINKfTz/9lCJFihAdHc1ff/2Fr68vBw4c4PTp09jZ2ekaW0BAAJaW6St/v3XrFk2aNOHcuXN07tyZIUOGEB0dzYYNG+jZsydbt25l5cqVWFlZ6R3qC509e5YpU6bQsGFDPD09zfp27typT1BAVFQUb7/9Ntu3b6dBgwaMHTuWnDlzEhQUxNq1a1m2bBlXrlyhYMGCusWYElatWsXp06cZNmxYqjx+VFQU2bIl71d+YjEVLlyYqKgorK2tUyS248ePs2vXLg4dOpRg/5YtW/D398fLyytFni+l43+RJ79PlVLcunULX19fWrVqxa+//sqbb75pOm7AgAHMnTuXP/74g8aNG6d6XOIpSYREPC1btqRatWoA9O3bFzc3N7788ks2b95Mx44ddY3N1tY2zZ8zOjoaGxubRBOwnj17cu7cOX7++WfeeustU/sHH3zARx99xMyZM6lSpQqffPJJWoUMaKNU2bNnT5HHsrGxSZHHeRUfffQR27dvZ9asWfE+kCdNmsSsWbPSNB6lFNHR0djb26fp874Ko9FIbGwsdnZ2KfpHjIWFRYo+3tKlSylUqBC1atWK11eoUCHCw8OZMmUKmzdvTpHnS+n4X+TZ36cAffr0IU+ePPzvf/8zS4TKlClD+fLl8fX1lUQojaWvP61FulS/fn0ALl26ZNZ+/vx53nnnHXLmzImdnR3VqlVL8BfVgwcPGD58OJ6entja2lKwYEF69OhhVscRExPDpEmTKF68OLa2tnh4ePDxxx8TExNj9ljP1gj9888/WFhYsGzZsnjPuWPHDiwsLNiyZYup7fr167z33nvkyZMHW1tbypUrx5IlS8zO27t3LxYWFqxevZrx48dToEABHBwcCAsLS/C1+euvv9ixYwe9evUyS4KemD59OiVKlODLL78kKioKMB/SnzVrFoULF8be3h5vb29Onz4d7zGS8jo/GYbft28fgwYNwt3d3TRC8t9//zFo0CBKlSqFvb09uXLlokOHDmaXwHx9fenQoQMAjRo1Mg3l7927F4hfI/TkdVq7di1Tp06lYMGC2NnZ0aRJEy5evBjva5g3bx5FixbF3t6eGjVq8Oeffyap7ujatWssXLiQZs2aJThSYmVlxahRo+KNBj148IBevXrh4uKCs7MzvXv35uHDh2bHLF26lMaNG+Pu7o6trS1ly5Zl/vz58Z7D09OTN998kx07dlCtWjXs7e1ZuHBhsh4DYNu2bXh7e+Po6IiTkxPVq1dn1apVgPb6/vbbb/z333+m1/7ZUbmk/nxYWFgwZMgQVq5cSbly5bC1tWX79u2mvmdrhMLDwxk2bJjp59Ld3Z1mzZpx9OjRl8aUWI3N+fPn6dixI7lz58be3p5SpUoxbty4BF+PZ/3yyy80btwYCwuLeH2Ojo4MHz6cX3/91RRbYu7du8eoUaOoUKECOXLkwMnJiZYtW3LixAmz456Pf+bMmVhYWCRYnzRmzBhsbGy4f/++qe3w4cO0aNECZ2dnHBwc8Pb25uDBgy/9OgFcXFywt7dPcHSuWbNm/PrrrxnmcnpmISNC4qWefGC6urqa2s6cOUPdunUpUKAAo0ePJnv27Kxdu5a2bduyYcMG2rVrB0BERAT169fn3LlzvPfee1StWpWQkBA2b97MtWvXcHNzw2g08tZbb3HgwAHef/99ypQpw6lTp5g1axYXLlzgl19+STCuatWqUbRoUdauXUvPnj3N+tasWYOrqys+Pj6AdvmqVq1apg+K3Llzs23bNvr06UNYWFi8D9nPPvsMGxsbRo0aRUxMTKIjIr/++isAPXr0SLA/W7ZsdOnShSlTpnDw4EGaNm1q6lu+fDnh4eEMHjyY6Oho5syZQ+PGjTl16hR58uRJ1uv8xKBBg8idOzcTJ04kMjISgL///ptDhw7RuXNnChYsSFBQEPPnz6dhw4acPXsWBwcHGjRowAcffMDcuXMZO3YsZcqUATD9n5gvvvgCS0tLRo0aRWhoKF999RVdu3bl8OHDpmPmz5/PkCFDqF+/PsOHDycoKIi2bdvi6ur60stZ27ZtIy4uju7du7/wuOd17NiRIkWKMH36dI4ePcoPP/yAu7s7X375pVlc5cqV46233iJbtmz8+uuvDBo0CKPRyODBg80eLyAggHfffZf+/fvTr18/SpUqlazH8PX15b333qNcuXKMGTMGFxcXjh07xvbt2+nSpQvjxo0jNDSUa9eumUa4cuTIAZDsn48//viDtWvXMmTIENzc3OJd5nxiwIABrF+/niFDhlC2bFnu3r3LgQMHOHfuHFWrVn1hTAk5efIk9evXx9ramvfffx9PT08uXbrEr7/+ytSpUxM97/r161y5coWqVasmesyHH37IrFmzmDx58gtHhQIDA/nll1/o0KEDRYoU4datWyxcuBBvb2/Onj1L/vz5EzyvY8eOfPzxx6xdu5aPPvrIrG/t2rU0b97c9Pvvjz/+oGXLlnh5eTFp0iQsLS1NCfGff/5JjRo1zM4PDQ0lJCQEpRS3b9/m22+/JSIigm7dusWLw8vLi1mzZnHmzBnKly+f6NcpUpgS4rGlS5cqQO3atUvduXNHXb16Va1fv17lzp1b2draqqtXr5qObdKkiapQoYKKjo42tRmNRlWnTh1VokQJU9vEiRMVoDZu3Bjv+YxGo1JKqRUrVihLS0v1559/mvUvWLBAAergwYOmtsKFC6uePXua9seMGaOsra3VvXv3TG0xMTHKxcVFvffee6a2Pn36qHz58qmQkBCz5+jcubNydnZWDx8+VEoptWfPHgWookWLmtpepG3btgpQ9+/fT/SYjRs3KkDNnTtXKaXU5cuXFaDs7e3VtWvXTMcdPnxYAWr48OGmtqS+zk/eu3r16qm4uDiz50/o6/Dz81OAWr58ualt3bp1ClB79uyJd7y3t7fy9vY27T95ncqUKaNiYmJM7XPmzFGAOnXqlFJKey9y5cqlqlevrh49emQ6ztfXVwFmj5mQ4cOHK0AdO3bshcc9MWnSJAWYvfdKKdWuXTuVK1cus7aEXhcfHx9VtGhRs7bChQsrQG3fvj3e8Ul5jAcPHihHR0dVs2ZNFRUVZXbsk58BpZR64403VOHCheM9XnJ+PgBlaWmpzpw5E+9xADVp0iTTvrOzsxo8eHC8456VWExPvoeXLl1qamvQoIFydHRU//33X6JfY0J27dqlAPXrr7/G6/P29lblypVTSik1ZcoUBSh/f3+zGGbMmGE6Pjo6WhkMhnix2traqk8//fSF8deuXVt5eXmZnXvkyBGznxOj0ahKlCihfHx8zL6uhw8fqiJFiqhmzZqZ2p78TD7/z9bWVvn6+ib4Whw6dEgBas2aNS98zUTKkktjIp6mTZuSO3duPDw8eOedd8iePTubN282/fV+7949/vjjDzp27Eh4eDghISGEhIRw9+5dfHx8+Pfff013mW3YsIFKlSrFG7kATMPg69ato0yZMpQuXdr0WCEhIabr5Hv27Ek01k6dOvHo0SM2btxoatu5cycPHjygU6dOgFbTsWHDBlq3bo1Syuw5fHx8CA0NjTfk3rNnzyTVgISHhwPa8H1invQ9f3mtbdu2FChQwLRfo0YNatasabqFNjmv8xP9+vWLV5T97Nfx6NEj7t69S/HixXFxcXnppYaX6d27t9lo2ZPLqIGBgYB2+fLu3bv069fP7FJA165dzUYYE/PkNXvR65uQAQMGmO3Xr1+fu3fvmr0Hz74uT/5q9/b2JjAwkNDQULPzixQpYhpdfFZSHuP3338nPDyc0aNHx6tLSehS0POS+/Ph7e1N2bJlX/q4Li4uHD58mBs3brz02Je5c+cO+/fv57333qNQoUJmfS/7Gu/evQvw0u+HDz/8EFdXV6ZMmZLoMba2tqZaPoPBwN27d8mRIwelSpV66fd6p06d8Pf3NysBWLNmDba2trRp0wbQirr//fdfunTpwt27d03vRWRkJE2aNGH//v0YjUazx503bx6///47v//+Oz/99BONGjWib9++Zr+znnjyGsj0D2lLLo2JeObNm0fJkiUJDQ1lyZIl7N+/36xI+eLFiyilmDBhQqK3e96+fZsCBQpw6dIl2rdv/8Ln+/fffzl37hy5c+dO9LESU6lSJUqXLs2aNWvo06cPoP3ycnNzM31Q3LlzhwcPHrBo0SIWLVqUpOcoUqTIC2N+4skHdHh4OC4uLgkek1iyVKJEiXjHlixZkrVr1wLJe51fFHdUVBTTp09n6dKlXL9+3az+4PkP/OR6/kPvyS/yJ/UUT2ouihcvbnZctmzZEr1k8ywnJyfg6WuYEnE9ecyDBw8yadIk/Pz84tUPhYaG4uzsbNpP7PshKY/x5IP1VS91JPfnI6nfu1999RU9e/bEw8MDLy8vWrVqRY8ePShatGiyY3yS+L7O5Rz1kroYZ2dnhg0bxqRJkzh27FiCiZPRaGTOnDl8//33XL58GYPBYOrLlSvXCx+/Q4cOjBgxgjVr1jB27FiUUqxbt46WLVuavmf+/fdfgHiX4p8VGhpqFluNGjXMiqXfffddqlSpwpAhQ3jzzTfN/pB48hokJUEWKUcSIRHPsz+4bdu2pV69enTp0oWAgABy5Mhh+otn1KhRCf6VDPE/+F7EaDRSoUIFvvnmmwT7PTw8Xnh+p06dmDp1KiEhITg6OrJ582beffdd0wjEk3i7deuW6C+wihUrmu0n9Y6gMmXK8Msvv3Dy5EkaNGiQ4DEnT54ESNJf6c96ldc5obiHDh3K0qVLGTZsGLVr18bZ2RkLCws6d+4c76/X5EpsSoCXfaglVenSpQE4deoUlStXTvJ5L4vr0qVLNGnShNKlS/PNN9/g4eGBjY0NW7duZdasWfFel4Re1+Q+xqtK7s9HUr93O3bsSP369fn555/ZuXMnM2bM4Msvv2Tjxo20bNnyteNOqicJyrPFyIl5Uis0ZcqUBOc3mjZtGhMmTOC9997js88+I2fOnFhaWjJs2LCXvh/58+enfv36rF27lrFjx/LXX39x5coVs7qyJ48xY8aMRL8fX1RHBWBpaUmjRo2YM2cO//77L+XKlTP1PXkN3NzcXvgYImVJIiReyMrKiunTp9OoUSO+++47Ro8ebfqL0dra2qz4NyHFihVL8E6o5485ceIETZo0eaW/hDp16sSUKVPYsGEDefLkISwsjM6dO5v6c+fOjaOjIwaD4aXxJtebb77J9OnTWb58eYKJkMFgYNWqVbi6ulK3bl2zvid/XT7rwoULppGS5LzOL7J+/Xp69uzJ119/bWqLjo7mwYMHZselxl+hTybHu3jxIo0aNTK1x8XFERQUFC8BfV7Lli2xsrLip59+SnbB9Iv8+uuvxMTEsHnzZrPRoxddhn3VxyhWrBgAp0+ffuEfCIm9/q/78/Ei+fLlY9CgQQwaNIjbt29TtWpVpk6dakqEkvp8T75XX/aznpAnye7ly5dfeuyTUaHJkycn+EfN+vXradSoET/++KNZ+4MHD5KUXHTq1IlBgwYREBDAmjVrcHBwMJvM8cl76eTk9Fo/k3FxcYB2M8mznrwGL7tJQaQsqRESL9WwYUNq1KjB7NmziY6Oxt3dnYYNG7Jw4UJu3rwZ7/g7d+6Yttu3b8+JEyf4+eef4x335K/zjh07cv36dRYvXhzvmKioKNPdT4kpU6YMFSpUYM2aNaxZs4Z8+fKZJSVWVla0b9+eDRs2JPiL+tl4k6tOnTo0bdqUpUuXmt2q/8S4ceO4cOECH3/8cby/1H/55RezGp8jR45w+PBh04dQcl7nF7Gysoo3QvPtt9+aXTYATHMOPZ8gvY5q1aqRK1cuFi9ebPrlD7By5cokjQB4eHjQr18/du7cybfffhuv32g08vXXX3Pt2rVkxfVkxOj5y4RLly5N8cdo3rw5jo6OTJ8+nejoaLO+Z8/Nnj17gpcqX/fnIyEGgyHec7m7u5M/f36zW/ITi+l5uXPnpkGDBixZsoQrV66Y9b1sdLBAgQJ4eHgkeYbwYcOG4eLiwqeffhqvL6Hv9XXr1iV5Zvz27dtjZWXF//73P9atW8ebb75pNheXl5cXxYoVY+bMmfGSGEjaz+SjR4/YuXMnNjY28RIef39/nJ2dzUaJROqTESGRJB999BEdOnTA19eXAQMGMG/ePOrVq0eFChXo168fRYsW5datW/j5+XHt2jXTvB0fffQR69evp0OHDrz33nt4eXlx7949Nm/ezIIFC6hUqRLdu3dn7dq1DBgwgD179lC3bl0MBgPnz59n7dq1pvlbXqRTp05MnDgROzs7+vTpE2/ywy+++II9e/ZQs2ZN+vXrR9myZbl37x5Hjx5l165d3Lt375Vfm+XLl9OkSRPatGlDly5dqF+/PjExMWzcuJG9e/fSqVOneLfkgnZZq169egwcOJCYmBhmz55Nrly5+Pjjj03HJPV1fpE333yTFStW4OzsTNmyZfHz82PXrl3xaiYqV66MlZUVX375JaGhodja2prmyHlVNjY2TJ48maFDh9K4cWM6duxIUFAQvr6+FCtWLEkjDl9//TWXLl3igw8+YOPGjbz55pu4urpy5coV1q1bx/nz581GAJOiefPm2NjY0Lp1a/r3709ERASLFy/G3d09waTzdR7DycmJWbNm0bdvX6pXr06XLl1wdXXlxIkTPHz40DQPlpeXF2vWrGHEiBFUr16dHDly0Lp16xT5+XheeHg4BQsW5J133qFSpUrkyJGDXbt28ffff5uNHCYWU0Lmzp1LvXr1qFq1Ku+//z5FihQhKCiI3377jePHj78wnjZt2vDzzz+jlHrp94SzszMffvhhgkXTb775Jp9++im9e/emTp06nDp1ipUrVya57unJEhjffPMN4eHhphsunrC0tOSHH36gZcuWlCtXjt69e1OgQAGuX7/Onj17cHJyMk2p8cS2bds4f/48oNVzrVq1in///ZfRo0ebao+e+P3332ndurXUCKW1tL5NTaRfT273/Pvvv+P1GQwGVaxYMVWsWDHT7dmXLl1SPXr0UHnz5lXW1taqQIEC6s0331Tr1683O/fu3btqyJAhqkCBAsrGxkYVLFhQ9ezZ0+xW9tjYWPXll1+qcuXKKVtbW+Xq6qq8vLzUlClTVGhoqOm452+ff+Lff/813Z564MCBBL++W7duqcGDBysPDw9lbW2t8ubNq5o0aaIWLVpkOubJbeHr1q1L1msXHh6uJk+erMqVK6fs7e2Vo6Ojqlu3rvL19Y13+/Czt/1+/fXXysPDQ9na2qr69eurEydOxHvspLzOL3rv7t+/r3r37q3c3NxUjhw5lI+Pjzp//nyCr+XixYtV0aJFlZWVldmt9IndPv/865TQbclKKTV37lxVuHBhZWtrq2rUqKEOHjyovLy8VIsWLZLw6ioVFxenfvjhB1W/fn3l7OysrK2tVeHChVXv3r3Nbq1/cvv8nTt3zM5/8vpcvnzZ1LZ582ZVsWJFZWdnpzw9PdWXX36plixZEu+4woULqzfeeCPBuJL6GE+OrVOnjrK3t1dOTk6qRo0a6n//+5+pPyIiQnXp0kW5uLgowOy29aT+fACJ3hLPM7fPx8TEqI8++khVqlRJOTo6quzZs6tKlSqp77//3uycxGJK7H0+ffq0ateunXJxcVF2dnaqVKlSasKECQnG86yjR48qIN4UAc/ePv+s+/fvK2dn5wRvnx85cqTKly+fsre3V3Xr1lV+fn7xvn8Ti18p7WcAUI6OjvGmO3ji2LFj6u2331a5cuVStra2qnDhwqpjx45q9+7dpmMSun3ezs5OVa5cWc2fPz/e74Vz586Zpi8RactCKZnCUoi0FBQURJEiRZgxYwajRo3SOxxdGI1GcufOzdtvv53gJR+R9TRp0oT8+fOzYsUKvUPRxbBhw9i/fz/+/v4yIpTGpEZICJGqoqOj49VtLF++nHv37r10iQ2RdUybNo01a9YkuMxFZnf37l1++OEHPv/8c0mCdCA1QkKIVPXXX38xfPhwOnToQK5cuTh69Cg//vgj5cuXN61vJkTNmjWJjY3VOwxd5MqVK8Hia5E2JBESQqQqT09PPDw8mDt3Lvfu3SNnzpz06NGDL774QtdV7YUQAkBqhIQQQgiRZUmNkBBCCCGyLEmEhBBCCJFlZbkaIaPRyI0bN3B0dJTqfCGEECKDUEoRHh5O/vz5402a+zqyXCJ048aNly7iKYQQQoj06erVqxQsWDDFHi/LJUKOjo6A9kI+P725EEIIIdKnsLAwPDw8TJ/jKSXLJUJPLoc5OTlJIiSEEEJkMCld1iLF0kIIIYTIsiQREkIIIUSWJYmQEEIIIbIsSYSEEEIIkWVJIiSEEEKILEsSISGEEEJkWZIICSGEECLLkkRICCGEEFmWJEJCCCGEyLIkERJCCCFElqVrIrR//35at25N/vz5sbCw4JdffnnpOXv37qVq1arY2tpSvHhxfH19Uz1OIYQQQmROuiZCkZGRVKpUiXnz5iXp+MuXL/PGG2/QqFEjjh8/zrBhw+jbty87duxI5UiFEEIIkRnpuuhqy5YtadmyZZKPX7BgAUWKFOHrr78GoEyZMhw4cIBZs2bh4+OTWmEKIYQQIpPKUDVCfn5+NG3a1KzNx8cHPz8/nSISQgghRGozPrzPmXWzUuWxdR0RSq7g4GDy5Mlj1pYnTx7CwsKIiorC3t4+3jkxMTHExMSY9sPCwlI9TiGEEEKkgAeB3Px9Lr0nPmDfxdyp8hQZakToVUyfPh1nZ2fTPw8PD71DEkIIIURilILrB2FzezaNeIOKvW3Ycb4I0XGpM3aToRKhvHnzcuvWLbO2W7du4eTklOBoEMCYMWMIDQ01/bt69WpahCqEEEKI5DDGwfk1sKoWrK7HnWPb6brybUIiswPg7mpMlafNUIlQ7dq12b17t1nb77//Tu3atRM9x9bWFicnJ7N/QgghhEgnYkLhn6/hh2LwW2cIPgJA7hwPmd3hEABtWxflL//hqfL0utYIRUREcPHiRdP+5cuXOX78ODlz5qRQoUKMGTOG69evs3z5cgAGDBjAd999x8cff8x7773HH3/8wdq1a/ntt9/0+hKEEEII8SpCL8PRuXDqB3gUgcFoQZzRCttsBshdCbxG0OeDjnh0v0bz5sUIDw9PlTB0TYT++ecfGjVqZNofMWIEAD179sTX15ebN29y5coVU3+RIkX47bffGD58OHPmzKFgwYL88MMPcuu8EEIIkVHc8AP/b+DfjaC0y11XHzjR43/tKF/SgW8XvAMejcDCAgvAx6d4qoZjoZRSqfoM6UxYWBjOzs6EhobKZTIhhBAiLRjjtMTH/xu4edisa+2pyvTf8BYPIrRqnd9+60KrViXiPURqfX5nqNvnhRBCCJGBxITCqR/h2FwI+8+sK8yiIB/s7seyrU/HYzw8nHB0tEnTECUREkIIIUTKCg3Skp9TP0Dsc7U9bhXwsxpMt0nRBAY+MDV36lSO+fPfwNU14bvAU4skQkIIIYRIGTf+elz/s8FU/2NSpCVxlYYzdYU1n32+H4NBGwlydLRh3rxWdOtWEQsLizQPWRIhIYQQQrw6Yxxc/AX++QZuPrfklZUtlO0BXsO4iyetW/8PP79rpu46dTz46ad2FCnimrYxP0MSISGEEEIkX0wYnF4CR+dAWJB5n4M7VB4MlQaCg7Y0hovBSLZsWkG0lZUFEyd6M3ZsfVObXiQREkIIIUTShV15PP/PYoh9bv1Ot/LgNQJKvwvZ7My6rKwsWbGiHW+/vZZ581pRq1bBNAw6cZIICSGEEOLlbh7R6n8urAdlMO/zbKElQIWbwuM6n337grC3t6ZGjQKmwwoXduGff/rpUguUGEmEhBBCCJEwowEubdLqf24cNO+zsoWy3aHqMHArZ2qOjTUwadIevvzyIEWKuHL8eH8cHW1N/ekpCQJJhIQQQgjxvNhwOL0Ujs7WlsJ4ln1urf6n8kCtFugZAQEhdOmykaNHbwIQGHif+fP/4eOP66ZR4MkniZAQQgghNGFX4di3cGqRNhnis3KV1S5/lekar/5HKcXixUcZNmw7UVFxAFhbWzJ1amNGjqyTVtG/EkmEhBBCiKwu+B+t/idgbfz6n8LNodoI7f8ELmvduRNJv36/smlTgKmtVKlcrFrVnqpV86V25K9NEiEhhBAiKzIa4NJm8J8F1/8077OygTLdwGu4didYInbsuEivXpsIDo4wtQ0Y4MXXX/vg4GCdWpGnKEmEhBBCiKwkNuKZ+p9A8z57N6g0CCoPgux5Xvgwt25F0LbtGqKjtUthbm4OLFnyFq1bl0qlwFOHJEJCCCFEVhB+Tav/ObkIYh6Y9+Uso43+lOkG1klb6ytPnhx88UUThg3bgY9PMXx925I3b46UjzuVSSIkhBBCZGa3/LXb3y+s1ZbDeFahplr9j6cPWLx4hmejUWEwGLG2tjK1DR1ak4IFnWjXrgyWlunrtvikkkRICCGEyGyMBgjcohVAX9tv3mdlA6W7gtcwyF0xSQ9382Y4vXptonLlPHz5ZTNTu6WlBe3bl03BwNOeJEJCCCFEZvEoEk77avU/Dy6a99nl0mp/Kg+C7HmT/JCbNp2nT5/N3L0bxe+/X8LHpziNGxdJ0bD1JImQEEIIkdGFX4fj38HJhRB937zPtZR2+atMN7B2SPJDRkbGMnLkThYu9De15cmT8WqAXkYSISGEECKjunVUu/09YHUC9T9NtAkQi7R4af3P8/z9b9Cly0YuXLhramvTphQ//PAWbm5JT6YyAkmEhBBCiIxEGSHwN63+5+pe8z5LayjTBaoOB/dKyX5og8HIzJmHGD9+D3FxRgAcHKyZPduHvn2rprt1wlKCJEJCCCFERvAoEs4sh6Oz4P6/5n12OaHSQG0NsByvNptzSMhDOnRYx969QaY2L698rFrVnpIlc71G4OmbJEJCCCFEehZxA47PgxMLIPqeeZ9rSW3+n7I9klX/kxBnZ1siImIBbSWN0aPrMXlyQ2xsrF5yZsYmiZAQQgiRHt0+rtX/nP8fGB+Z93k00up/irZKdv1PYqytrVi58m3atl3N/Plv4O3tmSKPm95JIiSEEEKkF8oIl7dp9T9X/jDvs8wGpd/V6n/yVHntp/Lzu4qDgzWVKj29lb5kyVycPj0ow06O+CokERJCCCH09ughnF2hjQDdDzDvs3OFigO0+h/HAq/9VHFxRqZO3c9nn+2nZMlc/PPP+2YLpGalJAgkERJCCCH0E3Hzmfqfu+Z9riW00Z9yPcA6e4o8XWDgfbp124if3zUAzp0L4fvv/2bUqDop8vgZkSRCQgghRFq7fUK7++vcqgTqfxo+rv95I8Xqf5RSrFhxkiFDthIerhVEW1lZMGmSN8OG1UqR58ioJBESQggh0oIywuXtj+t/dpv3WWaDUp21O8DyVE3Rp71/P4oBA35j7dozprZixVz56ae3qVWrYIo+V0YkiZAQQgiRmh5FwbnH9T/3zpv32bpApQFQeUiK1P88b+/eILp3/5lr18JMbb17V2bOnBY4Otqm+PNlRJIICSGEEKkhMhiOfw8n5kNUiHmfS3GoOgzK9QSb1Fm/6+bNcHx8fiI21gCAq6sdCxe+SYcO5VLl+TIqSYSEEEKIlHTn1OP5f1aCIda8r2CDx/U/b4Jl6k5UmC+fI5MmeTNu3B80auTJ8uXtKFjQKVWfMyOSREgIIYR4XUpB0A6t/ue/3837LLNByY5a/U/eaqkYgsJoVFhZPS2w/uSTunh4ONG1a8Usd1t8UkkiJIQQQryqR1FwbqV2B9jds+Z9ts5Qsb9W/+Pkkaph3LkTSb9+v1KlSl4mTWpoareysqR79+QvvpqVSCIkhBBCJFfkLa325/j3EHXHvM+5qFb/U753qtX/PGvHjov06rWJ4OAItmy5QPPmxahdO3UTr8xEEiEhhBAiqULOaPU/534CQ4x5X4F6Wv1PsbdSvf4HIDo6jjFjdjF79mFTm6urvWmeIJE0kggJIYQQL6KUVvfj/41WB/QsCyso9aT+p3qahXTq1C26dt3IqVO3TW0+PsXw9W1L3rypPwqVmUgiJIQQQiQkLlqb+dn/G7h7xrzP1hkqvA9VhoBToTQLyWhUfPvtYT75ZBcxMdpt8ba2Vnz1VTOGDKkhBdGvQBIhIYQQ4lkPb8Px+XDie237Wc5Fnqn/cUzTsO7efUjXrhvZseOSqa1CBXdWrWpP+fLuaRpLZiKJkBBCCAHaXV/+s7RV4J+v/8lfF6qNgGJt0qT+JyHZs9tw/Xq4aX/48FpMm9YEOzv5KH8d8uoJIYTIupSC/3Y9rv/Zbt5nYQUl39Hqf/LV1Ce+Z9jZZWPVqrdp02Y1Cxa8SfPmxfQOKVOQREgIIUTWExcD5x/X/4ScNu+zcYIK/aDqUHAqrE98gL//DbJnt6F0aTdTW4UKebhwYSjZsqXMqvRCEiEhhBBZycM7cGIBHJ8HD2+Z9zl5QtUPofx7YKvfUhQGg5GZMw8xfvweypd356+/+mBr+/TjWpKglCWJkBBCiMzv7jk4OhvOLtfuBntWvtpa/U/xttpyGDq6ejWU7t1/Zt++/wA4fjyY77//m+HDa+saV2YmiZAQQojMSSm48od2+evyVvM+C0so0V6r/8mfPpKMtWvP0L//Fh480BI1CwsYPboegwfX0DmyzE0SISGEEJlLXAwErNYSoDsnzftsHKFCX6jyATh76hLe88LCYvjgg20sW3bC1Obh4cSKFe3w9vbUL7AsQhIhIYQQmcPDEDi5EI5/B5HB5n1OhR/X//TRtf7neX5+V+nW7WcCA++b2jp1Ksf8+W/g6mqvY2RZhyRCQgghMrZ7AVr9z5llEBdl3pevJniNhBLtdK//ed7162E0bLiM2FhthmhHRxvmzWtFt24VsbCQGaLTSvr6rhBCCCGSQim4ukebADFwi3mfhSWUeFtbADWd1P8kpEABJ0aNqs20aQeoU8eDn35qR5EirnqHleVIIiSEECLjMMTC+Sf1PyfM+6xzaPU/VT/QlsJIZ5RSAGajPZMnN6RQIWf69Kkqt8XrRBIhIYQQ6V/UXa3+59h3EHnTvM/RQ6v/qdBXWww1Hbp/P4oBA36jevX8jBpVx9RubW1F//7VdIxMSCIkhBAi/bp34XH9j2/8+p+81R/X/7wNVtZ6RJcke/cG0b37z1y7FsbPP5+jSZMiVKmST++wxGOSCAkhhEhflIJr++Cfbx7X/6hnOi20wmevEZC/jjbZTjoVG2tg4sQ9fPXVQR5fFSNHDhuCgyP0DUyYkURICCFE+mCIhYC1Wv3P7WPmfdbZtVvfq34ALul/sdGAgBC6dNnI0aNPL+M1auTJ8uXtKFgw/dy+LyQREkIIobeoe3ByERz/FiJumPflKKglPxX6gZ2LLuElh1KKRYv8GT58B1FRcQBYW1sydWpjRo6sg6Vl+h3ByqokERJCCKGP+//C0TlweinEPTTvy1NNu/xV8p10Xf/zrHv3oujdexObNweY2kqVysWqVe2pWlVqgtIrSYSEEEKkHaXg+p9a/c+lzcSr/yneVlv/q0C9dF3/kxBbWyvOnw8x7Q8cWI2ZM5vj4JAxErmsShIhIYQQqc/wCC6s0+p/bvmb91lnh/Lvaet/uRbXJ74UkD27DStXvk2bNqtZsOANWrcupXdIIgkkERJCCJF6ou/DycVwbC5EXDfvy1FAS34q9gO7jDej8qlTt8ie3YaiRZ/GXq1afgIDP8DWVj5eMwp5p4QQQqS8+xe1+p8zS+FRpHmfe1WoNhJKdsgw9T/PMhoV3357mE8+2UWVKvn488/eZrNCSxKUsci7JYQQImUoBdcPaJe/Lm4iXv1Psbeg2ggoUD/D1f88cfNmOL16bWLnzksA/PXXNebP/5uhQ2vqHJl4VbovbDJv3jw8PT2xs7OjZs2aHDly5IXHz549m1KlSmFvb4+HhwfDhw8nOjo6jaIVQggRj+ERnPsfrKwBaxrAxV8wJUHZHKDyYHgvANr+AgUbZNgkaNOm81SoMN+UBAEMH16Lfv28dIxKvC5dR4TWrFnDiBEjWLBgATVr1mT27Nn4+PgQEBCAu7t7vONXrVrF6NGjWbJkCXXq1OHChQv06tULCwsLvvnmGx2+AiGEyMKiH8CpxXB0LkRcM+/LkR8qD4WK74N9Tl3CSymRkbGMHLmThQufFnnny5cDX9+2NG+e/id3FC9moZ4sh6uDmjVrUr16db777jsAjEYjHh4eDB06lNGjR8c7fsiQIZw7d47du3eb2kaOHMnhw4c5cOBAkp4zLCwMZ2dnQkNDcXKS2T2FECLZHgQ+nv/nxwTqf6po8/+U6ghWNvrEl4L8/W/QpctGLly4a2pr27Y0ixe3xs3NQcfIsp7U+vzWbUQoNjYWf39/xowZY2qztLSkadOm+Pn5JXhOnTp1+Omnnzhy5Ag1atQgMDCQrVu30r1790SfJyYmhpiYGNN+WFhYyn0RQgiRVSgFNw49rv/5BZTRvL9oa63+p6B3hr309byrV0OpU2cJsbEGABwcrJkzpwV9+lTBIpN8jULHRCgkJASDwUCePHnM2vPkycP58+cTPKdLly6EhIRQr149lFLExcUxYMAAxo4dm+jzTJ8+nSlTpqRo7EIIkWUY4+DCBi0BCn6uhjObPZTrBVWHQc6SekSXqjw8nBk0qBqzZx/Gyysfq1a1p2TJXHqHJVJYhrprbO/evUybNo3vv/+emjVrcvHiRT788EM+++wzJkyYkOA5Y8aMYcSIEab9sLAwPDw80ipkIYTImGJC4dQPWv1P+BXzvuz5oMoQqNgf7DNXYqCUMhvtmT69KYUKOTN4cA1sbKx0jEykFt0SITc3N6ysrLh165ZZ+61bt8ibN2+C50yYMIHu3bvTt29fACpUqEBkZCTvv/8+48aNw9Iy/k1wtra22NrapvwXIIQQmVHoZS35OfUDPIow78tdSZv/p1SnTFH/86ywsBg++GAbNWoUYNCg6qZ2O7tsDB9eW8fIRGrT7fZ5GxsbvLy8zAqfjUYju3fvpnbthL/pHj58GC/ZsbLSMnQda76FECLju+EHv3aAH4vD0dnmSVDRN6HDH9D9GJTtnumSID+/q1SuvIBly04wcuROzp27o3dIIg3pemlsxIgR9OzZk2rVqlGjRg1mz55NZGQkvXv3BqBHjx4UKFCA6dOnA9C6dWu++eYbqlSpYro0NmHCBFq3bm1KiIQQQiSRMQ7+3ajV/9w8bN6XzU6r/6nyIeQqrUt4qS0uzsjnn+/n88/3YzBof0xbW1ty6dJ9ypTJrXN0Iq3omgh16tSJO3fuMHHiRIKDg6lcuTLbt283FVBfuXLFbARo/PjxWFhYMH78eK5fv07u3Llp3bo1U6dO1etLEEKIjCcmFE79qK3/FfafeV/2vFD5cf2Pg5s+8aWBwMD7dOu2ET+/p/Mf1anjwU8/taNIkYy37pl4dbrOI6QHmUdICJFlhQZpyc+pHyA23Lwvd8XH8/90hmyZt65SKcXy5ScYMmQbERGxAFhZWTBxojdjx9Y3WzNMpC+Zbh4hIYQQaeTGX9rlr383xJ//p0grLQEq1DjTzP+TmAcPounffwtr154xtRUt6srKlW9Tq1ZBHSMTepJESAghMiNjnDbx4T/fwM3nJqnNZgdle2jz/+Qqo0d0urCwgMOHn14K69WrMnPntsDRMfOOgImXk0RICCEyk5gwOL1EWwIjLMi8z8Fdq/+pNAAcsl4xsLOzHStWtOPtt9fy/fet6NChnN4hiXRAEiEhhMgMwq48nv9nMcQ+t5SQW3nt8lfpd7XRoCwiICCE7NltKFjwaT1J/fqFCQr6kOzZM9cUAOLVSSIkhBAZ2c0jWv3PhfWgDOZ9RVpC1eFQuGmmr/95llKKRYv8GT58B7VqFWTXrh5YWj79+iUJEs+SREgIITIaowEubdLqf24cNO+zstXqf7yGQa6yuoSnpzt3Iunb91c2bw4AYM+eIBYt8mfAgGo6RybSK0mEhBAio4gNh9NLtZmfQy+b9zm4Q+XBj+t/3HUJT287dlykV69NBAc/nRV7wAAvevSopGNUIr2TREgIIdK7sKtw7Fs4tUibDPFZucpp9T9lumSp+p9nRUfHMWbMLmbPfjo7tpubA0uWvEXr1qV0jExkBJIICSFEehX8t3b568K6+PU/nj5aAlS4WZaq/3neqVO36Np1I6dO3Ta1+fgUw9e3LXnz5tAxMpFRSCIkhBDpidEAlzZrBdDXD5j3WdlAme5a/Y9beV3CS0/+++8B1asvJiZGSxJtba346qtmDBlSw6w4WogXkURICCHSg9iIZ+p/As377N0e1/8MhOx5dAkvPSpc2IUePSqxePFRKlRwZ9Wq9pQvnzXro8Srk0RICCH0FH5Nq/85uQhiHpj35SzzuP6nK1jb6xJeejdrlg+FCzszcmQd7OzkI00kn3zXCCGEHm75P67/Wasth/Gsws20BMjTJ0vX/zwrMjKWkSN3UqtWQXr1qmxqz57dhnHjGugXmMjwJBESQoi0YjRA4Bat/ufafvM+Kxso3RW8hkPuCvrEl075+9+ga9eNBATcZeXKU9SvX4hixXLqHZbIJCQREkKI1PYoEk77avU/Dy6a99m7abU/lQdB9rx6RJduGQxGZs48xPjxe4iLMwJgNCpOn74tiZBIMZIICSFEagm/Dse/g5MLIfq+eV/O0o/rf7pJ/U8Crl4NpXv3n9m37z9Tm5dXPlatak/Jkrl0jExkNpIICSFESrt1FPxnQcDq+PU/hZpCtSf1P5b6xJfOrV17hv79t/DgQTSglUmNHl2PyZMbYmNjpXN0IrORREgIIVKCMkLgb1r9z9W95n2W1tqdX1WHgbss95CY8PAYhg7dxrJlJ0xtHh5OrFjRDm9vT/0CE5maJEJCCPE6HkXCmeVwdBbc/9e8zy4XVB4IlQZBjnz6xJeBxMQY2Lnzkmm/U6dyzJ//Bq6uculQpB5JhIQQ4lVE3IDj8+DEAoi+Z97nWkq7+6tsd7B20Ce+DMjNzYFly9ryzjvr+O67lnTrVhELmT5ApDJJhIQQIjluH9fqf87/D4yPzPsKNdYKoIu0lPqfJAgMvE/27NbkyfN0TbBmzYrx33/DcHHJmgvIirQniZAQQryMMkLgVu3y15U/zPssraH0u9oIkHtlXcLLaJRSLF9+giFDttGgQWG2bHnXbORHkiCRliQREkKIxDx6CGeXayNA9y+Y99nlhEoDtDXAcuTXJ74M6P79KAYM+I21a88AsHXrvyxdepz33quic2Qiq5JESAghnhdx83H9z/wE6n9KQNXhUK4HWGfXJ74Mau/eILp3/5lr18JMbb16VaZDh7I6RiWyOkmEhBDiidsntMtf51bFr//xaKjV/xR9Q+p/kik21sDEiXv46quDKKW1ubrasXDhm3ToUE7f4ESWJ4mQECJrU0a4vF2b/+fKbvM+y2xa/U/V4ZBHLt28ivPnQ+jadSNHj940tTVq5Mny5e0oWNBJx8iE0EgiJITImh5FwbkVWv3PvfPmfXauUPFx/Y9jAX3iywQCA+9TtepCoqK02bWtrS2ZOrUxI0fWwdJSbosX6YMkQkKIrCUyGI5/r9X/RIWY97kU1+7+KtdT6n9SQNGirrz9dhlWrjxFqVK5WLWqPVWrysSSIn2RREgIkTXcOfV4/p+VYIg17yvo/bT+x1LWskpJ8+a1onBhZ8aNa4CDg7Xe4QgRz2slQtHR0djZyXwPQoh0SikI2qHV//z3u3mfZTYo1UkbAcrjpU98mUh0dBxjxuyiTh0PswJoZ2c7pk5tomNkQrxYsm99MBqNfPbZZxQoUIAcOXIQGBgIwIQJE/jxxx9TPEAhhEi2R1Fw8gdYVh42tjRPgmxdoPon0PcytPpJkqAUcOrULWrUWMzs2Yd5//0tXL0aqndIQiRZshOhzz//HF9fX7766itsbGxM7eXLl+eHH35I0eCEECJZIm/BocmwuDD83g/unn3a51IMGn8L71+FBl+AY0HdwswsjEbFnDl/Ub36Yk6dug1AVNQj/vnnhs6RCZF0yb40tnz5chYtWkSTJk0YMGCAqb1SpUqcP3/+BWcKIUQqCTmj1f+c+wkMMeZ9Bepr9T/FWkv9Twq6eTOc3r03sWPH09XiK1RwZ9Wq9pQv765jZEIkT7IToevXr1O8ePF47UajkUePHiVwhhBCpAKltEte/t9odUDPsrCCUh21+p+81fWJLxPbtOk8ffv+SkjIQ1Pb8OG1mDatCXZ2cg+OyFiS/R1btmxZ/vzzTwoXLmzWvn79eqpUkQnHhBCpLC4azq3URoDunjHvs3WGCu9DlaHg5KFPfJlYZGQsI0fuZOFCf1Nbvnw58PVtS/PmxXSMTIhXl+xEaOLEifTs2ZPr169jNBrZuHEjAQEBLF++nC1btqRGjEIIAQ9vw/H52hpgUXfM+5yLQtVhUL4X2DjqEV2WEBYWw4YN50z7bduWZvHi1ri5OegYlRCvx0KpJyu/JN2ff/7Jp59+yokTJ4iIiKBq1apMnDiR5s2bp0aMKSosLAxnZ2dCQ0NxcpLp3YVI9+6e1UZ/zq5IoP6n3uP6n7ek/ieNbNp0ni5dNjJnTgv69KmChYXMEC3SRmp9fr9SIpSRSSIkRAagFPy363H9z3bzPgsrKNlBq//JV0Of+LKIq1dDyZ7dhpw57c3ab9+OxN1dZt4WaSu1Pr+Tfft80aJFuXv3brz2Bw8eULRo0RQJSgiRRcXFwOmlsLwibGhungTZOEG1UdA3EN78nyRBqWzt2jNUrLiA/v238Pzfy5IEicwk2TVCQUFBGAyGeO0xMTFcv349RYISQmQxD+/AiQVa/c/DW+Z9Tp7gNQzKvyf1P2kgLCyGDz7YxrJlJwBYv/4sq1adomvXijpHJkTqSHIitHnzZtP2jh07cHZ2Nu0bDAZ2796Np6dnigYnhMjk7p6Do7Ph7HLtbrBn5a+j1f8Ub6MthyFSnZ/fVbp23cjlyw9MbZ06laNVqxL6BSVEKkvyb5e2bdsCYGFhQc+ePc36rK2t8fT05Ouvv07R4IQQmZBScOUPrf7n8lbzPgtLKPGOVv+Tv5Y+8WVBcXFGpk7dz2ef7cdg0C6DOTraMG9eK7p1qygF0SJTS3IiZDQaAShSpAh///03bm5uqRaUECITiouBgNVaAnTnpHmfjSNU6KfN/+PsqUt4WVVg4H26dduIn981U1udOh789FM7ihRx1TEyIdJGssebL1++nBpxCCEyq4chcHIhHP8OIoPN+5wKQ9UPoXwfsJW7ONPaxYv3qFp1IeHhsQBYWVkwcaI3Y8fWJ1u2ZN9LI0SG9EoX3iMjI9m3bx9XrlwhNjbWrO+DDz5IkcCEEBncvQCt/ufMMoiLMu/LV0ur/ynRTup/dFSsmCtNmhTll1/OU7SoKytXvk2tWrIYrchakv0b6NixY7Rq1YqHDx8SGRlJzpw5CQkJwcHBAXd3d0mEhMjKlIKre7QJEAOfm2newhJKtH9c/1Nbn/iEGQsLCxYvbk3hws589lkjHB1t9Q5JiDSX7LHP4cOH07p1a+7fv4+9vT1//fUX//33H15eXsycOTM1YhRCpHeGWDizHFZUgXVNzJMgG0ct+elzEVqvlSRIJ7GxBkaP3sVvv10wa3dzc2D27BaSBIksK9kzS7u4uHD48GFKlSqFi4sLfn5+lClThsOHD9OzZ0/Onz+fWrGmCJlZWogUFHVXq/859h1E3jTvcyyk1f9U6KMthip0ExAQQpcuGzl69Cbu7tk5eXIAefLk0DssIZIltT6/k31pzNraGktLbSDJ3d2dK1euUKZMGZydnbl69WqKBSaESMfuXXhc/+Mbv/4nbw2oNhJKvC31PzpTSrFokT/Dh+8gKioOgPv3ozh48Cpvv11G5+iESB+S/VuqSpUq/P3335QoUQJvb28mTpxISEgIK1asoHz58qkRoxAiPVAKru2Df76BwF/N+ywsoXg7rQA6f22QeWd0d+dOJH37/srmzQGmtlKlcrFqVXuqVs2nY2RCpC/JToSmTZtGeHg4AFOnTqVHjx4MHDiQEiVK8OOPP6Z4gEIInRliIWCtNv/P7WPmfdY5tEtfVT4AF1lrML3YseMivXptIjg4wtQ2cGA1Zs5sjoODtY6RCZH+yOrzQoiERd2Dk4vg+LcQccO8L0fBx/U/fcHORZfwRHzR0XGMGbOL2bMPm9rc3BxYsuQtWrcupWNkQry+dFMjlJijR48yceJEtmzZ8vKDhRDp1/1/4egcbRX4uIfmfXmqPa7/aQ9WMrKQ3ty+HcnSpcdN+y1aFGfp0jbkzSuF0UIkJlm3z+/YsYNRo0YxduxYAgMDATh//jxt27alevXqpmU4hBAZjFJwbT/80haWlNJWgTclQRZa/U+nP6HrESjdWZKgdKpQIWfmz38DW1sr5s5twdatXSQJEuIlkjwi9OOPP9KvXz9y5szJ/fv3+eGHH/jmm28YOnQonTp14vTp05QpI3chCJGhGB7BhXVa/c8tf/M+6+xQ/j3tEphLMX3iEy9082Y42bPb4OT0dA6gd9+tQL16hfDwkCkLhEiKJNcIVaxYke7du/PRRx+xYcMGOnToQK1atVi7di0FC2acKdmlRkgIIPo+nFwMx+ZCxHXzvhwFoeoHj+t/ZNHN9GrTpvP07fsrb7xRAl/ftnqHI0SqS63P7yQnQtmzZ+fMmTN4enqilMLW1pY9e/ZQt27dFAsmLUgiJLK0+xe1+p8zS+FRpHlfHi/wGgkl35FLX+lYZGQsI0fuZOHCpyN469d3oH37sjpGJUTq071YOioqCgcHB0Bbn8bW1pZ8+WQuCiHSPaXg+gHt8tfFTcCzf/tYQPE22vw/BerJ/D/pnL//Dbp02ciFC3dNbW3blsbb21O/oITI4JJ119gPP/xAjhxa4V1cXBy+vr64ubmZHSOLrgqRThgewYX1j+t//jHvy+bwtP7Htbg+8YkkMxiMzJx5iPHj9xAXp92U4uBgzZw5LejTpwoWksAK8cqSfGnM09PzpT9sFhYWprvJkmrevHnMmDGD4OBgKlWqxLfffkuNGjUSPf7BgweMGzeOjRs3cu/ePQoXLszs2bNp1apVkp5PLo2JTC/6AZxaDEfnQsQ1874c+bXJDyv0A/ucuoQnkufq1VC6d/+Zffv+M7V5eeVj1ar2lCyZS8fIhEhbul8aCwoKSrEnfWLNmjWMGDGCBQsWULNmTWbPno2Pjw8BAQG4u7vHOz42NpZmzZrh7u7O+vXrKVCgAP/99x8uLi4pHpsQGc6DwMfz//wYv/7HvYo2/0/JDmBlo098ItkuXLhLzZo/8OBBNKBduRw9uh6TJzfExsZK5+iEyBx0nVm6Zs2aVK9ene+++w4Ao9GIh4cHQ4cOZfTo0fGOX7BgATNmzOD8+fNYW79aMaeMCIlMRSm4cehx/c8voJ6dy8sCirXW6n8KNpD6nwzIaFS0arWSHTsu4eHhxIoV7aQeSGRZqfX5nawJFVNSbGws/v7+NG3a9GkwlpY0bdoUPz+/BM/ZvHkztWvXZvDgweTJk4fy5cszbdo0DAZDWoUtRPpgjIPza2BVLVhdD/7d+DQJymYPlQZB7/PQdhN4eEsSlEFZWlqwdGkb3n+/KidODJAkSIhUkGJLbCRXSEgIBoOBPHnymLXnyZOH8+fPJ3hOYGAgf/zxB127dmXr1q1cvHiRQYMG8ejRIyZNmpTgOTExMcTExJj2w8LCUu6LECKtxYTCqR+0+p/wK+Z92fNBlaFQ8X2wl9qRjCYuzsjUqfupX78wjRsXMbXny+fIwoWtdYxMiMxNt0ToVRiNRtzd3Vm0aBFWVlZ4eXlx/fp1ZsyYkWgiNH36dKZMmZLGkQqRwkIva8nPqR/gUYR5X+7KUG0ElOok9T8ZVGDgfbp124if3zUKFHDk5MmB5Mxpr3dYQmQJuiVCbm5uWFlZcevWLbP2W7dukTdv3gTPyZcvH9bW1lhZPS0SLFOmDMHBwcTGxmJjE/9DYMyYMYwYMcK0HxYWhoeHRwp9FUKksht+Wv3Ps5e+nijaGryGg0dDufSVQSmlWLHiJEOGbCU8PBaA4OAI9uy5LBMkCpFGXqlG6NKlS4wfP553332X27dvA7Bt2zbOnDmT5MewsbHBy8uL3bt3m9qMRiO7d++mdu3aCZ5Tt25dLl68aLa464ULF8iXL1+CSRCAra0tTk5OZv+ESNeMcRCwVqv/+V8dbS4gs/qfgVr9T7vNUKiRJEEZ1P37UXTuvIGePX8xJUFFi7py4MB7kgQJkYaSnQjt27ePChUqcPjwYTZu3EhEhDZMf+LEiUQvTyVmxIgRLF68mGXLlnHu3DkGDhxIZGQkvXv3BqBHjx6MGTPGdPzAgQO5d+8eH374IRcuXOC3335j2rRpDB48OLlfhhDpT0wo/PMN/FgctnSCm4ef9mXPC/WmwvtXoen3kLOUfnGK17Z3bxAVKy5g7dqnfzz26lWZ48f7U6tWxlm7UYjMINmXxkaPHs3nn3/OiBEjcHR0NLU3btzYdBt8UnXq1Ik7d+4wceJEgoODqVy5Mtu3bzcVUF+5cgVLy6e5moeHBzt27GD48OFUrFiRAgUK8OGHH/LJJ58k98sQIv0IDdIWPz31A8SGm/flrqit/1WqE2SzTfB0kXHExhqYNGkPX355kCcTl7i42LFo0Zt06FBO3+CEyKKSPY9Qjhw5OHXqFEWKFMHR0ZETJ05QtGhRgoKCKF26NNHR0akVa4qQeYREunHjr8f1PxsSqP95Q5v/x0MufWUmgYH3qVhxPpGRjwBo2NCT5cvb4uHhrHNkQqR/6WYeIRcXF27evBmv/dixYxQoUCBFghIi0zLGaTU/q+rA/2rDhXXP1P/YQcX+0OsctNsChRpLEpTJFC3qypw5LbC2tuSrr5qye3cPSYKE0FmyL4117tyZTz75hHXr1mFhYYHRaOTgwYOMGjWKHj16pEaMQmR8MWFweom2BEZYkHmfQx6oMgQqDgAHtwRPFxlTSMhDHByscXB4OhP+e+9Vwdvbk+LFZa03IdKDZF8ai42NZfDgwfj6+mIwGMiWLRsGg4EuXbrg6+trdmt7eiSXxkSaCrvyeP6fxRD73GSebhW0y1+l35X6n0xox46L9Oq1ibffLs28eW/oHY4QGV5qfX6/8lpjV65c4fTp00RERFClShVKlCiRYkGlJkmERJq4eUSr/7mwHtRzS8AUaaklQIWayKWvTCg6Oo4xY3Yxe/bTu/62bHmXN94oqWNUQmR8uq8+/8SBAweoV68ehQoVolChQikWiBAZntEAlzZpt8DfOGjeZ2ULZXuA1zDIJXPEZFanTt2ia9eNnDp129TWokVxvLzy6xiVEOJFkp0INW7cmAIFCvDuu+/SrVs3ypaVX+oii4sNh9NL4ehsbSmMZzm4Q+XBUGmAti0yJaNR8e23h/nkk13ExGgjgLa2VsyY0YwhQ2pgISN/QqRbyU6Ebty4werVq/nf//7HF198QcWKFenatSvvvvsuBQvKRGAiCwm7Ase+1ep/YkLN+9zKP1P/Y6dPfCJN3LwZTu/em9ix45KprUIFd1atak/58pL8CpHevXKNEMDly5dZtWoV//vf/zh//jwNGjTgjz/+SMn4UpzUCInXFvy3dvnrwrr49T+eLbQEqHBTqf/JAgICQqhXbykhIQ9NbcOH12LatCbY2WWoNa2FSPfSXbH0EwaDgW3btjFhwgROnjyJwWB4+Uk6kkRIvBKjAS5t1gqgrx8w77OyhbLdoeowcJPZgbMSg8FI48bL2b//P/Lly4Gvb1uaNy+md1hCZErpplj6iYMHD7Jy5UrWr19PdHQ0bdq0Yfr06SkWmBDpQmzEM/U/geZ99rm1+p/KA6X+J4uysrJkxYp2jB//B99844Obm4PeIQkhkinZI0Jjxoxh9erV3Lhxg2bNmtG1a1fatGmDg0PG+AUgI0IiScKvafU/JxdBzAPzvlxltctfZbpK/U8WYjAYmTnzEPXrF6ZOHQ+9wxEiy0k3I0L79+/no48+omPHjri5ySy4IpO55f+4/metthzGswo3h2ojtP+l/idLuXo1lO7df2bfvv8oUsSF48cH4OQkk2AKkRkkOxE6ePDgyw8SIiMxGiBwi1b/c22/eZ+VDZTpptX/5K6gS3hCX2vXnqF//y08eKAtKB0U9ICdOy/xzjsydYgQmUGSEqHNmzfTsmVLrK2t2bx58wuPfeutt1IkMCFS3aNIOO2r1f88uGjeZ+8GlQZB5UGQPY8e0QmdhYXF8MEH21i27ISpzcPDiRUr2uHt7alfYEKIFJWkGiFLS0uCg4Nxd3fH0jLxBestLCzkrjGR/imljf4cngrR9837cpZ+XP/TDazt9YlP6M7P7yrduv1MYODT749Oncoxf/4buLrK94UQetC1RshoNCa4LUSGdO4n2DfKvK1QU63+x9MHLBJP9kXmFhdnZOrU/Xz22X4MBu1vREdHG+bNa0W3bhVlhmghMqFk/8Zfvnw5MTEx8dpjY2NZvnx5igQlRKoJuwq7hzzdL9sDepyADr9ri6FKEpSlXbp0j+nTD5iSoDp1PDhxYgDdu1eSJEiITCrZv/V79+5NaGhovPbw8HB69+6dIkEJkSqUEXb0htgwbb9sD2i5DHJX1DcukW6UKuXGV181w8rKgilTGrJvXy+KFHHVOywhRCpK9l1jSqkE/zK6du0azs7OKRKUEKni2Dy4slvbdvSARnP0jUfo7v79KBwcrLG1ffqrcOjQGjRuXETWCRMii0hyIlSlShUsLCywsLCgSZMmZMv29FSDwcDly5dp0aJFqgQpxGu7ex7+/Pjpvs9SsHPRLRyhv717g+je/Wc6dy7HjBnNTe0WFhaSBAmRhSQ5EWrbti0Ax48fx8fHhxw5cpj6bGxs8PT0pH379ikeoBCvzRgH23tAnDYPDFU+gMJN9I1J6CY21sCkSXv48suDKAUzZ/rRokVxmjQpqndoQggdJDkRmjRpEgCenp506tQJOztZWkBkEIenayvGA7iWgvqyJl5WFRAQQpcuGzl69KaprVEjT0qVklnyhciqkl0j1LNnz9SIQ4jUccsf/vpU27awgpbLwTpjrIsnUo5SikWL/Bk+fAdRUdrSKdbWlkyd2piRI+tgaSl3hAmRVSUpEcqZMycXLlzAzc0NV1fXF95Geu/evRQLTojX8igKtnZ/umZYzbGQr4a+MYk0d+dOJH37/srmzQGmtlKlcrFqVXuqVs2nY2RCiPQgSYnQrFmzcHR0NG3LfBoiQzg4Hu6d07bdq0Kt8frGI9JcQEAIDRsuIzg4wtQ2cGA1Zs5sjoODtY6RCSHSiyQtsZGZyBIbWcTVvbC2MaDAyha6+YNbOZ2DEmnt0SMDdesu4e+/b+Dm5sCSJW/RunUpvcMSQryC1Pr8TvaEikePHuXUqVOm/U2bNtG2bVvGjh1LbGxsigUmxCuLCYPtvYDHOX69aZIEZVHW1lasXPk2b79dhlOnBkoSJISIJ9mJUP/+/blw4QIAgYGBdOrUCQcHB9atW8fHH3/8krOFSAN7h0PYf9p2QW/wGqZrOCJtGI2KuXMPc+zYTbP2EiVysWFDR/LmzZHImUKIrCzZidCFCxeoXLkyAOvWrcPb25tVq1bh6+vLhg0bUjo+IZLn0q9weom2bZ0DWvjK+mFZwM2b4bRqtZIPP9xOly4befjwkd4hCSEyiGR/QiilTCvQ79q1i1atWgHg4eFBSEhIykYnRHI8vAM7+z7dbzQHnD11C0ekjU2bzlOx4gJ27LgEwPnzIWzb9q/OUQkhMopkzyNUrVo1Pv/8c5o2bcq+ffuYP38+AJcvXyZPnjwpHqAQSaIU7BoAD29r+0VbQ3lZBDgzi4yMZeTInSxc6G9qy5cvB76+bWnevJiOkQkhMpJkJ0KzZ8+ma9eu/PLLL4wbN47ixYsDsH79eurUqZPiAQqRJOdWwr8btW17N2i+GGSah0zL3/8GXbps5MKFu6a2tm1Ls3hxa9zcZMJMIUTSpdjt89HR0VhZWWFtnb7n5pDb5zOhsKuwvALEhGr7rddDSVn3LjMyGIzMmHGICRP2EBenXaJ3cLBm9mwf+vatKnOcCZGJpdbnd7JHhJ7w9/fn3DltsrqyZctStWrVFAtKiCRTRtjR+2kSVLa7JEGZ2PnzIWZJkJdXPlatak/Jkrl0jkwIkVElOxG6ffs2nTp1Yt++fbi4uADw4MEDGjVqxOrVq8mdO3dKxyhE4o5/D1d2a9s5CkKjufrGI1JVuXLufPZZI8aO3c3o0fWYPLkhNjZWeoclhMjAkn3X2NChQ4mIiODMmTPcu3ePe/fucfr0acLCwvjggw9SI0YhEnYvAPY/M3dVi6Vg56JbOCLlhYfHmEZ/nvjoozocOdKPadOaSBIkhHhtyU6Etm/fzvfff0+ZMmVMbWXLlmXevHls27YtRYMTIlHGONjWA+KitP0qQ6FwU31jEinKz+8qlSsv5PPP95u1W1lZUq1afp2iEkJkNslOhIxGY4IF0dbW1qb5hYRIdUe+gOAj2rZrSaj/hb7xiBQTF2dkypS91K+/lMDA+3z22X4OHbqqd1hCiEwq2YlQ48aN+fDDD7lx44ap7fr16wwfPpwmTZqkaHBCJOjWUfCbom1bWELL5WAtt0xnBoGB92nQYCmTJ+/DYNBuaK1VqyD58snyGEKI1JHsROi7774jLCwMT09PihUrRrFixShSpAhhYWF8++23qRGjEE/FRcO27tqlMYCaYyFfTX1jEq9NKcXy5SeoXHkBfn7XALCysmDKlIbs29eLIkVc9Q1QCJFpJfuuMQ8PD44ePcru3btNt8+XKVOGpk2lPkOkgQPj4e5Zbdu9CtSaoG884rXdvx/FwIG/sWbNGVNb0aKurFz5NrVqFdQxMiFEVpCsRGjNmjVs3ryZ2NhYmjRpwtChQ1MrLiHiu7oP/L/Rtq1soeUKsLLRNybxWgICQmjWbAVXr4aZ2nr1qszcuS1wdLTVMTIhRFaR5ERo/vz5DB48mBIlSmBvb8/GjRu5dOkSM2bMSM34hNDEhMH2XsDjidDrTQW3cnpGJFJA4cIuuLjYcfVqGK6udixc+CYdOsj7KoRIO0muEfruu++YNGkSAQEBHD9+nGXLlvH999+nZmxCPLV3BIQFadsFG0DVYXpGI1KInV02Vq1qT6tWJTh5cqAkQUKINJfktcbs7e05d+4cnp6egHYbvb29PUFBQeTLly81Y0xRstZYBnTpV/jlLW3bOgf0PAnORfSNSSSbUorFi49Sr14hypaVGeiFEMmTWp/fSR4RiomJIXv27E9PtLTExsaGqKioFAtGiHgehsDOfk/3G82WJCgDunMnkrZt19C//xa6dNlATEyc3iEJIQSQzGLpCRMm4ODwdL6W2NhYpk6dirOzs6ntm2++SbnoRNamFOwaAA9vaftF34Ty7+kbk0i2HTsu0qvXJoKDIwA4ceIWW7ZcoH37sjpHJoQQyUiEGjRoQEBAgFlbnTp1CAwMNO1bWFikXGRCnF8F/27Qtu1yQfPFIN9jGUZ0dByjR+9izpzDpjY3NweWLHmL1q1L6RiZEEI8leREaO/evakYhhDPCb8Guwc/3W+2ELLn1S8ekSynTt2iS5eNnD5929Tm41MMX9+25M0rs0QLIdKPZE+oKESqU0bY3htiQrX9Mt2gZHt9YxJJYjQqvv32MJ98souYGAMAtrZWfPVVM4YMqYGlpYzoCSHSF0mERPpzfD5c2aVt5ygAjWXplozi1KlbjBixE6NRuxm1QgV3Vq1qT/ny7jpHJoQQCUv2WmNCpKp7F2D/R0/3fZaCnYtu4YjkqVQpL2PH1gNg+PBaHDnST5IgIUS6JiNCIv0wxsH2HhD3eEqGykPAs5m+MYkXevjwEXZ22cwueU2c6E3z5sWoX7+wjpEJIUTSyIiQSD+OfAk3H99h5FoCGnypbzzihfz9b1ClykK+/vqQWbu1tZUkQUKIDOOVEqE///yTbt26Ubt2ba5fvw7AihUrOHDgQIoGJ7KQW8fAb7K2bWEJLZaDtcMLTxH6MBiMfPnlAWrV+pELF+4ybtwfHD16U++whBDilSQ7EdqwYQM+Pj7Y29tz7NgxYmJiAAgNDWXatGkpHqDIAuKiYVt37dIYQI0xkL+WvjGJBF29GkqTJssZPXo3cXFGACpWzEOOHDY6RyaEEK8m2YnQ559/zoIFC1i8eDHW1tam9rp163L06NEUDU5kEQcnwN0z2nbuylB7oq7hiIStXXuGihUXsG/ff4A2t+WYMfU4dKgPJUvm0jk6IYR4Nckulg4ICKBBgwbx2p2dnXnw4EFKxCSykmv74Z+vtW0rG2i1QvtfpBthYTF88ME2li07YWrz8HBixYp2eHt76heYEEKkgGQnQnnz5uXixYumVeifOHDgAEWLFk2puERWEBsO23oC2pwz1J0KbuV1DUmYCwgIoVWrVQQG3je1depUjgUL3sTFxU7HyIQQImUk+9JYv379+PDDDzl8+DAWFhbcuHGDlStXMmrUKAYOHJgaMYrMau8ICAvStgvUB6/huoYj4itY0Ils2bRfE46ONixf3pb//a+9JEFCiEwj2YnQ6NGj6dKlC02aNCEiIoIGDRrQt29f+vfvz9ChQ18piHnz5uHp6YmdnR01a9bkyJEjSTpv9erVWFhY0LZt21d6XqGjwN/g1A/atnUOaOELlla6hiTiy57dhlWr3qZhQ09OnBhA9+6VZHFlIUSmYqGUUq9yYmxsLBcvXiQiIoKyZcuSI8erLaS4Zs0aevTowYIFC6hZsyazZ89m3bp1BAQE4O6e+Iy0QUFB1KtXj6JFi5IzZ05++eWXJD1fWFgYzs7OhIaG4uTk9Eoxi9f0MASWlYeHt7T9ZouhYl99YxIopVix4iR163pQrFjOeH2SAAkh9JRan9+vPKGijY0NZcuWpUaNGq+cBAF888039OvXj969e1O2bFkWLFiAg4MDS5YsSfQcg8FA165dmTJlitQlZTRKwe6BT5Ogom9AhT76xiS4fz+Kzp030LPnL3TtupFHjwxm/ZIECSEyq2QXSzdq1OiFvxT/+OOPJD9WbGws/v7+jBkzxtRmaWlJ06ZN8fPzS/S8Tz/9FHd3d/r06cOff/75wueIiYkxzXUEWkYpdHT+f3BhvbZtlwua/6Ddhy10s3dvEN27/8y1a9rPxuHD19my5QLt2pXROTIhhEh9yU6EKleubLb/6NEjjh8/zunTp+nZs2eyHiskJASDwUCePHnM2vPkycP58+cTPOfAgQP8+OOPHD9+PEnPMX36dKZMmZKsuEQqCb8Guwc/3W+2ALLn1S+eLC421sDEiXv46quDPLlA7upqx6JFrSUJEkJkGclOhGbNmpVg++TJk4mIiHjtgF4kPDyc7t27s3jxYtzc3JJ0zpgxYxgxYoRpPywsDA8Pj9QKUSRGKdjxHsQ80PbLdIWS7+gaUlYWEBBCly4bzZbGaNTIk+XL21GwoNTOCSGyjhRbfb5bt27UqFGDmTNnJvkcNzc3rKysuHXrlln7rVu3yJs3/kjBpUuXCAoKonXr1qY2o1Gb5j9btmwEBARQrFgxs3NsbW2xtbVNzpciUsOJ+fDf79p2jgLQ+Ft948milFIsWuTP8OE7iIrSljSxtrZk6tTGjBxZx2wVeSGEyApSLBHy8/PDzi55c4vY2Njg5eXF7t27TbfAG41Gdu/ezZAhQ+IdX7p0aU6dOmXWNn78eMLDw5kzZ46M9KRX9/+FfaOe7vssBTtX/eLJwo4dC2bAgN9M+6VK5WLVqvZUrZpPx6iEEEI/yU6E3n77bbN9pRQ3b97kn3/+YcKECckOYMSIEfTs2ZNq1apRo0YNZs+eTWRkJL179wagR48eFChQgOnTp2NnZ0f58uYzD7u4uADEaxfphDEOtvWAuChtv9Ig8Gymb0xZWNWq+RgxohbffPMXAwdWY+bM5jg4WL/8RCGEyKSSnQg5Ozub7VtaWlKqVCk+/fRTmjdvnuwAOnXqxJ07d5g4cSLBwcFUrlyZ7du3mwqor1y5gqXlK9/lL/T291dw8y9t26U4eH+lbzxZTExMHDY2VmZ3ek6b1oQWLYrTrFmxF5wphBBZQ7ImVDQYDBw8eJAKFSrg6poxL23IhIpp6NYxWFVDGxWysITOByB/bb2jyjJOnbpFly4bGTiwGoMGVdc7HCGEeC3pYkJFKysrmjdvLqvMi5eLi4btPbQkCKDGaEmC0ojRqJgz5y+qV1/M6dO3GTlyJ2fP3tE7LCGESJeSfWmsfPnyBAYGUqRIkdSIR2QWBydCyGltO3clqD1J33iyiJs3w+ndexM7dlwytZUokfMFZwghRNaW7OKbzz//nFGjRrFlyxZu3rxJWFiY2T8huPYn/PN4GgUrG2i5QvtfpKpNm85TseICsyRo+PBaHDnSj7Jlc+sYmRBCpF9JHhH69NNPGTlyJK1atQLgrbfeMivAfLIoo8FgSOwhRFYQGw7bewKPS8/qfg65K+gaUmYXGRnLyJE7WbjQ39SWL18OfH3b0ry5FEQLIcSLJLlY2srKips3b3Lu3LkXHuft7Z0igaUWKZZOZTvfh1OLte0C9aDjXrC00jWkzOzChbu0bv0/Lly4a2pr27Y0ixe3xs3NQcfIhBAiZaXW53eSR4Se5EvpPdEROgr87WkSZJ0dWiyTJCiV5cmTndhYbRTWwcGaOXNa0KdPFVktXgghkihZNULyy1UkKuou7Oz7dL/hLHApql88WYSzsx0//dSOmjULcOxYf/r2rSo/p0IIkQzJumusZMmSL/0le+/evdcKSGRASsGugRAZrO0XaQUV+r74HPFK1q07Q61aBfHweDqxad26hfDz6yMJkBBCvIJkJUJTpkyJN7O0EJxfDRfWadt2OaH5DyAfyikqLCyGDz7YxrJlJ2jY0JNdu7pjZfV0QFeSICGEeDXJSoQ6d+6Mu7t7asUiMqLw67B70NP9pgsghyzgmZL8/K7SrdvPBAbeB2Dv3iC2bLlAmzaldY5MCCEyviTXCMlfnCIepWDHexDzQNsv3QVKddA1pMwkLs7IlCl7qV9/qSkJcnS0Yfnytrz1VimdoxNCiMwh2XeNCWFyYgH8t1PbzpEfmnynbzyZSGDgfbp124if3zVTW506Hvz0UzuKFMmY6/wJIUR6lOREyGg0pmYcIqO5/y/sG/V032cJ2MkH9OtSSrFixUmGDNlKeHgsAFZWFkyc6M3YsfXJli3Zk8ELIYR4gWSvNSYExjjY1hPiHmr7lQaCp4++MWUS//xzg549fzHtFy3qysqVb1OrVkH9ghJCiExM/rwUyff3DLjpp227FAPvGfrGk4lUr16A/v29AOjVqzLHj/eXJEgIIVKRjAiJ5Ll9HA49XknewhJaLNdmkRav5NEjA9myWZrdjPD1181p1aqEFEQLIUQakBEhkXRxMbCtOxgfafvVP4ECdfSNKQMLCAihVq0fWbbshFl79uw2kgQJIUQakURIJN2hiRByWtvOXQnqTNY1nIxKKcXChf9QpcpCjh69ydCh27h4UWZkF0IIPcilMZE01w5otUEAVjbQcrn2v0iWO3ci6dv3VzZvDjC1FSjgSFTUIx2jEkKIrEsSIfFyseGwvQfweC6pOp9B7oq6hpQR7dhxkV69NhEcHGFqGzDAi6+/9sHBwVrHyIQQIuuSREi83L5REHpZ285fF6qN1DeeDCY6Oo4xY3Yxe/ZhU5ubmwNLlrxF69ZSCySEEHqSREi8WOBWOLlI27bODi2XgaWVvjFlIBcv3uPtt9dw6tRtU1uLFsVZurQNefPm0DEyIYQQIImQeJGou7Cz79P9ht9o8waJJHN1tePu3SgAbG2tmDGjGUOG1JC1+4QQIp2Qu8ZE4nYPhsib2naRllChn77xZEC5cjng69uGSpXy8M8/7zN0aE1JgoQQIh2RESGRsPOrIWCNtm2XE5r/CPIB/lK//hpA9eoFzC57NWtWDH//IlhZyd8dQgiR3shvZhFf+HXYPejpftP5kCOffvFkAJGRsQwYsIW33lrNe+9tQill1i9JkBBCpE/y21mYUwp29oHo+9p+6XehVEd9Y0rn/P1vULXqIhYu9Adg27aLbNlyQeeohBBCJIUkQsLcyYUQtEPbzpEfGn+nbzzpmMFg5MsvD1Cr1o9cuHAXAAcHaxYvbs2bb5bUOTohhBBJITVC4qn7F2HvM3MENf8R7HPqF086dvVqKN27/8y+ff+Z2ry88rFqVXtKlsylY2RCCCGSQxIhoTEaYFsPiHuo7VcaAEVa6BtTOrVmzWkGDPiNBw+iAa2GfPToekye3BAbG5ljSQghMhJJhITm7xlw00/bdikGDWboG0869ddf1+jceYNp38PDiRUr2uHt7alfUEIIIV6Z1AgJuH1CW1kewMISWiwDG5n1OCG1ahWke3dtnbVOncpx4sQASYKEECIDkxGhrC4uBrZ1B+Pj1c+rfwwF6uobUzpiNCosLc3nT/ruu1a88UYJOnYsJ5MjCiFEBicjQlndoUkQckrbzl0Rak/WNZz0JDDwPvXqLWHt2jNm7U5OtnTqVF6SICGEyARkRCgru3YA/v5K27a0hpYrIJutvjGlA0opVqw4yZAhWwkPj+XcuS3Url0QDw9nvUMTQgiRwmREKKuKjYDtPYHHMyDX/UwbEcri7t+PonPnDfTs+Qvh4bEA5Mxpb1o4VQghROYiI0JZ1b5REBqobeevA9VG6RtPOrB3bxDdu//MtWthprZevSozd24LHB1lpEwIITIjSYSyosvbtBmkAayzQ8vlYJl157+JjTUwceIevvrqIE+WCHNxsWPRojfp0KGcvsEJIYRIVZIIZTVR92BHn6f73l9r8wZlUYGB9+nQYR1Hj940tTVs6Mny5W2lJkgIIbIAqRHKanYPhsjHH/qeLaDi+/rGozN7+2xcuRIKgLW1JV991ZTdu3tIEiSEEFmEJEJZyfnVELBa27ZzBZ8ftfUhsrB8+Rz58ce3KF3ajb/+6stHH9WNN2+QEEKIzEsujWUVETdg96Cn+03ma6vLZzG7dgVSpUpecuVyMLW99VYpWrYsjrV11q2TEkKIrEpGhLICpbS6oOj72n6pzlC6k74xpbHo6DiGD99Os2Yr6N9/C+pJVfRjkgQJIUTWJIlQVnByEQRt17az54Mm8/SNJ42dOnWLGjUWM3v2YQA2bDjH9u0XdY5KCCFEeiCJUGZ3/yLsHfF03+dHsM+pXzxpyGhUzJnzF9WrL+bUqdsA2NpaMXduC1q0KK5zdEIIIdIDqRHKzIwGbfbouIfafsX+UKSlvjGlkZs3w+ndexM7dlwytVWo4M6qVe0pX95dx8iEEEKkJ5IIZWb/zIQbh7Rt56LgPVPfeNLI5s0B9OmzmZCQh6a24cNrMW1aE+zs5FteCCHEU/KpkFndOQkHJzzesdBmj7bJoWtIaeHgwSu0abPatJ83bw6WLWtL8+ZZd9JIIYQQiZMaocwoLga2dQfjI22/+sdQoK6+MaWROnU8aNeuNABt2pTi1KmBkgQJIYRIlIwIZUZ+k7URIQC3ClBniq7hpCalFBbPTAppYWHB4sWteeutUvTsWcmsTwghhHiejAhlNtcPwt9faduW1tByBWTLnCunX70aSuPGy9my5YJZe65cDvTqVVmSICGEEC8lI0KZSWyEdpeYMmr7dT4F90r6xpRK1q49Q//+W3jwIJozZ25z8uRA8ubN/DVQQgghUpaMCGUm+z+CB49vF89fB6p/pG88qSAsLIZevX6hU6f1PHgQDYCdXTZu3AjXOTIhhBAZkYwIZRaXt8OJBdp2NgdosQwsM9eyEX5+V+nadSOXLz8wtXXqVI7589/A1dVev8CEEEJkWJIIZQZR92Bnn6f7Db8G18wzc3JcnJHPP9/P55/vx2DQ1ghzdLRh3rxWdOtWUWqBhBBCvDJJhDKDP4Zoq8sDePpoM0hnEkFBD+jSZQN+ftdMbXXqePDTT+0oUsRVx8iEEEJkBlIjlNGdXwPn/6dt27lC8x8hE42QWFpacPbsHQCsrCyYMqUh+/b1kiRICCFEipBEKCOLuAG7Bz3db/I9OBbQL55UUKiQMwsWvEnRoq4cOPAeEyd6ky2bfNsKIYRIGfKJklEpBTv7QvQ9bb9kRyjdWd+YUsCff/5HWFiMWVvnzuU5c2YQtWoV1CkqIYQQmVW6SITmzZuHp6cndnZ21KxZkyNHjiR67OLFi6lfvz6urq64urrStGnTFx6faZ1aDJe3advZ80LT7/WN5zXFxhoYPXoX3t6+DB26LV6/LJYqhBAiNeieCK1Zs4YRI0YwadIkjh49SqVKlfDx8eH27dsJHr93717effdd9uzZg5+fHx4eHjRv3pzr16+nceQ6enAJ9o54ut/8R7DPpV88rykgIITatX/kyy8PohQsX36CnTsv6R2WEEKILMBCKaX0DKBmzZpUr16d7777DgCj0YiHhwdDhw5l9OjRLz3fYDDg6urKd999R48ePV56fFhYGM7OzoSGhuLk5PTa8ac5owHWeMONg9p+xfeh2UJ9Y3pFSikWLfJn+PAdREXFAWBtbcnUqY0ZObIOlpaZp+hbCCHE60mtz29drzfExsbi7+/PmDFjTG2WlpY0bdoUPz+/JD3Gw4cPefToETlz5kywPyYmhpiYpzUnYWFhrxe03v75+mkS5FwUvL/WN55XdOdOJH37/srmzQGmtlKlcrFqVXuqVs2nY2RCCCGyEl0vjYWEhGAwGMiTJ49Ze548eQgODk7SY3zyySfkz5+fpk2bJtg/ffp0nJ2dTf88PDxeO27d3DkJhyY83rHQZo+2yXjra+3YcZGKFReYJUEDB1bj6NH+kgQJIYRIU7rXCL2OL774gtWrV/Pzzz9jZ2eX4DFjxowhNDTU9O/q1atpHGUKiYuBbd3BEKvtV/8ICtbTN6ZX8Oef/9GixUqCgyMAcHNzYPPmznz//Rs4OFjrHJ0QQoisRtdLY25ublhZWXHr1i2z9lu3bpE3b94Xnjtz5ky++OILdu3aRcWKFRM9ztbWFltb2xSJV1d+U7QRIQC38trK8hlQvXqFaNGiONu3X6RFi+IsXdpGVo0XQgihG11HhGxsbPDy8mL37t2mNqPRyO7du6ldu3ai53311Vd89tlnbN++nWrVqqVFqPq6fgj+/lLbtrSGlisgW8ZM7iwsLFi6tA3ff9+KrVu7SBIkhBBCV7pfGhsxYgSLFy9m2bJlnDt3joEDBxIZGUnv3r0B6NGjh1kx9ZdffsmECRNYsmQJnp6eBAcHExwcTEREhF5fQuqKjYDtPUAZtf06U8C9sq4hJVVwcARvvLGK3bsDzdrz5s3BwIHVZbFUIYQQutN9lrpOnTpx584dJk6cSHBwMJUrV2b79u2mAuorV65gafk0X5s/fz6xsbG88847Zo8zadIkJk+enJahp439H2vzBgHkq63VBmUAmzcH0KfPZkJCHnLiRDAnTgwgVy4HvcMSQgghzOg+j1Bay1DzCAXtgA0ttO1sDtDjOLiW0DWkl4mMjGXkyJ0sXOhvasuXLwe//vouXl75dYxMCCFERpYp5xESLxB9H3a893Tfe2a6T4L8/W/QtetGAgLumtrati3N4sWtcXOT0SAhhBDpjyRC6dXuIdrq8gCePlBpgL7xvIDBYGTmzEOMH7+HuDitlsnBwZo5c1rQp08VqQUSQgiRbkkilB4FrIXzq7RtWxdtLbF0mkxcuxZG9+4/s3dvkKnNyysfq1a1p2TJjLv+mRBCiKxB97vGxHMibsKugU/3m8wDxwL6xfMSUVGP+PtvbcFbCwsYM6Yehw71kSRICCFEhiCJUHqiFOzsC9H3tP2SHaD0u/rG9BIlSuRi7tyWeHg4sWdPT6ZNa4KNjZXeYQkhhBBJIneNpScnF8Pv72vb2fNCj1Pg4KZvTM85cuQ65cu7my2HoZQiMvIROXLY6BiZEEKIzCy1Pr9lRCi9eBAIe4c/3W/+Q7pKguLijEyZspc6dX5k1KidZn0WFhaSBAkhhMiQJBFKD4wG2N4THkVq+xX6QdE39I3pGYGB92nQYCmTJ+/DYFDMn/8Pe/Zc1jssIYQQ4rXJXWPpgf83cP2Atu1cBBp+rW88jymlWLHiJEOGbCU8XFv13srKgokTvalfv7DO0QkhhBCvTxIhvd05BQfHP96xgBbLwMZR15AA7t+PYuDA31iz5oyprWhRV1aufJtatQrqGJkQQgiRciQR0pMhFrZ11/4HqDYKCtbXNyZg374gunf/matXw0xtvXpVZu7cFjg6ZsxV74UQQoiESCKkJ78pcOeEtu1WHup+qm88aElQo0bLeHIvoaurHQsXvkmHDuX0DUwIIYRIBVIsrZcbfnDkC23b0hparoBsdvrGBNSrV4gGDbT6n0aNPDl5cqAkQUIIITItGRHSw6NI2NYDlLYuF3Umg3tlPSMysbKyZMWKdqxbd5Zhw2phaZk+l/YQQgghUoKMCOlh38fw4KK2na8WVP9YlzDu3Imkffu1HDx4xazdw8OZESNqSxIkhBAi05MRobQWtBNOfK9tZ3OAlsvBMu3fhh07LtKr1yaCgyM4evQmJ04MwMlJCqGFEEJkLTIilJai78OO957ue88A1xJpG0J0HMOGbadFi5UEB0cAEBERy4ULd9M0DiGEECI9kBGhtPTHUIjQVmqncDOoNPDFx6ewU6du0aXLRk6fvm1qa9GiOEuXtiFv3hxpGosQQgiRHkgilFYC1sG5ldq2rTP4LAGLtKnBMRoV3357mE8+2UVMjEELwdaKGTOaMWRIDSzSKA4hhBAivZFEKC1E3IRdz4z+NJkHjmkzO/PNm+H07r2JHTsumdoqVHBn1ar2lC/vniYxCCGEEOmV1AilNqXg934Q/bgGp+Q7ULpLmj39vXtR7N0bZNofPrwWR470kyRICCGEQBKh1HfqRwj8Tdt2yANN5qfZJTGAcuXcmTGjGXnz5mDHjm58840PdnYyECiEEEIAWCj1ZDGFrCEsLAxnZ2dCQ0NxcnJK3Sd7EAjLK8Ej7e4s2v4Kxd5M1ac8cSKY0qXdsLV9muwopXjwIBpXV/tUfW4hhBAitaTW57eMCKUWowG293qaBFXom6pJkMFg5MsvD1Ct2mLGjfvDrM/CwkKSICGEECIBkgilFv9ZcP1PbdvJExp+k2pPdfVqKE2aLGf06N3ExRn5+ms/Dhy48vIThRBCiCxOikVSQ8hpODju8Y4FtFwGNo6p8lRr156hf/8tPHgQrT2bBYweXY8aNQqkyvMJIYQQmYkkQinNEAtbu2v/A1QbCQUbpPjThIXF8MEH21i27ISpzcPDiRUr2uHt7ZnizyeEEEJkRpIIpTS/T+HOcW07Vzmo+1nKP4XfVbp1+5nAwPumtk6dyjF//htSCySEEEIkgyRCKenGX3BkurZtmQ1aroBsdin6FHv3BtG06XIMBu1mP0dHG+bNa0W3bhVlhmghhBAimaRYOqU8ioTtPUAZtf3akyFPlRR/mrp1PfDyyg9AnToenDgxgO7dK0kSJIQQQrwCGRFKKfs/gfv/atv5akKNT1LlaaytrVi58m3WrDnNJ5/UI1s2yWWFEEKIVyUTKqaEoN9hQ3NtO5s9dD8OOUu+9sPevx/FkCHbGDGilmkUSAiR9pRSxMXFYTAY9A5FiEzN2toaKyurBPtSa0JFGRF6XdH3YUfvp/sNZqRIErR3bxDdu//MtWth+Pvf4OjR/jg4WL/24wohkic2NpabN2/y8OFDvUMRItOzsLCgYMGC5MiRI82eUxKh1/XHBxBxXdsu1BQqD3zx8S8RG2tg4sQ9fPXVQZ6M1d2+HcmZM7epXl3mBhIiLRmNRi5fvoyVlRX58+fHxsZG6vGESCVKKe7cucO1a9coUaJEoiNDKU0SoddxYT2c+0nbtnUGnyVg8eo1OwEBIXTpspGjR2+a2ho18mT58nYULJjK66IJIeKJjY3FaDTi4eGBg4OD3uEIkenlzp2boKAgHj16JIlQuhcZDL8PeLrf+Dtw8nilh1JKsWiRP8OH7yAqKg4Aa2tLpk5tzMiRdbC0lL9AhdCTpaXclCBEWtBjxFUSoVehFOzsB9F3tf0S7aFM11d6qDt3Iunb91c2bw4wtZUqlYtVq9pTtWq+lIhWCCGEEImQROhVnF4CgVu0bYc80HS+tsjXK7h6NYytW/817Q8cWI2ZM5tLYbQQQgiRBmS8N7lCL8OeYU/3my8Gh9yv/HBVq+bj888b4ebmwObNnfn++zckCRJCCB0FBASQN29ewsPD9Q4lU4mNjcXT05N//vlH71DMSCKUHEYDbOsJjyK0/fJ9oFjrZD3E+fMhPHpkPhfJqFF1OHNmEK1bl0qpSIUQWVyvXr2wsLDAwsICa2trihQpwscff0x0dHS8Y7ds2YK3tzeOjo44ODhQvXp1fH19E3zcDRs20LBhQ5ydncmRIwcVK1bk008/5d69e6n8FaWdMWPGMHToUBwdHfUOJdXMmzcPT09P7OzsqFmzJkeOHHnpOQ8ePGDw4MHky5cPW1tbSpYsydatWxM89osvvsDCwoJhw4aZ2mxsbBg1ahSffJI6Ew6/KkmEkuPobLj+p7bt5AkNv0nyqUajYs6cv6hceQGff77frM/KyhJ39+wpF6cQQgAtWrTg5s2bBAYGMmvWLBYuXMikSZPMjvn2229p06YNdevW5fDhw5w8eZLOnTszYMAARo0aZXbsuHHj6NSpE9WrV2fbtm2cPn2ar7/+mhMnTrBixYo0+7piY2NT7bGvXLnCli1b6NWr12s9TmrG+LrWrFnDiBEjmDRpEkePHqVSpUr4+Phw+/btRM+JjY2lWbNmBAUFsX79egICAli8eDEFCsSf1uXvv/9m4cKFVKxYMV5f165dOXDgAGfOnEnRr+m1qCwmNDRUASo0NDR5J945pdQsG6VmotRMC6Wu7E3yqTduhCkfnxUKJiuYrCwtp6jDh68lM3IhRFqLiopSZ8+eVVFRUXqHkmw9e/ZUbdq0MWt7++23VZUqVUz7V65cUdbW1mrEiBHxzp87d64C1F9//aWUUurw4cMKULNnz07w+e7fv59oLFevXlWdO3dWrq6uysHBQXl5eZkeN6E4P/zwQ+Xt7W3a9/b2VoMHD1YffvihypUrl2rYsKF69913VceOHc3Oi42NVbly5VLLli1TSillMBjUtGnTlKenp7Kzs1MVK1ZU69atSzROpZSaMWOGqlatmllbSEiI6ty5s8qfP7+yt7dX5cuXV6tWrTI7JqEYlVLq1KlTqkWLFip79uzK3d1ddevWTd25c8d03rZt21TdunWVs7Ozypkzp3rjjTfUxYsXXxjj66pRo4YaPHiwad9gMKj8+fOr6dOnJ3rO/PnzVdGiRVVsbOwLHzs8PFyVKFFC/f7778rb21t9+OGH8Y5p1KiRGj9+fILnv+hn7pU/v19CiqWTwhAL23po/wN4jQAP7ySdumnTefr2/ZWQkKez0n7wQQ0qVsyTGpEKIdLCT9W0KTTSWva80O3V6itOnz7NoUOHKFy4sKlt/fr1PHr0KN7ID0D//v0ZO3Ys//vf/6hZsyYrV64kR44cDBo0KMHHd3FxSbA9IiICb29vChQowObNm8mbNy9Hjx7FaDQmK/5ly5YxcOBADh48CMDFixfp0KEDERERplmId+zYwcOHD2nXrh0A06dP56effmLBggWUKFGC/fv3061bN3Lnzo23d8K/w//880+qVatm1hYdHY2XlxeffPIJTk5O/Pbbb3Tv3p1ixYpRo0aNRGN88OABjRs3pm/fvsyaNYuoqCg++eQTOnbsyB9//AFAZGQkI0aMoGLFikRERDBx4kTatWvH8ePHE522Ydq0aUybNu2Fr9fZs2cpVKhQvPbY2Fj8/f0ZM2aMqc3S0pKmTZvi5+eX6ONt3ryZ2rVrM3jwYDZt2kTu3Lnp0qULn3zyidl8P4MHD+aNN96gadOmfP755wk+Vo0aNfjzzz9fGH9akkQoKf76DG4f07ZzlYV6Cb+5z4qMjGXkyJ0sXOhvasubNwfLlrWlefNiqRWpECItRAY/nVE+HduyZQs5cuQgLi6OmJgYLC0t+e6770z9Fy5cwNnZmXz54k/VYWNjQ9GiRblw4QIA//77L0WLFsXaOnk3c6xatYo7d+7w999/kzNnTgCKFy+e7K+lRIkSfPXVV6b9YsWKkT17dn7++We6d+9ueq633noLR0dHYmJimDZtGrt27aJ27doAFC1alAMHDrBw4cJEE6H//vsvXiJUoEABs2Rx6NCh7Nixg7Vr15olQs/H+Pnnn1OlShWzpGXJkiV4eHhw4cIFSpYsSfv27c2ea8mSJeTOnZuzZ89Svnz5BGMcMGAAHTt2fOHrlT9/wutThoSEYDAYyJPH/I/xPHnycP78+UQfLzAwkD/++IOuXbuydetWLl68yKBBg3j06JHpcuvq1as5evQof//990tj+++//154TFqSROhlbvwFhx9/E1tmg5YrIJvdC0/x979Bly4buXDhrqmtTZtS/PDDW7i5yey0QmR42fNmiOdt1KgR8+fPJzIyklmzZpEtW7Z4H7xJpV5xfe7jx49TpUoVUxL0qry8vMz2s2XLRseOHVm5ciXdu3cnMjKSTZs2sXr1akAbMXr48CHNmjUzOy82NpYqVaok+jxRUVHY2Zn/jjcYDEybNo21a9dy/fp1YmNjiYmJiTfb+PMxnjhxgj179iS4btalS5coWbIk//77LxMnTuTw4cOEhISYRsquXLmSaCKUM2fO1349k8toNOLu7s6iRYuwsrLCy8uL69evM2PGDCZNmsTVq1f58MMP+f333+O9fs+zt7dPV2v3SSL0Io8ewvYeoB4P4daeBHmqvvCUP/64jI/PT8TFaec4OFgze7YPfftWlTWKhMgsXvHyVFrLnj27afRlyZIlVKpUiR9//JE+ffoAULJkSUJDQ7lx40a8EYTY2FguXbpEo0aNTMceOHCAR48eJWtUyN7e/oX9lpaW8ZKsR48eJfi1PK9r1654e3tz+/Ztfv/9d+zt7WnRogWgXZID+O233+IV9Nra2iYaj5ubG/fv3zdrmzFjBnPmzGH27NlUqFCB7NmzM2zYsHgF0c/HGBERQevWrfnyyy/jPc+TUbjWrVtTuHBhFi9eTP78+TEajZQvX/6Fxdavc2nMzc0NKysrbt26ZdZ+69Yt8uZNPNHOly9fvJXhy5QpQ3BwsOly2+3bt6la9elnpMFgYP/+/Xz33XfExMSYzr137x65c7/6tDMpTe4ae5H9n8D9x5Md5q0BNUa/9JS6dT0oW1Z7g7288nHsWH/69fOSJEgIoStLS0vGjh3L+PHjiYqKAqB9+/ZYW1vz9ddfxzt+wYIFREZG8u677wLQpUsXIiIi+P777xN8/AcPHiTYXrFiRY4fP57o7fW5c+fm5s2bZm3Hjx9P0tdUp04dPDw8WLNmDStXrqRDhw6mJK1s2bLY2tpy5coVihcvbvbPwyPx5ZCqVKnC2bNnzdoOHjxImzZt6NatG5UqVTK7ZPgiVatW5cyZM3h6esaLIXv27Ny9e5eAgADGjx9PkyZNKFOmTLwkLCEDBgzg+PHjL/yX2KUxGxsbvLy82L17t6nNaDSye/du0yXEhNStW5eLFy+a1XZduHCBfPnyYWNjQ5MmTTh16pRZDNWqVaNr164cP37cLIE6ffr0C0fl0lyKll5nAEmuOg/6/fEdYig1216pu+eT/BynT99S48btVjExca8ZrRBCT5ntrrFHjx6pAgUKqBkzZpjaZs2apSwtLdXYsWPVuXPn1MWLF9XXX3+tbG1t1ciRI83O//jjj5WVlZX66KOP1KFDh1RQUJDatWuXeueddxK9mywmJkaVLFlS1a9fXx04cEBdunRJrV+/Xh06dEgppdT27duVhYWFWrZsmbpw4YKaOHGicnJyinfXWEJ3Hyml1Lhx41TZsmVVtmzZ1J9//hmvL1euXMrX11ddvHhR+fv7q7lz5ypfX99EX7fNmzcrd3d3FRf39Pf38OHDlYeHhzp48KA6e/as6tu3r3JycjJ7fROK8fr16yp37tzqnXfeUUeOHFEXL15U27dvV7169VJxcXHKYDCoXLlyqW7duql///1X7d69W1WvXl0B6ueff040xte1evVqZWtrq3x9fdXZs2fV+++/r1xcXFRwcLDpmO7du6vRo0eb9q9cuaIcHR3VkCFDVEBAgNqyZYtyd3dXn3/+eaLPk9j7VrhwYbV8+fIEz9HjrjFJhBISdV+pBQWfJkL+cxN5rGjVt+8mdfr0rdQJVgihq8yWCCml1PTp01Xu3LlVRESEqW3Tpk2qfv36Knv27MrOzk55eXmpJUuWJPi4a9asUQ0aNFCOjo4qe/bsqmLFiurTTz994e3zQUFBqn379srJyUk5ODioatWqqcOHD5v6J06cqPLkyaOcnZ3V8OHD1ZAhQ5KcCJ09e1YBqnDhwspoNJr1GY1GNXv2bFWqVCllbW2tcufOrXx8fNS+ffsSjfXRo0cqf/78avv27aa2u3fvqjZt2qgcOXIod3d3NX78eNWjR4+XJkJKKXXhwgXVrl075eLiouzt7VXp0qXVsGHDTLH+/vvvqkyZMsrW1lZVrFhR7d27N9UTIaWU+vbbb1WhQoWUjY2NqlGjhmk6g2e/np49e5q1HTp0SNWsWVPZ2tqqokWLqqlTp5oljM9L6DU5dOiQcnFxUQ8fPkzwHD0SIQulXrECLoMKCwvD2dmZ0NBQnJycEj5oWw84+3hysEJN4J2dYGF+FdHP7yrduv1MYOB9KlbMw5EjfbG1lZIrITKT6OhoLl++TJEiRV5aACoyj3nz5rF582Z27NihdyiZTqdOnahUqRJjx45NsP9FP3NJ+vx+BVIj9LwLG54mQbbO4LPULAmKizMyZcpe6tdfSmCgdi338uX7nDx5K6FHE0IIkcH079+fBg0ayFpjKSw2NpYKFSowfPhwvUMxI0MYz4oMht/7P91v/C04PS2qCwy8T7duG/Hzu2Zqq1PHg59+akeRIq5pGakQQohUki1bNsaNG6d3GJmOjY0N48eP1zuMeCQRekIp2Pk+RD+e+6fE21Cm2+MuxYoVJxkyZCvh4dotjVZWFkyc6M3YsfXJlk0G1oQQQoiMSBKhJ04vhcBftW0Hd2i6ACwsuH8/ioEDf2PNmqcLxBUt6srKlW9Tq1ZBnYIVQgghREqQRAgg9DLs+fDpfrPF4KDNBXTuXAjr1j2dU6JXr8rMndsCR8fEJ+QSQmQuWeyeEiF0o8fPmlzTUUbY3gseabOQUv49KP6WqbtOHQ/GjauPi4sda9e+w9KlbSQJEiKLeDI5X3paDkCIzOzJjNrPTsCY2mREyH82XNuvbTsV5nLhyRQyGLGyepojTpjQgP79vShQIOVu1xNCpH9WVla4uLhw+/ZtABwcHGSWeCFSidFo5M6dOzg4OJAtW9qlJ1k7EQo5Awe0uQyUsmBRyHSGV13OpEnefPJJPdNh1tZWkgQJkUU9WX/pSTIkhEg9lpaWFCpUKE3/4Mi6Eyreu4PTluZw+xh3Ihzou3M4mw9pw+DZslly5EhfqlTJp3O0Qoj0wmAwJLgYqBAi5djY2GBpmXDVTmpNqJguRoTmzZvHjBkzCA4OplKlSnz77bfUqFEj0ePXrVvHhAkTCAoKokSJEnz55Ze0atUqeU/69wy4fYwdAcXotfYdgkOfrqbct28VSpVye9UvRwiRCVlZWaVp3YIQIm3oXiy9Zs0aRowYwaRJkzh69CiVKlXCx8cn0WHoQ4cO8e6779KnTx+OHTtG27Ztadu2LadPn07W80b7zWLYpha0WNyd4FB7ANzcHNi8uTPz57+Jg4P1Sx5BCCGEEBmd7pfGatasSfXq1fnuu+8ArVjKw8ODoUOHMnr06HjHd+rUicjISLZs2WJqq1WrFpUrV2bBggUvfb4nQ2tl3Ptw7vbTWaNbtCjO0qVtyJs3Rwp8VUIIIYRISZlyrbHY2Fj8/f1p2rSpqc3S0pKmTZvi5+eX4Dl+fn5mxwP4+Pgkenxizt3W5gmytbVi7twWbN3aRZIgIYQQIovRtUYoJCQEg8FAnjx5zNrz5MnD+fPnEzwnODg4weODg4MTPD4mJoaYmBjTfmho6JMeypZy5kffDpQtm1sW1xNCCCHSsbCwMCDlJ11MF8XSqWn69OlMmTIlgZ5ZnA2A2rXHpHlMQgghhHg1d+/exdnZOcUeT9dEyM3NDSsrK27dumXWfuvWLdPcHc/Lmzdvso4fM2YMI0aMMO0/ePCAwoULc+XKlRR9IUXyhYWF4eHhwdWrV1P0eq94NfJ+pB/yXqQf8l6kH6GhoRQqVIicOXOm6OPqmgjZ2Njg5eXF7t27adu2LaAVS+/evZshQ4YkeE7t2rXZvXs3w4YNM7X9/vvv1K5dO8HjbW1tsbWNvySGs7OzfFOnE05OTvJepCPyfqQf8l6kH/JepB+JzTP0qnS/NDZixAh69uxJtWrVqFGjBrNnzyYyMpLevXsD0KNHDwoUKMD06dMB+PDDD/H29ubrr7/mjTfeYPXq1fzzzz8sWrRIzy9DCCGEEBmQ7olQp06duHPnDhMnTiQ4OJjKlSuzfft2U0H0lStXzLK/OnXqsGrVKsaPH8/YsWMpUaIEv/zyC+XLl9frSxBCCCFEBqV7IgQwZMiQRC+F7d27N15bhw4d6NChwys9l62tLZMmTUrwcplIW/JepC/yfqQf8l6kH/JepB+p9V7oPqGiEEIIIYRedF9iQwghhBBCL5IICSGEECLLkkRICCGEEFmWJEJCCCGEyLIyZSI0b948PD09sbOzo2bNmhw5cuSFx69bt47SpUtjZ2dHhQoV2Lp1axpFmvkl571YvHgx9evXx9XVFVdXV5o2bfrS904kT3J/Np5YvXo1FhYWpolPxetL7nvx4MEDBg8eTL58+bC1taVkyZLyuyqFJPe9mD17NqVKlcLe3h4PDw+GDx9OdHR0GkWbee3fv5/WrVuTP39+LCws+OWXX156zt69e6latSq2trYUL14cX1/f5D+xymRWr16tbGxs1JIlS9SZM2dUv379lIuLi7p161aCxx88eFBZWVmpr776Sp09e1aNHz9eWVtbq1OnTqVx5JlPct+LLl26qHnz5qljx46pc+fOqV69eilnZ2d17dq1NI48c0ru+/HE5cuXVYECBVT9+vVVmzZt0ibYTC6570VMTIyqVq2aatWqlTpw4IC6fPmy2rt3rzp+/HgaR575JPe9WLlypbK1tVUrV65Uly9fVjt27FD58uVTw4cPT+PIM5+tW7eqcePGqY0bNypA/fzzzy88PjAwUDk4OKgRI0aos2fPqm+//VZZWVmp7du3J+t5M10iVKNGDTV48GDTvsFgUPnz51fTp09P8PiOHTuqN954w6ytZs2aqn///qkaZ1aQ3PfieXFxccrR0VEtW7YstULMUl7l/YiLi1N16tRRP/zwg+rZs6ckQikkue/F/PnzVdGiRVVsbGxahZhlJPe9GDx4sGrcuLFZ24gRI1TdunVTNc6sJimJ0Mcff6zKlStn1tapUyfl4+OTrOfKVJfGYmNj8ff3p2nTpqY2S0tLmjZtip+fX4Ln+Pn5mR0P4OPjk+jxImle5b143sOHD3n06FGKL7CXFb3q+/Hpp5/i7u5Onz590iLMLOFV3ovNmzdTu3ZtBg8eTJ48eShfvjzTpk3DYDCkVdiZ0qu8F3Xq1MHf3990+SwwMJCtW7fSqlWrNIlZPJVSn9/pYmbplBISEoLBYDAtz/FEnjx5OH/+fILnBAcHJ3h8cHBwqsWZFbzKe/G8Tz75hPz588f7RhfJ9yrvx4EDB/jxxx85fvx4GkSYdbzKexEYGMgff/xB165d2bp1KxcvXmTQoEE8evSISZMmpUXYmdKrvBddunQhJCSEevXqoZQiLi6OAQMGMHbs2LQIWTwjsc/vsLAwoqKisLe3T9LjZKoRIZF5fPHFF6xevZqff/4ZOzs7vcPJcsLDw+nevTuLFy/Gzc1N73CyPKPRiLu7O4sWLcLLy4tOnToxbtw4FixYoHdoWc7evXuZNm0a33//PUePHmXjxo389ttvfPbZZ3qHJl5RphoRcnNzw8rKilu3bpm137p1i7x58yZ4Tt68eZN1vEiaV3kvnpg5cyZffPEFu3btomLFiqkZZpaR3Pfj0qVLBAUF0bp1a1Ob0WgEIFu2bAQEBFCsWLHUDTqTepWfjXz58mFtbY2VlZWprUyZMgQHBxMbG4uNjU2qxpxZvcp7MWHCBLp3707fvn0BqFChApGR/2/v7oOiqt44gH9ZdF9admHIGHZlfQGDGielRWmAGsKXWCeTfEOLURCSBkKcGi2mzIUMtRIadKykRlBieHMqnBggMZiBdUpUFhrBRRCkxi2ncEAUBHaf3x8N9+fKS6L+sB/7fGbuH/fec859zj3D7DPnnsu9gdjYWLz33ns2Hwln/1uj/X4rlcq7ng0CJtmMkFgshp+fH06ePCkcs1qtOHnyJAICAkasExAQYFMeAE6cODFqeXZ37mUsAODjjz/Grl27UFZWhgULFkxEqHZhvOPxxBNP4JdffoHRaBS2FStWICQkBEajERqNZiLDn1Tu5W8jKCgILS0tQjIKAM3NzVCpVJwE3Yd7GYubN28OS3aGElTiT3dOqAf2+z2+ddz/fvn5+SSRSCg7O5saGxspNjaWXFxc6Pfffyciog0bNlBSUpJQ3mAw0JQpU2jfvn3U1NREer2eX59/QMY7Fnv37iWxWEzHjh0js9ksbNevX39YXZhUxjsed+K3xh6c8Y5FR0cHKRQKSkhIIJPJRN9//z25ubnRhx9++LC6MGmMdyz0ej0pFArKy8ujS5cu0Q8//EBeXl4UHh7+sLowaVy/fp3q6uqorq6OAFB6ejrV1dXR5cuXiYgoKSmJNmzYIJQfen1++/bt1NTURAcPHuTX54ccOHCAZsyYQWKxmPz9/emnn34SzgUHB1NkZKRN+cLCQvL29iaxWExz586lkpKSCY548hrPWMycOZMADNv0ev3EBz5Jjfdv43acCD1Y4x2LU6dO0TPPPEMSiYQ8PT0pNTWVBgcHJzjqyWk8YzEwMEDJycnk5eVFUqmUNBoNxcfH07Vr1yY+8EmmsrJyxN+AofsfGRlJwcHBw+r4+vqSWCwmT09PysrKGvd1HYh4Lo8xxhhj9mlSrRFijDHGGBsPToQYY4wxZrc4EWKMMcaY3eJEiDHGGGN2ixMhxhhjjNktToQYY4wxZrc4EWKMMcaY3eJEiDFmIzs7Gy4uLg87jHvm4OCA7777bswyUVFRePnllyckHsbYvxsnQoxNQlFRUXBwcBi2tbS0POzQkJ2dLcQjEong4eGBTZs24erVqw+kfbPZjGXLlgEA2tvb4eDgAKPRaFMmIyMD2dnZD+R6o0lOThb66ejoCI1Gg9jYWHR2do6rHU7aGPvfmlRfn2eM/ZdOp0NWVpbNsccee+whRWNLqVTCZDLBarWivr4emzZtwpUrV1BeXn7fbY/21fDbOTs73/d17sbcuXNRUVEBi8WCpqYmREdHo6urCwUFBRNyfcbYP+MZIcYmKYlEAnd3d5vN0dER6enpeOqppyCXy6HRaBAfH4+enp5R26mvr0dISAgUCgWUSiX8/Pxw5swZ4XxNTQ2ee+45yGQyaDQaJCYm4saNG2PG5uDgAHd3d6jVaixbtgyJiYmoqKhAb28vrFYrPvjgA3h4eEAikcDX1xdlZWVC3f7+fiQkJEClUkEqlWLmzJnYs2ePTdtDj8Zmz54NAHj66afh4OCA559/HoDtLEtmZibUarXNl90BICwsDNHR0cJ+cXExtFotpFIpPD09kZKSgsHBwTH7OWXKFLi7u2P69OlYsmQJ1q5dixMnTgjnLRYLYmJiMHv2bMhkMvj4+CAjI0M4n5ycjCNHjqC4uFiYXaqqqgIA/PrrrwgPD4eLiwtcXV0RFhaG9vb2MeNhjA3HiRBjdkYkEmH//v04f/48jhw5gh9//BFvv/32qOUjIiLg4eGB2tpanD17FklJSZg6dSoAoLW1FTqdDqtXr0ZDQwMKCgpQU1ODhISEccUkk8lgtVoxODiIjIwMpKWlYd++fWhoaEBoaChWrFiBixcvAgD279+P48ePo7CwECaTCbm5uZg1a9aI7Z4+fRoAUFFRAbPZjG+++WZYmbVr1+Kvv/5CZWWlcKyzsxNlZWWIiIgAAFRXV2Pjxo3YunUrGhsbcejQIWRnZyM1NfWu+9je3o7y8nKIxWLhmNVqhYeHB4qKitDY2IidO3fi3XffRWFhIQBg27ZtCA8Ph06ng9lshtlsRmBgIAYGBhAaGgqFQoHq6moYDAY4OTlBp9Ohv7//rmNijAGT8uvzjNm7yMhIcnR0JLlcLmxr1qwZsWxRURE9+uijwn5WVhY5OzsL+wqFgrKzs0esGxMTQ7GxsTbHqqurSSQSUW9v74h17my/ubmZvL29acGCBUREpFarKTU11abOwoULKT4+noiItmzZQosWLSKr1Tpi+wDo22+/JSKitrY2AkB1dXU2ZSIjIyksLEzYDwsLo+joaGH/0KFDpFaryWKxEBHR4sWLaffu3TZt5OTkkEqlGjEGIiK9Xk8ikYjkcjlJpVLhS9rp6emj1iEieuONN2j16tWjxjp0bR8fH5t7cOvWLZLJZFReXj5m+4wxW7xGiLFJKiQkBJ9//rmwL5fLAfw9O7Jnzx5cuHAB3d3dGBwcRF9fH27evIlHHnlkWDtvvfUWXnvtNeTk5AiPd7y8vAD8/disoaEBubm5QnkigtVqRVtbG5588skRY+vq6oKTkxOsViv6+vrw7LPP4quvvkJ3dzeuXLmCoKAgm/JBQUGor68H8PdjraVLl8LHxwc6nQ7Lly/HCy+8cF/3KiIiAps3b8Znn30GiUSC3NxcrF+/HiKRSOinwWCwmQGyWCxj3jcA8PHxwfHjx9HX14evv/4aRqMRW7ZssSlz8OBBHD58GB0dHejt7UV/fz98fX3HjLe+vh4tLS1QKBQ2x/v6+tDa2noPd4Ax+8WJEGOTlFwux5w5c2yOtbe3Y/ny5YiLi0NqaipcXV1RU1ODmJgY9Pf3j/iDnpycjFdffRUlJSUoLS2FXq9Hfn4+Vq5ciZ6eHrz++utITEwcVm/GjBmjxqZQKHDu3DmIRCKoVCrIZDIAQHd39z/2S6vVoq2tDaWlpaioqEB4eDiWLFmCY8eO/WPd0bz00ksgIpSUlGDhwoWorq7Gp59+Kpzv6elBSkoKVq1aNayuVCodtV2xWCyMwd69e/Hiiy8iJSUFu3btAgDk5+dj27ZtSEtLQ0BAABQKBT755BP8/PPPY8bb09MDPz8/mwR0yL9lQTxj/y84EWLMjpw9exZWqxVpaWnCbMfQepSxeHt7w9vbG2+++SZeeeUVZGVlYeXKldBqtWhsbByWcP0TkUg0Yh2lUgm1Wg2DwYDg4GDhuMFggL+/v025devWYd26dVizZg10Oh06Ozvh6upq097QehyLxTJmPFKpFKtWrUJubi5aWlrg4+MDrVYrnNdqtTCZTOPu55127NiBRYsWIS4uTuhnYGAg4uPjhTJ3zuiIxeJh8Wu1WhQUFMDNzQ1KpfK+YmLM3vFiacbsyJw5czAwMIADBw7g0qVLyMnJwRdffDFq+d7eXiQkJKCqqgqXL1+GwWBAbW2t8MjrnXfewalTp5CQkACj0YiLFy+iuLh43Iulb7d9+3Z89NFHKCgogMlkQlJSEoxGI7Zu3QoASE9PR15eHi5cuIDm5mYUFRXB3d19xH8C6ebmBplMhrKyMvzxxx/o6uoa9boREREoKSnB4cOHhUXSQ3bu3ImjR48iJSUF58+fR1NTE/Lz87Fjx45x9S0gIADz5s3D7t27AQCPP/44zpw5g/LycjQ3N+P9999HbW2tTZ1Zs2ahoaEBJpMJf/75JwYGBhAREYFp06YhLCwM1dXVaGtrQ1VVFRITE/Hbb7+NKybG7N7DXqTEGHvwRlpgOyQ9PZ1UKhXJZDIKDQ2lo0ePEgC6du0aEdkuZr516xatX7+eNBoNicViUqvVlJCQYLMQ+vTp07R06VJycnIiuVxO8+bNG7bY+XZ3Lpa+k8VioeTkZJo+fTpNnTqV5s+fT6WlpcL5zMxM8vX1JblcTkqlkhYvXkznzp0TzuO2xdJERF9++SVpNBoSiUQUHBw86v2xWCykUqkIALW2tg6Lq6ysjAIDA0kmk5FSqSR/f3/KzMwctR96vZ7mz58/7HheXh5JJBLq6Oigvr4+ioqKImdnZ3JxcaG4uDhKSkqyqXf16lXh/gKgyspKIiIym820ceNGmjZtGkkkEvL09KTNmzdTV1fXqDExxoZzICJ6uKkYY4wxxtjDwY/GGGOMMWa3OBFijDHGmN3iRIgxxhhjdosTIcYYY4zZLU6EGGOMMWa3OBFijDHGmN3iRIgxxhhjdosTIcYYY4zZLU6EGGOMMWa3OBFijDHGmN3iRIgxxhhjdosTIcYYY4zZrf8Atfy+1gHqy+gAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_predictedNaive = modelNaive.predict(X_test)\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, y_predictedNaive)\n",
    "\n",
    "# Tính AUC\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Vẽ đường ROC\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (NaiveB)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"../static/app/images/ROCNaiveBayes.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VII. Áp dụng DP vào 2 mô hình tiềm năng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from diffprivlib.models import GaussianNB as DPGaussianNB\n",
    "\n",
    "class NaiveBayesModelDP:\n",
    "    def __init__(self, epsilon=1.0):\n",
    "        self.epsilon = epsilon  # Tham số epsilon cho DP\n",
    "        self.model = DPGaussianNB(epsilon=self.epsilon)\n",
    "        self.is_trained = False\n",
    "\n",
    "    def train(self, X_train, y_train):\n",
    "        self.model.fit(X_train, y_train)\n",
    "        self.is_trained = True\n",
    "\n",
    "    def predict(self, X_test):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model has not been trained yet. Please train the model before making predictions.\")\n",
    "        return self.model.predict(X_test)\n",
    "\n",
    "    def evaluate(self, X_test, y_test):\n",
    "        if not self.is_trained:\n",
    "            raise ValueError(\"Model has not been trained yet. Please train the model before evaluation.\")\n",
    "\n",
    "        y_pred = self.predict(X_test)\n",
    "        # Tạo ma trận nhầm lẫn\n",
    "        cm = confusion_matrix(y_test, y_pred)\n",
    "        # Tạo heatmap từ ma trận nhầm lẫn\n",
    "        plt.figure(figsize=(5, 4))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=['Predicted 0', 'Predicted 1'], yticklabels=['Actual 0', 'Actual 1'])\n",
    "        plt.xlabel('Predicted Label')\n",
    "        plt.ylabel('True Label')\n",
    "        plt.title('Confusion Matrix (Naive)')\n",
    "        plt.show()\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\diffprivlib\\models\\naive_bayes.py:107: PrivacyLeakWarning: Bounds have not been specified and will be calculated on the data provided. This will result in additional privacy leakage. To ensure differential privacy and no additional privacy leakage, specify bounds for each dimension.\n",
      "  warnings.warn(\"Bounds have not been specified and will be calculated on the data provided. This will \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.6412650720710107\n",
      "F1_score = 0.17956656346749225\n",
      "Recall = 0.5370370370370371\n",
      "Precision = 0.10780669144981413\n"
     ]
    }
   ],
   "source": [
    "modelNaive1 = NaiveBayesModelDP()\n",
    "modelNaive1.train(X_train,y_train)\n",
    "yResultNaive1 = modelNaive1.evaluate(X_test,y_test)\n",
    "NaiveResult1 = evaluateModel(y_test,yResultNaive1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegressionDP:\n",
    "    def __init__(self,model,X_train,y_train, X_test, y_test, EPSILON = 1.0,DELTA = 1e-5, EPOCHS = 10, MAX_GRAD_NORM = 0.1, MAX_PHYSICAL_BATCH_SIZE = 256, LOGGING_INTERVAL = 100,learning_rate=0.01, num_epochs=100):\n",
    "        self.EPSILON=EPSILON\n",
    "        self.DELTA=DELTA\n",
    "        self.EPOCHS=EPOCHS\n",
    "        self.MAX_GRAD_NORM=MAX_GRAD_NORM\n",
    "        self.MAX_PHYSICAL_BATCH_SIZE = MAX_PHYSICAL_BATCH_SIZE\n",
    "        self.LOGGING_INTERVAL=LOGGING_INTERVAL\n",
    "        self.X_train=X_train\n",
    "        self.y_train=y_train\n",
    "        self.X_test=X_test\n",
    "        self.y_test=y_test\n",
    "        self.learning_rate=learning_rate\n",
    "        self.model=model\n",
    "        self.num_epochs=num_epochs\n",
    "        self.device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        self.status=False\n",
    "    def preTrain(self):\n",
    "        train_dataset = TensorDataset(self.X_train, self.y_train)\n",
    "        train_dataloader = DataLoader(train_dataset, batch_size=self.MAX_PHYSICAL_BATCH_SIZE, shuffle=True)\n",
    "        model = self.model.to(self.device)\n",
    "        criterion = nn.BCELoss()\n",
    "        optimizer = torch.optim.SGD(model.parameters(),lr=self.learning_rate)\n",
    "        model = model.train()\n",
    "        return train_dataloader,model,optimizer,criterion\n",
    "    def train_model(self):\n",
    "        from opacus import PrivacyEngine\n",
    "        \n",
    "        privacy_engine = PrivacyEngine()\n",
    "        train_dataloader,model,optimizer,criterion= self.preTrain()\n",
    "        model, optimizer, data_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_dataloader,\n",
    "            target_delta=self.DELTA,\n",
    "            target_epsilon=self.EPSILON, \n",
    "            epochs=self.EPOCHS,\n",
    "            max_grad_norm=self.MAX_GRAD_NORM,\n",
    "        )\n",
    "        print(f\"Training with hyperparameters:\")\n",
    "        print(f\"  EPSILON: {self.EPSILON}\")\n",
    "        print(f\"  DELTA: {self.DELTA}\")\n",
    "        print(f\"  EPOCHS: {self.EPOCHS}\")\n",
    "        print(f\"  MAX_GRAD_NORM: {self.MAX_GRAD_NORM}\")\n",
    "        print(f\"  MAX_PHYSICAL_BATCH_SIZE: {self.MAX_PHYSICAL_BATCH_SIZE}\")\n",
    "        print(f\"  LOGGING_INTERVAL: {self.LOGGING_INTERVAL}\")\n",
    "        print(f\"  learning_rate: {self.learning_rate}\")\n",
    "        print(f\"  num_epochs: {self.num_epochs}\")\n",
    "        num_epochs = self.num_epochs\n",
    "        lossesLogDP = []  # Danh sách lưu giữ giá trị loss\n",
    "        epsilons = []  # Danh sách lưu giữ giá trị epsilon\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            for step,(X_batch, y_batch) in enumerate(data_loader):\n",
    "                X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "                y_predicted = model(X_batch)\n",
    "                loss = criterion(y_predicted,y_batch)\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                if step >= 0 and step % self.LOGGING_INTERVAL == 0:\n",
    "                    eps = privacy_engine.get_epsilon(self.DELTA)\n",
    "                    if(epoch+1) % 10 ==0:\n",
    "                        print(f\"epoch: {epoch+1}, loss={loss.item():.4f}  | ɛ: {eps:.2f} \")\n",
    "                        \n",
    "                    lossesLogDP.append(loss.item())\n",
    "                    epsilons.append(eps)\n",
    "        with torch.no_grad():\n",
    "            y_predicted = model(self.X_test.to(self.device))\n",
    "            y_predicted_cls = y_predicted.round()\n",
    "            evalLogDP=evaluateModel(y_predicted_cls,y_test)\n",
    "            print(evalLogDP)\n",
    "        if self.status == True:\n",
    "            torch.save(model, './StruckPredict.pth')\n",
    "        epochs = range(1, num_epochs + 1)\n",
    "        plt.figure(figsize=(12, 6))\n",
    "\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, lossesLogDP, label='Loss', marker='o')\n",
    "        plt.title('Loss Over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, epsilons, label='Epsilon', marker='o')\n",
    "        plt.title('Epsilon Over Epochs')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Epsilon')\n",
    "        plt.legend()\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('../static/app/images/epsilonAndLoss.JPG')\n",
    "        plt.show()\n",
    "        return lossesLogDP,epsilons,y_predicted\n",
    "    def predict_model(self, X):\n",
    "        with torch.no_grad():\n",
    "            y_predicted = self.model(X.to(self.device))\n",
    "            y_predicted_cls = y_predicted.round()\n",
    "            return y_predicted_cls\n",
    "    def train_model_for_grid(self):\n",
    "        from opacus import PrivacyEngine\n",
    "        \n",
    "        privacy_engine = PrivacyEngine()\n",
    "        train_dataloader,model,optimizer,criterion= self.preTrain()\n",
    "        model, optimizer, data_loader = privacy_engine.make_private_with_epsilon(\n",
    "            module=model,\n",
    "            optimizer=optimizer,\n",
    "            data_loader=train_dataloader,\n",
    "            target_delta=self.DELTA,\n",
    "            target_epsilon=self.EPSILON, \n",
    "            epochs=self.EPOCHS,\n",
    "            max_grad_norm=self.MAX_GRAD_NORM,\n",
    "        )\n",
    "        num_epochs = self.num_epochs\n",
    "        for epoch in range(num_epochs):\n",
    "            for step,(X_batch, y_batch) in enumerate(data_loader):\n",
    "                X_batch, y_batch = X_batch.to(self.device), y_batch.to(self.device)\n",
    "                y_predicted = model(X_batch)\n",
    "                loss = criterion(y_predicted,y_batch)\n",
    "                \n",
    "                loss.backward()\n",
    "                \n",
    "                optimizer.step()\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "        with torch.no_grad():\n",
    "            y_predicted = model(self.X_test.to(self.device))\n",
    "            y_predicted_cls = y_predicted.round()\n",
    "            eval = evaluateModel(y_predicted_cls,y_test)\n",
    "            auc,f1= eval['roc_auc_score'], eval['F1_score']\n",
    "        return auc,f1\n",
    "    def grid_search(self,num_features):\n",
    "        from sklearn.model_selection import ParameterGrid\n",
    "        bestAuc = 0\n",
    "        bestF1 = 0\n",
    "        best_params = None\n",
    "        param_grid = {\n",
    "        'EPSILON': [1.0, 0.5],\n",
    "        'DELTA': [1e-5, 1e-6],\n",
    "        'EPOCHS': [10, 20],\n",
    "        'MAX_GRAD_NORM': [0.1, 0.2],\n",
    "        'MAX_PHYSICAL_BATCH_SIZE': [256, 512],\n",
    "        'LOGGING_INTERVAL': [100, 200],\n",
    "        'learning_rate': [0.01, 0.001],\n",
    "        'num_epochs': [50, 100]\n",
    "        }\n",
    "        all_params = list(ParameterGrid(param_grid))\n",
    "        total_combinations = len(all_params)\n",
    "\n",
    "        for i, params in enumerate(all_params, 1):\n",
    "            print(f\"Training model {i}/{total_combinations} with parameters: {params}\")\n",
    "            modelTemp=LogisticRegression(num_features)\n",
    "            logDPTemp=LogisticRegressionDP(modelTemp,X_train,y_train,X_test,y_test,params['EPSILON'],params['DELTA'],params['EPOCHS'],params['MAX_GRAD_NORM'],\n",
    "                                           params['MAX_PHYSICAL_BATCH_SIZE'],params['LOGGING_INTERVAL'],params['learning_rate'],params['num_epochs'],)\n",
    "            auc,f1 = logDPTemp.train_model_for_grid()\n",
    "\n",
    "            if auc > 0.5 and f1 > 0.1:\n",
    "                if auc > bestAuc and f1 > bestF1:\n",
    "                    bestAuc= auc\n",
    "                    bestF1 = f1\n",
    "                    best_params = params\n",
    "        if best_params != None:\n",
    "            print(\"Grid search finished.\")\n",
    "            print(f\"Best AUC: {bestAuc:.4f}\")\n",
    "            print(\"Best parameters:\", best_params)\n",
    "            self.update_parameters(best_params)\n",
    "    \n",
    "    def update_parameters(self, new_params):\n",
    "        # Update the model parameters with the new_params\n",
    "        self.EPSILON = new_params['EPSILON']\n",
    "        self.DELTA = new_params['DELTA']\n",
    "        self.EPOCHS = new_params['EPOCHS']\n",
    "        self.MAX_GRAD_NORM = new_params['MAX_GRAD_NORM']\n",
    "        self.MAX_PHYSICAL_BATCH_SIZE = new_params['MAX_PHYSICAL_BATCH_SIZE']\n",
    "        self.LOGGING_INTERVAL = new_params['LOGGING_INTERVAL']\n",
    "        self.learning_rate = new_params['learning_rate']\n",
    "        self.num_epochs = new_params['num_epochs']\n",
    "        self.status=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2=LogisticRegression(num_features)\n",
    "logDP=LogisticRegressionDP(model2,X_train,y_train,X_test,y_test)\n",
    "#logDP.train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5416957296752694\n",
      "F1_score = 0.1917808219178082\n",
      "Recall = 0.11764705882352941\n",
      "Precision = 0.5185185185185185\n",
      "Training model 2/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5210855620952903\n",
      "F1_score = 0.14153846153846156\n",
      "Recall = 0.08487084870848709\n",
      "Precision = 0.42592592592592593\n",
      "Training model 3/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48832492514663056\n",
      "F1_score = 0.08051529790660225\n",
      "Recall = 0.04409171075837742\n",
      "Precision = 0.46296296296296297\n",
      "Training model 4/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5159598906989303\n",
      "F1_score = 0.1258741258741259\n",
      "Recall = 0.0694980694980695\n",
      "Precision = 0.6666666666666666\n",
      "Training model 5/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5144849612552961\n",
      "F1_score = 0.1234567901234568\n",
      "Recall = 0.0682261208576998\n",
      "Precision = 0.6481481481481481\n",
      "Training model 6/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5000916170407695\n",
      "F1_score = 0.09937888198757763\n",
      "Recall = 0.05423728813559322\n",
      "Precision = 0.5925925925925926\n",
      "Training model 7/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5099757748428584\n",
      "F1_score = 0.11573236889692586\n",
      "Recall = 0.06412825651302605\n",
      "Precision = 0.5925925925925926\n",
      "Training model 8/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4899772305616461\n",
      "F1_score = 0.0849772382397572\n",
      "Recall = 0.04628099173553719\n",
      "Precision = 0.5185185185185185\n",
      "Training model 9/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.538774542533941\n",
      "F1_score = 0.1839080459770115\n",
      "Recall = 0.10884353741496598\n",
      "Precision = 0.5925925925925926\n",
      "Training model 10/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5527303217176635\n",
      "F1_score = 0.21764705882352942\n",
      "Recall = 0.12937062937062938\n",
      "Precision = 0.6851851851851852\n",
      "Training model 11/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5160181147266019\n",
      "F1_score = 0.12923076923076923\n",
      "Recall = 0.07749077490774908\n",
      "Precision = 0.3888888888888889\n",
      "Training model 12/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5295056459500311\n",
      "F1_score = 0.16040100250626566\n",
      "Recall = 0.0927536231884058\n",
      "Precision = 0.5925925925925926\n",
      "Training model 13/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5503744650499286\n",
      "F1_score = 0.21142857142857144\n",
      "Recall = 0.125\n",
      "Precision = 0.6851851851851852\n",
      "Training model 14/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5178114067966018\n",
      "F1_score = 0.13333333333333333\n",
      "Recall = 0.08045977011494253\n",
      "Precision = 0.3888888888888889\n",
      "Training model 15/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49017259670311736\n",
      "F1_score = 0.07692307692307693\n",
      "Recall = 0.04318181818181818\n",
      "Precision = 0.35185185185185186\n",
      "Training model 16/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.47353140971728025\n",
      "F1_score = 0.04633204633204634\n",
      "Recall = 0.02586206896551724\n",
      "Precision = 0.2222222222222222\n",
      "Training model 17/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4884855817705182\n",
      "F1_score = 0.07561436672967864\n",
      "Recall = 0.042105263157894736\n",
      "Precision = 0.37037037037037035\n",
      "Training model 18/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5442082878457061\n",
      "F1_score = 0.1978798586572438\n",
      "Recall = 0.1222707423580786\n",
      "Precision = 0.5185185185185185\n",
      "Training model 19/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5201145262412374\n",
      "F1_score = 0.13405797101449274\n",
      "Recall = 0.07429718875502007\n",
      "Precision = 0.6851851851851852\n",
      "Training model 20/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.528705213428655\n",
      "F1_score = 0.14175654853620956\n",
      "Recall = 0.0773109243697479\n",
      "Precision = 0.8518518518518519\n",
      "Training model 21/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5251504090952751\n",
      "F1_score = 0.15012106537530268\n",
      "Recall = 0.08635097493036212\n",
      "Precision = 0.5740740740740741\n",
      "Training model 22/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5176636716315905\n",
      "F1_score = 0.13333333333333333\n",
      "Recall = 0.07971014492753623\n",
      "Precision = 0.4074074074074074\n",
      "Training model 23/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4878524901889388\n",
      "F1_score = 0.07364341085271318\n",
      "Recall = 0.04112554112554113\n",
      "Precision = 0.35185185185185186\n",
      "Training model 24/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5081544581940453\n",
      "F1_score = 0.1107871720116618\n",
      "Recall = 0.0657439446366782\n",
      "Precision = 0.35185185185185186\n",
      "Training model 25/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5165637282425604\n",
      "F1_score = 0.1311475409836066\n",
      "Recall = 0.07692307692307693\n",
      "Precision = 0.4444444444444444\n",
      "Training model 26/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5599215854881969\n",
      "F1_score = 0.2360248447204969\n",
      "Recall = 0.1417910447761194\n",
      "Precision = 0.7037037037037037\n",
      "Training model 27/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5313564440149776\n",
      "F1_score = 0.15526802218114602\n",
      "Recall = 0.08624229979466119\n",
      "Precision = 0.7777777777777778\n",
      "Training model 28/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5165995813227937\n",
      "F1_score = 0.12649572649572652\n",
      "Recall = 0.0696798493408663\n",
      "Precision = 0.6851851851851852\n",
      "Training model 29/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5171453656089302\n",
      "F1_score = 0.13157894736842105\n",
      "Recall = 0.07462686567164178\n",
      "Precision = 0.5555555555555556\n",
      "Training model 30/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5006289446970031\n",
      "F1_score = 0.08294930875576037\n",
      "Recall = 0.05521472392638037\n",
      "Precision = 0.16666666666666666\n",
      "Training model 31/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5064233683738111\n",
      "F1_score = 0.10850439882697947\n",
      "Recall = 0.0589171974522293\n",
      "Precision = 0.6851851851851852\n",
      "Training model 32/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48435565460398317\n",
      "F1_score = 0.07977207977207977\n",
      "Recall = 0.043209876543209874\n",
      "Precision = 0.5185185185185185\n",
      "Training model 33/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5199910777395395\n",
      "F1_score = 0.13718411552346568\n",
      "Recall = 0.08520179372197309\n",
      "Precision = 0.35185185185185186\n",
      "Training model 34/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5447908919274558\n",
      "F1_score = 0.199288256227758\n",
      "Recall = 0.12334801762114538\n",
      "Precision = 0.5185185185185185\n",
      "Training model 35/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5180883219982894\n",
      "F1_score = 0.13333333333333333\n",
      "Recall = 0.07542579075425791\n",
      "Precision = 0.5740740740740741\n",
      "Training model 36/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5220856605651717\n",
      "F1_score = 0.144\n",
      "Recall = 0.08411214953271028\n",
      "Precision = 0.5\n",
      "Training model 37/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5055987319766848\n",
      "F1_score = 0.10746268656716419\n",
      "Recall = 0.05844155844155844\n",
      "Precision = 0.6666666666666666\n",
      "Training model 38/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5043591633127374\n",
      "F1_score = 0.09859154929577466\n",
      "Recall = 0.06086956521739131\n",
      "Precision = 0.25925925925925924\n",
      "Training model 39/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5198969636106825\n",
      "F1_score = 0.13071895424836602\n",
      "Recall = 0.07168458781362007\n",
      "Precision = 0.7407407407407407\n",
      "Training model 40/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4838603425559947\n",
      "F1_score = 0.08044382801664356\n",
      "Recall = 0.043478260869565216\n",
      "Precision = 0.5370370370370371\n",
      "Training model 41/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5172624953491257\n",
      "F1_score = 0.1320754716981132\n",
      "Recall = 0.07954545454545454\n",
      "Precision = 0.3888888888888889\n",
      "Training model 42/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5435983781848442\n",
      "F1_score = 0.19540229885057472\n",
      "Recall = 0.11564625850340136\n",
      "Precision = 0.6296296296296297\n",
      "Training model 43/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.509072379744542\n",
      "F1_score = 0.1139896373056995\n",
      "Recall = 0.06626506024096386\n",
      "Precision = 0.4074074074074074\n",
      "Training model 44/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4952108516372674\n",
      "F1_score = 0.08996539792387544\n",
      "Recall = 0.04961832061068702\n",
      "Precision = 0.48148148148148145\n",
      "Training model 45/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5019703038394627\n",
      "F1_score = 0.10077519379844961\n",
      "Recall = 0.05627705627705628\n",
      "Precision = 0.48148148148148145\n",
      "Training model 46/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5394943028848157\n",
      "F1_score = 0.1782608695652174\n",
      "Recall = 0.10098522167487685\n",
      "Precision = 0.7592592592592593\n",
      "Training model 47/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5288191610902563\n",
      "F1_score = 0.15384615384615385\n",
      "Recall = 0.08636363636363636\n",
      "Precision = 0.7037037037037037\n",
      "Training model 48/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4975376344086021\n",
      "F1_score = 0.0892018779342723\n",
      "Recall = 0.051075268817204304\n",
      "Precision = 0.35185185185185186\n",
      "Training model 49/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5202619464436231\n",
      "F1_score = 0.13978494623655913\n",
      "Recall = 0.08176100628930817\n",
      "Precision = 0.48148148148148145\n",
      "Training model 50/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5438572757651705\n",
      "F1_score = 0.19553072625698326\n",
      "Recall = 0.11513157894736842\n",
      "Precision = 0.6481481481481481\n",
      "Training model 51/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5082103512783205\n",
      "F1_score = 0.10937499999999999\n",
      "Recall = 0.058823529411764705\n",
      "Precision = 0.7777777777777778\n",
      "Training model 52/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4865354603780128\n",
      "F1_score = 0.08163265306122448\n",
      "Recall = 0.04430379746835443\n",
      "Precision = 0.5185185185185185\n",
      "Training model 53/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4926438053097345\n",
      "F1_score = 0.08723747980613894\n",
      "Recall = 0.047787610619469026\n",
      "Precision = 0.5\n",
      "Training model 54/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48249598876855193\n",
      "F1_score = 0.04833836858006043\n",
      "Recall = 0.02888086642599278\n",
      "Precision = 0.14814814814814814\n",
      "Training model 55/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4896250941516631\n",
      "F1_score = 0.08108108108108107\n",
      "Recall = 0.04460966542750929\n",
      "Precision = 0.4444444444444444\n",
      "Training model 56/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5086073549224092\n",
      "F1_score = 0.11214953271028037\n",
      "Recall = 0.061224489795918366\n",
      "Precision = 0.6666666666666666\n",
      "Training model 57/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5525444925444926\n",
      "F1_score = 0.21652421652421652\n",
      "Recall = 0.12794612794612795\n",
      "Precision = 0.7037037037037037\n",
      "Training model 58/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5506036022985176\n",
      "F1_score = 0.21203438395415472\n",
      "Recall = 0.12542372881355932\n",
      "Precision = 0.6851851851851852\n",
      "Training model 59/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49646041008185426\n",
      "F1_score = 0.09001956947162426\n",
      "Recall = 0.05032822757111598\n",
      "Precision = 0.42592592592592593\n",
      "Training model 60/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.497097677303627\n",
      "F1_score = 0.0950920245398773\n",
      "Recall = 0.051839464882943144\n",
      "Precision = 0.5740740740740741\n",
      "Training model 61/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5206592956592957\n",
      "F1_score = 0.1386861313868613\n",
      "Recall = 0.08636363636363636\n",
      "Precision = 0.35185185185185186\n",
      "Training model 62/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5500417136968151\n",
      "F1_score = 0.21114369501466276\n",
      "Recall = 0.1254355400696864\n",
      "Precision = 0.6666666666666666\n",
      "Training model 63/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.46461708241369254\n",
      "F1_score = 0.021691973969631236\n",
      "Recall = 0.012285012285012284\n",
      "Precision = 0.09259259259259259\n",
      "Training model 64/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5380664011343828\n",
      "F1_score = 0.18041237113402062\n",
      "Recall = 0.10479041916167664\n",
      "Precision = 0.6481481481481481\n",
      "Training model 65/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5126084417751084\n",
      "F1_score = 0.12200435729847493\n",
      "Recall = 0.0691358024691358\n",
      "Precision = 0.5185185185185185\n",
      "Training model 66/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5430289223155957\n",
      "F1_score = 0.18867924528301888\n",
      "Recall = 0.12658227848101267\n",
      "Precision = 0.37037037037037035\n",
      "Training model 67/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5122781983376464\n",
      "F1_score = 0.12030075187969924\n",
      "Recall = 0.06694560669456066\n",
      "Precision = 0.5925925925925926\n",
      "Training model 68/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49502398081534776\n",
      "F1_score = 0.0914826498422713\n",
      "Recall = 0.05\n",
      "Precision = 0.5370370370370371\n",
      "Training model 69/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5172172289015992\n",
      "F1_score = 0.1326530612244898\n",
      "Recall = 0.07692307692307693\n",
      "Precision = 0.48148148148148145\n",
      "Training model 70/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.509068766745149\n",
      "F1_score = 0.11352253756260434\n",
      "Recall = 0.062385321100917435\n",
      "Precision = 0.6296296296296297\n",
      "Training model 71/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5327587401383873\n",
      "F1_score = 0.16666666666666666\n",
      "Recall = 0.09562841530054644\n",
      "Precision = 0.6481481481481481\n",
      "Training model 72/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.50951440072803\n",
      "F1_score = 0.11546391752577319\n",
      "Recall = 0.06496519721577726\n",
      "Precision = 0.5185185185185185\n",
      "Training model 73/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5094526064583489\n",
      "F1_score = 0.11538461538461539\n",
      "Recall = 0.06521739130434782\n",
      "Precision = 0.5\n",
      "Training model 74/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5662820436566942\n",
      "F1_score = 0.2527881040892193\n",
      "Recall = 0.15813953488372093\n",
      "Precision = 0.6296296296296297\n",
      "Training model 75/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5172397424611188\n",
      "F1_score = 0.132387706855792\n",
      "Recall = 0.07588075880758807\n",
      "Precision = 0.5185185185185185\n",
      "Training model 76/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5101457716104091\n",
      "F1_score = 0.11685393258426968\n",
      "Recall = 0.06649616368286446\n",
      "Precision = 0.48148148148148145\n",
      "Training model 77/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5216665493639259\n",
      "F1_score = 0.14250614250614252\n",
      "Recall = 0.0821529745042493\n",
      "Precision = 0.5370370370370371\n",
      "Training model 78/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5172321013031338\n",
      "F1_score = 0.1325648414985591\n",
      "Recall = 0.07849829351535836\n",
      "Precision = 0.42592592592592593\n",
      "Training model 79/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5350360262448174\n",
      "F1_score = 0.16176470588235295\n",
      "Recall = 0.08979591836734693\n",
      "Precision = 0.8148148148148148\n",
      "Training model 80/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48067892062443823\n",
      "F1_score = 0.07702888583218707\n",
      "Recall = 0.041604754829123326\n",
      "Precision = 0.5185185185185185\n",
      "Training model 81/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5085292497987884\n",
      "F1_score = 0.11337868480725621\n",
      "Recall = 0.06459948320413436\n",
      "Precision = 0.46296296296296297\n",
      "Training model 82/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5239001215832845\n",
      "F1_score = 0.14084507042253522\n",
      "Recall = 0.09433962264150944\n",
      "Precision = 0.2777777777777778\n",
      "Training model 83/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5225388262931222\n",
      "F1_score = 0.14423076923076922\n",
      "Recall = 0.08287292817679558\n",
      "Precision = 0.5555555555555556\n",
      "Training model 84/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5312295618051014\n",
      "F1_score = 0.15544041450777202\n",
      "Recall = 0.1079136690647482\n",
      "Precision = 0.2777777777777778\n",
      "Training model 85/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.508347516505924\n",
      "F1_score = 0.11199999999999999\n",
      "Recall = 0.06129597197898424\n",
      "Precision = 0.6481481481481481\n",
      "Training model 86/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5326337048777994\n",
      "F1_score = 0.16551724137931037\n",
      "Recall = 0.09448818897637795\n",
      "Precision = 0.6666666666666666\n",
      "Training model 87/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48262424828920997\n",
      "F1_score = 0.0761346998535871\n",
      "Recall = 0.04133545310015898\n",
      "Precision = 0.48148148148148145\n",
      "Training model 88/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5012501509844184\n",
      "F1_score = 0.09981515711645102\n",
      "Recall = 0.055441478439425054\n",
      "Precision = 0.5\n",
      "Training model 89/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5228095280518498\n",
      "F1_score = 0.14482758620689656\n",
      "Recall = 0.08898305084745763\n",
      "Precision = 0.3888888888888889\n",
      "Training model 90/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5518785415126879\n",
      "F1_score = 0.21621621621621623\n",
      "Recall = 0.13658536585365855\n",
      "Precision = 0.5185185185185185\n",
      "Training model 91/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4743845085273394\n",
      "F1_score = 0.061538461538461535\n",
      "Recall = 0.03355704697986577\n",
      "Precision = 0.37037037037037035\n",
      "Training model 92/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49884059030400496\n",
      "F1_score = 0.09666666666666665\n",
      "Recall = 0.05311355311355311\n",
      "Precision = 0.5370370370370371\n",
      "Training model 93/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.510628179064508\n",
      "F1_score = 0.11764705882352942\n",
      "Recall = 0.06605922551252848\n",
      "Precision = 0.5370370370370371\n",
      "Training model 94/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5411309400085123\n",
      "F1_score = 0.18991097922848665\n",
      "Recall = 0.11307420494699646\n",
      "Precision = 0.5925925925925926\n",
      "Training model 95/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5045904338073013\n",
      "F1_score = 0.10584958217270193\n",
      "Recall = 0.0572289156626506\n",
      "Precision = 0.7037037037037037\n",
      "Training model 96/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5144349501136026\n",
      "F1_score = 0.12552301255230125\n",
      "Recall = 0.07075471698113207\n",
      "Precision = 0.5555555555555556\n",
      "Training model 97/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5312626817511457\n",
      "F1_score = 0.16617210682492578\n",
      "Recall = 0.0989399293286219\n",
      "Precision = 0.5185185185185185\n",
      "Training model 98/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5287127401192316\n",
      "F1_score = 0.15841584158415842\n",
      "Recall = 0.09142857142857143\n",
      "Precision = 0.5925925925925926\n",
      "Training model 99/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5105297830748431\n",
      "F1_score = 0.1176470588235294\n",
      "Recall = 0.0673854447439353\n",
      "Precision = 0.46296296296296297\n",
      "Training model 100/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4891184237253707\n",
      "F1_score = 0.0753968253968254\n",
      "Recall = 0.042222222222222223\n",
      "Precision = 0.35185185185185186\n",
      "Training model 101/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5350482932046603\n",
      "F1_score = 0.1663286004056795\n",
      "Recall = 0.09339407744874716\n",
      "Precision = 0.7592592592592593\n",
      "Training model 102/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5285431396846222\n",
      "F1_score = 0.15204678362573099\n",
      "Recall = 0.08496732026143791\n",
      "Precision = 0.7222222222222222\n",
      "Training model 103/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5259887087017887\n",
      "F1_score = 0.15340909090909088\n",
      "Recall = 0.09060402684563758\n",
      "Precision = 0.5\n",
      "Training model 104/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.47448453397287405\n",
      "F1_score = 0.04508196721311476\n",
      "Recall = 0.02534562211981567\n",
      "Precision = 0.2037037037037037\n",
      "Training model 105/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.536641325006788\n",
      "F1_score = 0.16574585635359115\n",
      "Recall = 0.11811023622047244\n",
      "Precision = 0.2777777777777778\n",
      "Training model 106/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5331681884955497\n",
      "F1_score = 0.17045454545454544\n",
      "Recall = 0.10067114093959731\n",
      "Precision = 0.5555555555555556\n",
      "Training model 107/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.51003663003663\n",
      "F1_score = 0.11609498680738788\n",
      "Recall = 0.06769230769230769\n",
      "Precision = 0.4074074074074074\n",
      "Training model 108/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5303375422959479\n",
      "F1_score = 0.14580031695721077\n",
      "Recall = 0.07972270363951472\n",
      "Precision = 0.8518518518518519\n",
      "Training model 109/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49445589705147425\n",
      "F1_score = 0.07619047619047618\n",
      "Recall = 0.04597701149425287\n",
      "Precision = 0.2222222222222222\n",
      "Training model 110/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5445966953633805\n",
      "F1_score = 0.19852941176470587\n",
      "Recall = 0.12385321100917432\n",
      "Precision = 0.5\n",
      "Training model 111/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5178604520001612\n",
      "F1_score = 0.13059701492537315\n",
      "Recall = 0.07261410788381743\n",
      "Precision = 0.6481481481481481\n",
      "Training model 112/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4715340657571733\n",
      "F1_score = 0.046762589928057555\n",
      "Recall = 0.025896414342629483\n",
      "Precision = 0.24074074074074073\n",
      "Training model 113/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5137111429937828\n",
      "F1_score = 0.12429378531073447\n",
      "Recall = 0.07333333333333333\n",
      "Precision = 0.4074074074074074\n",
      "Training model 114/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5477617184971473\n",
      "F1_score = 0.2037533512064343\n",
      "Recall = 0.11912225705329153\n",
      "Precision = 0.7037037037037037\n",
      "Training model 115/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5048738043663445\n",
      "F1_score = 0.10629921259842519\n",
      "Recall = 0.05947136563876652\n",
      "Precision = 0.5\n",
      "Training model 116/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.46970259901845585\n",
      "F1_score = 0.05856515373352854\n",
      "Recall = 0.03179650238473768\n",
      "Precision = 0.37037037037037035\n",
      "Training model 117/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5006100625871518\n",
      "F1_score = 0.09803921568627451\n",
      "Recall = 0.05482456140350877\n",
      "Precision = 0.46296296296296297\n",
      "Training model 118/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5402998236331569\n",
      "F1_score = 0.17768595041322316\n",
      "Recall = 0.1\n",
      "Precision = 0.7962962962962963\n",
      "Training model 119/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5141642089316507\n",
      "F1_score = 0.12280701754385964\n",
      "Recall = 0.06782945736434108\n",
      "Precision = 0.6481481481481481\n",
      "Training model 120/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.47430441313210786\n",
      "F1_score = 0.0676056338028169\n",
      "Recall = 0.036585365853658534\n",
      "Precision = 0.4444444444444444\n",
      "Training model 121/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5423444485459988\n",
      "F1_score = 0.18181818181818182\n",
      "Recall = 0.10232558139534884\n",
      "Precision = 0.8148148148148148\n",
      "Training model 122/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5313787904171553\n",
      "F1_score = 0.16608996539792387\n",
      "Recall = 0.10212765957446808\n",
      "Precision = 0.4444444444444444\n",
      "Training model 123/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5356611854066502\n",
      "F1_score = 0.16506717850287908\n",
      "Recall = 0.09207708779443255\n",
      "Precision = 0.7962962962962963\n",
      "Training model 124/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5208171190453027\n",
      "F1_score = 0.13725490196078433\n",
      "Recall = 0.07675438596491228\n",
      "Precision = 0.6481481481481481\n",
      "Training model 125/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5427291606297692\n",
      "F1_score = 0.17550274223034737\n",
      "Recall = 0.0973630831643002\n",
      "Precision = 0.8888888888888888\n",
      "Training model 126/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5330690241827682\n",
      "F1_score = 0.1674641148325359\n",
      "Recall = 0.09615384615384616\n",
      "Precision = 0.6481481481481481\n",
      "Training model 127/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5358152473333875\n",
      "F1_score = 0.17525773195876287\n",
      "Recall = 0.10179640718562874\n",
      "Precision = 0.6296296296296297\n",
      "Training model 128/256 with parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5297885060590386\n",
      "F1_score = 0.1590909090909091\n",
      "Recall = 0.09067357512953368\n",
      "Precision = 0.6481481481481481\n",
      "Training model 129/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5290562538635896\n",
      "F1_score = 0.15546218487394958\n",
      "Recall = 0.08767772511848342\n",
      "Precision = 0.6851851851851852\n",
      "Training model 130/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5569865310874464\n",
      "F1_score = 0.22950819672131145\n",
      "Recall = 0.1394422310756972\n",
      "Precision = 0.6481481481481481\n",
      "Training model 131/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4949679251235672\n",
      "F1_score = 0.07717041800643087\n",
      "Recall = 0.04669260700389105\n",
      "Precision = 0.2222222222222222\n",
      "Training model 132/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.522235390906277\n",
      "F1_score = 0.14056224899598393\n",
      "Recall = 0.07882882882882883\n",
      "Precision = 0.6481481481481481\n",
      "Training model 133/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5493251395462923\n",
      "F1_score = 0.20833333333333334\n",
      "Recall = 0.13440860215053763\n",
      "Precision = 0.46296296296296297\n",
      "Training model 134/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5199677716015724\n",
      "F1_score = 0.136\n",
      "Recall = 0.07623318385650224\n",
      "Precision = 0.6296296296296297\n",
      "Training model 135/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4842361319279598\n",
      "F1_score = 0.06640625000000001\n",
      "Recall = 0.03711790393013101\n",
      "Precision = 0.3148148148148148\n",
      "Training model 136/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48710362863680945\n",
      "F1_score = 0.0781758957654723\n",
      "Recall = 0.04285714285714286\n",
      "Precision = 0.4444444444444444\n",
      "Training model 137/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5480405756892666\n",
      "F1_score = 0.20047732696897375\n",
      "Recall = 0.11506849315068493\n",
      "Precision = 0.7777777777777778\n",
      "Training model 138/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5542745334136062\n",
      "F1_score = 0.22297297297297294\n",
      "Recall = 0.13636363636363635\n",
      "Precision = 0.6111111111111112\n",
      "Training model 139/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48990322554122157\n",
      "F1_score = 0.08320000000000001\n",
      "Recall = 0.04553415061295972\n",
      "Precision = 0.48148148148148145\n",
      "Training model 140/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.481028474959666\n",
      "F1_score = 0.056155507559395246\n",
      "Recall = 0.03178484107579462\n",
      "Precision = 0.24074074074074073\n",
      "Training model 141/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5492639158963978\n",
      "F1_score = 0.20500000000000002\n",
      "Recall = 0.11849710982658959\n",
      "Precision = 0.7592592592592593\n",
      "Training model 142/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5347606072401713\n",
      "F1_score = 0.171021377672209\n",
      "Recall = 0.09809264305177112\n",
      "Precision = 0.6666666666666666\n",
      "Training model 143/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5321715928770892\n",
      "F1_score = 0.1623931623931624\n",
      "Recall = 0.09178743961352658\n",
      "Precision = 0.7037037037037037\n",
      "Training model 144/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5050058965161417\n",
      "F1_score = 0.10679611650485436\n",
      "Recall = 0.05851063829787234\n",
      "Precision = 0.6111111111111112\n",
      "Training model 145/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5126066825293291\n",
      "F1_score = 0.12201591511936341\n",
      "Recall = 0.07120743034055728\n",
      "Precision = 0.42592592592592593\n",
      "Training model 146/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5262903578211399\n",
      "F1_score = 0.1511111111111111\n",
      "Recall = 0.08585858585858586\n",
      "Precision = 0.6296296296296297\n",
      "Training model 147/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4757368227956463\n",
      "F1_score = 0.04838709677419355\n",
      "Recall = 0.027149321266968326\n",
      "Precision = 0.2222222222222222\n",
      "Training model 148/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4739260323702919\n",
      "F1_score = 0.04\n",
      "Recall = 0.022727272727272728\n",
      "Precision = 0.16666666666666666\n",
      "Training model 149/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.510566659798063\n",
      "F1_score = 0.11764705882352942\n",
      "Recall = 0.06635071090047394\n",
      "Precision = 0.5185185185185185\n",
      "Training model 150/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49318552405109156\n",
      "F1_score = 0.0917941585535466\n",
      "Recall = 0.04962406015037594\n",
      "Precision = 0.6111111111111112\n",
      "Training model 151/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5182942371097572\n",
      "F1_score = 0.13333333333333333\n",
      "Recall = 0.07511737089201878\n",
      "Precision = 0.5925925925925926\n",
      "Training model 152/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.500183276908757\n",
      "F1_score = 0.09643605870020965\n",
      "Recall = 0.054373522458628844\n",
      "Precision = 0.42592592592592593\n",
      "Training model 153/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49841108857336036\n",
      "F1_score = 0.08391608391608392\n",
      "Recall = 0.05172413793103448\n",
      "Precision = 0.2222222222222222\n",
      "Training model 154/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5353633999116651\n",
      "F1_score = 0.1759530791788856\n",
      "Recall = 0.10452961672473868\n",
      "Precision = 0.5555555555555556\n",
      "Training model 155/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48951235913182256\n",
      "F1_score = 0.08094435075885328\n",
      "Recall = 0.04452690166975881\n",
      "Precision = 0.4444444444444444\n",
      "Training model 156/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49348993288590604\n",
      "F1_score = 0.08383233532934133\n",
      "Recall = 0.04697986577181208\n",
      "Precision = 0.3888888888888889\n",
      "Training model 157/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.534201175021321\n",
      "F1_score = 0.17270194986072424\n",
      "Recall = 0.10163934426229508\n",
      "Precision = 0.5740740740740741\n",
      "Training model 158/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.53927856530087\n",
      "F1_score = 0.18575851393188855\n",
      "Recall = 0.11152416356877323\n",
      "Precision = 0.5555555555555556\n",
      "Training model 159/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5103749058483368\n",
      "F1_score = 0.11695906432748539\n",
      "Recall = 0.06535947712418301\n",
      "Precision = 0.5555555555555556\n",
      "Training model 160/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49547585031456004\n",
      "F1_score = 0.09259259259259259\n",
      "Recall = 0.050505050505050504\n",
      "Precision = 0.5555555555555556\n",
      "Training model 161/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5259901845579595\n",
      "F1_score = 0.15165876777251186\n",
      "Recall = 0.08695652173913043\n",
      "Precision = 0.5925925925925926\n",
      "Training model 162/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5242085513450663\n",
      "F1_score = 0.14886731391585759\n",
      "Recall = 0.09019607843137255\n",
      "Precision = 0.42592592592592593\n",
      "Training model 163/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4978098939357137\n",
      "F1_score = 0.09475465313028765\n",
      "Recall = 0.0521415270018622\n",
      "Precision = 0.5185185185185185\n",
      "Training model 164/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48421532685121227\n",
      "F1_score = 0.07965860597439545\n",
      "Recall = 0.04314329738058552\n",
      "Precision = 0.5185185185185185\n",
      "Training model 165/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49068261651456324\n",
      "F1_score = 0.07555555555555556\n",
      "Recall = 0.04292929292929293\n",
      "Precision = 0.3148148148148148\n",
      "Training model 166/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5322980857197106\n",
      "F1_score = 0.16548463356973997\n",
      "Recall = 0.0948509485094851\n",
      "Precision = 0.6481481481481481\n",
      "Training model 167/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5314698619943174\n",
      "F1_score = 0.16252821670428894\n",
      "Recall = 0.09254498714652956\n",
      "Precision = 0.6666666666666666\n",
      "Training model 168/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5109144609279884\n",
      "F1_score = 0.11825192802056556\n",
      "Recall = 0.06865671641791045\n",
      "Precision = 0.42592592592592593\n",
      "Training model 169/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5449170406636746\n",
      "F1_score = 0.19658119658119655\n",
      "Recall = 0.12777777777777777\n",
      "Precision = 0.42592592592592593\n",
      "Training model 170/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5514871070995447\n",
      "F1_score = 0.21492537313432836\n",
      "Recall = 0.12811387900355872\n",
      "Precision = 0.6666666666666666\n",
      "Training model 171/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.491487739542551\n",
      "F1_score = 0.08585055643879172\n",
      "Recall = 0.04695652173913043\n",
      "Precision = 0.5\n",
      "Training model 172/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5150382769982905\n",
      "F1_score = 0.12684989429175475\n",
      "Recall = 0.07159904534606205\n",
      "Precision = 0.5555555555555556\n",
      "Training model 173/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5230624214495182\n",
      "F1_score = 0.14634146341463414\n",
      "Recall = 0.08571428571428572\n",
      "Precision = 0.5\n",
      "Training model 174/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5266848154869933\n",
      "F1_score = 0.14744801512287334\n",
      "Recall = 0.08210526315789474\n",
      "Precision = 0.7222222222222222\n",
      "Training model 175/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.506402952642159\n",
      "F1_score = 0.10909090909090909\n",
      "Recall = 0.05989110707803993\n",
      "Precision = 0.6111111111111112\n",
      "Training model 176/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5131709334512636\n",
      "F1_score = 0.1197411003236246\n",
      "Recall = 0.06560283687943262\n",
      "Precision = 0.6851851851851852\n",
      "Training model 177/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.523266806722689\n",
      "F1_score = 0.14598540145985403\n",
      "Recall = 0.08403361344537816\n",
      "Precision = 0.5555555555555556\n",
      "Training model 178/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5073194794290512\n",
      "F1_score = 0.11086474501108647\n",
      "Recall = 0.06297229219143577\n",
      "Precision = 0.46296296296296297\n",
      "Training model 179/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4918357487922706\n",
      "F1_score = 0.09053497942386833\n",
      "Recall = 0.04888888888888889\n",
      "Precision = 0.6111111111111112\n",
      "Training model 180/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.488361968887857\n",
      "F1_score = 0.08150470219435736\n",
      "Recall = 0.04452054794520548\n",
      "Precision = 0.48148148148148145\n",
      "Training model 181/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5124885043907123\n",
      "F1_score = 0.1190082644628099\n",
      "Recall = 0.06533575317604355\n",
      "Precision = 0.6666666666666666\n",
      "Training model 182/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5671656686626747\n",
      "F1_score = 0.25\n",
      "Recall = 0.16666666666666666\n",
      "Precision = 0.5\n",
      "Training model 183/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5236933181433724\n",
      "F1_score = 0.14657210401891252\n",
      "Recall = 0.08401084010840108\n",
      "Precision = 0.5740740740740741\n",
      "Training model 184/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5217177990311762\n",
      "F1_score = 0.14072494669509594\n",
      "Recall = 0.07951807228915662\n",
      "Precision = 0.6111111111111112\n",
      "Training model 185/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49487015231936227\n",
      "F1_score = 0.0606060606060606\n",
      "Recall = 0.04504504504504504\n",
      "Precision = 0.09259259259259259\n",
      "Training model 186/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5316647386686297\n",
      "F1_score = 0.16720257234726688\n",
      "Recall = 0.10116731517509728\n",
      "Precision = 0.48148148148148145\n",
      "Training model 187/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5032559753401223\n",
      "F1_score = 0.10380622837370242\n",
      "Recall = 0.05725190839694656\n",
      "Precision = 0.5555555555555556\n",
      "Training model 188/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5037533523812863\n",
      "F1_score = 0.10243902439024391\n",
      "Recall = 0.05898876404494382\n",
      "Precision = 0.3888888888888889\n",
      "Training model 189/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.508260649087221\n",
      "F1_score = 0.11042944785276074\n",
      "Recall = 0.0661764705882353\n",
      "Precision = 0.3333333333333333\n",
      "Training model 190/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5255986082139915\n",
      "F1_score = 0.15121951219512195\n",
      "Recall = 0.08707865168539326\n",
      "Precision = 0.5740740740740741\n",
      "Training model 191/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5061401246161162\n",
      "F1_score = 0.10881801125703566\n",
      "Recall = 0.060542797494780795\n",
      "Precision = 0.5370370370370371\n",
      "Training model 192/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 10, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4821043677895137\n",
      "F1_score = 0.059196617336152224\n",
      "Recall = 0.03341288782816229\n",
      "Precision = 0.25925925925925924\n",
      "Training model 193/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5445431188561216\n",
      "F1_score = 0.1920374707259953\n",
      "Recall = 0.10991957104557641\n",
      "Precision = 0.7592592592592593\n",
      "Training model 194/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5468054701349444\n",
      "F1_score = 0.20377358490566036\n",
      "Recall = 0.12796208530805686\n",
      "Precision = 0.5\n",
      "Training model 195/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5139249525707941\n",
      "F1_score = 0.11832611832611832\n",
      "Recall = 0.06416275430359937\n",
      "Precision = 0.7592592592592593\n",
      "Training model 196/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.477898788214928\n",
      "F1_score = 0.06717557251908397\n",
      "Recall = 0.036605657237936774\n",
      "Precision = 0.4074074074074074\n",
      "Training model 197/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5167121765898086\n",
      "F1_score = 0.12330827067669173\n",
      "Recall = 0.06710310965630115\n",
      "Precision = 0.7592592592592593\n",
      "Training model 198/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5109752408052461\n",
      "F1_score = 0.11836734693877553\n",
      "Recall = 0.06651376146788991\n",
      "Precision = 0.5370370370370371\n",
      "Training model 199/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5084343924326946\n",
      "F1_score = 0.11262798634812286\n",
      "Recall = 0.06203007518796992\n",
      "Precision = 0.6111111111111112\n",
      "Training model 200/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5009848796751512\n",
      "F1_score = 0.09904761904761905\n",
      "Recall = 0.055201698513800426\n",
      "Precision = 0.48148148148148145\n",
      "Training model 201/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.537610294792068\n",
      "F1_score = 0.17989417989417988\n",
      "Recall = 0.10493827160493827\n",
      "Precision = 0.6296296296296297\n",
      "Training model 202/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5385953346855984\n",
      "F1_score = 0.18404907975460122\n",
      "Recall = 0.11029411764705882\n",
      "Precision = 0.5555555555555556\n",
      "Training model 203/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.46935845763909084\n",
      "F1_score = 0.0530421216848674\n",
      "Recall = 0.028960817717206135\n",
      "Precision = 0.3148148148148148\n",
      "Training model 204/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4979952450032237\n",
      "F1_score = 0.09363295880149813\n",
      "Recall = 0.052083333333333336\n",
      "Precision = 0.46296296296296297\n",
      "Training model 205/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5424792343806428\n",
      "F1_score = 0.18219461697722567\n",
      "Recall = 0.10256410256410256\n",
      "Precision = 0.8148148148148148\n",
      "Training model 206/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5590076518412243\n",
      "F1_score = 0.23163841807909602\n",
      "Recall = 0.13666666666666666\n",
      "Precision = 0.7592592592592593\n",
      "Training model 207/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5297998217035417\n",
      "F1_score = 0.14814814814814814\n",
      "Recall = 0.08148148148148149\n",
      "Precision = 0.8148148148148148\n",
      "Training model 208/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49442520606740475\n",
      "F1_score = 0.09461235216819974\n",
      "Recall = 0.05091937765205092\n",
      "Precision = 0.6666666666666666\n",
      "Training model 209/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5086880227001195\n",
      "F1_score = 0.10280373831775702\n",
      "Recall = 0.06875\n",
      "Precision = 0.2037037037037037\n",
      "Training model 210/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5492692685904175\n",
      "F1_score = 0.21052631578947364\n",
      "Recall = 0.12987012987012986\n",
      "Precision = 0.5555555555555556\n",
      "Training model 211/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5254539466147325\n",
      "F1_score = 0.15211267605633802\n",
      "Recall = 0.08970099667774087\n",
      "Precision = 0.5\n",
      "Training model 212/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48092074236413573\n",
      "F1_score = 0.0482573726541555\n",
      "Recall = 0.02821316614420063\n",
      "Precision = 0.16666666666666666\n",
      "Training model 213/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48504461399198234\n",
      "F1_score = 0.07929515418502203\n",
      "Recall = 0.0430622009569378\n",
      "Precision = 0.5\n",
      "Training model 214/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.488663910230094\n",
      "F1_score = 0.0641399416909621\n",
      "Recall = 0.03806228373702422\n",
      "Precision = 0.2037037037037037\n",
      "Training model 215/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4880312652662433\n",
      "F1_score = 0.07920792079207921\n",
      "Recall = 0.043478260869565216\n",
      "Precision = 0.4444444444444444\n",
      "Training model 216/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.48972511514401595\n",
      "F1_score = 0.08554572271386432\n",
      "Recall = 0.046474358974358976\n",
      "Precision = 0.5370370370370371\n",
      "Training model 217/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5300276335223212\n",
      "F1_score = 0.16292134831460672\n",
      "Recall = 0.09602649006622517\n",
      "Precision = 0.5370370370370371\n",
      "Training model 218/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5416957296752694\n",
      "F1_score = 0.1917808219178082\n",
      "Recall = 0.11764705882352941\n",
      "Precision = 0.5185185185185185\n",
      "Training model 219/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5295507664810615\n",
      "F1_score = 0.1592505854800937\n",
      "Recall = 0.09115281501340483\n",
      "Precision = 0.6296296296296297\n",
      "Training model 220/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4856831951795999\n",
      "F1_score = 0.07776049766718507\n",
      "Recall = 0.042444821731748725\n",
      "Precision = 0.46296296296296297\n",
      "Training model 221/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5293162498968391\n",
      "F1_score = 0.15611814345991562\n",
      "Recall = 0.0880952380952381\n",
      "Precision = 0.6851851851851852\n",
      "Training model 222/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5586116983791403\n",
      "F1_score = 0.23008849557522124\n",
      "Recall = 0.1511627906976744\n",
      "Precision = 0.48148148148148145\n",
      "Training model 223/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5368716577540107\n",
      "F1_score = 0.17118997912317327\n",
      "Recall = 0.09647058823529411\n",
      "Precision = 0.7592592592592593\n",
      "Training model 224/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.507045140862223\n",
      "F1_score = 0.11018363939899835\n",
      "Recall = 0.060550458715596334\n",
      "Precision = 0.6111111111111112\n",
      "Training model 225/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.520925091758425\n",
      "F1_score = 0.13943355119825707\n",
      "Recall = 0.07901234567901234\n",
      "Precision = 0.5925925925925926\n",
      "Training model 226/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5405798162293429\n",
      "F1_score = 0.18352941176470589\n",
      "Recall = 0.10512129380053908\n",
      "Precision = 0.7222222222222222\n",
      "Training model 227/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4910709802674522\n",
      "F1_score = 0.08615384615384615\n",
      "Recall = 0.04697986577181208\n",
      "Precision = 0.5185185185185185\n",
      "Training model 228/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4853245415207089\n",
      "F1_score = 0.07631160572337044\n",
      "Recall = 0.04173913043478261\n",
      "Precision = 0.4444444444444444\n",
      "Training model 229/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5305792124542125\n",
      "F1_score = 0.16358839050131926\n",
      "Recall = 0.09538461538461539\n",
      "Precision = 0.5740740740740741\n",
      "Training model 230/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5335775774590718\n",
      "F1_score = 0.16704288939051914\n",
      "Recall = 0.09511568123393316\n",
      "Precision = 0.6851851851851852\n",
      "Training model 231/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4808593918948142\n",
      "F1_score = 0.05225653206650831\n",
      "Recall = 0.02997275204359673\n",
      "Precision = 0.2037037037037037\n",
      "Training model 232/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5100967744587783\n",
      "F1_score = 0.1166666666666667\n",
      "Recall = 0.06572769953051644\n",
      "Precision = 0.5185185185185185\n",
      "Training model 233/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.502903478654464\n",
      "F1_score = 0.09556313993174062\n",
      "Recall = 0.058577405857740586\n",
      "Precision = 0.25925925925925924\n",
      "Training model 234/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5469077695946933\n",
      "F1_score = 0.20348837209302326\n",
      "Recall = 0.1206896551724138\n",
      "Precision = 0.6481481481481481\n",
      "Training model 235/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5212200734789454\n",
      "F1_score = 0.13740458015267176\n",
      "Recall = 0.07659574468085106\n",
      "Precision = 0.6666666666666666\n",
      "Training model 236/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5193245569297462\n",
      "F1_score = 0.13680781758957655\n",
      "Recall = 0.08300395256916997\n",
      "Precision = 0.3888888888888889\n",
      "Training model 237/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5225559742850809\n",
      "F1_score = 0.14463840399002492\n",
      "Recall = 0.08357348703170028\n",
      "Precision = 0.5370370370370371\n",
      "Training model 238/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.526546818191714\n",
      "F1_score = 0.15436241610738252\n",
      "Recall = 0.0942622950819672\n",
      "Precision = 0.42592592592592593\n",
      "Training model 239/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4895616690798999\n",
      "F1_score = 0.08620689655172413\n",
      "Recall = 0.04672897196261682\n",
      "Precision = 0.5555555555555556\n",
      "Training model 240/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5049098837454017\n",
      "F1_score = 0.10654490106544902\n",
      "Recall = 0.05804311774461028\n",
      "Precision = 0.6481481481481481\n",
      "Training model 241/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5414910382015645\n",
      "F1_score = 0.1899441340782123\n",
      "Recall = 0.1118421052631579\n",
      "Precision = 0.6296296296296297\n",
      "Training model 242/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5382217280289927\n",
      "F1_score = 0.173469387755102\n",
      "Recall = 0.11971830985915492\n",
      "Precision = 0.3148148148148148\n",
      "Training model 243/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5051193023537487\n",
      "F1_score = 0.1068702290076336\n",
      "Recall = 0.059574468085106386\n",
      "Precision = 0.5185185185185185\n",
      "Training model 244/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4832004612417742\n",
      "F1_score = 0.08311688311688312\n",
      "Recall = 0.0446927374301676\n",
      "Precision = 0.5925925925925926\n",
      "Training model 245/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5204414664574027\n",
      "F1_score = 0.13479052823315116\n",
      "Recall = 0.07474747474747474\n",
      "Precision = 0.6851851851851852\n",
      "Training model 246/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5247074433375387\n",
      "F1_score = 0.14903846153846156\n",
      "Recall = 0.0856353591160221\n",
      "Precision = 0.5740740740740741\n",
      "Training model 247/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.49613594040968345\n",
      "F1_score = 0.08949416342412453\n",
      "Recall = 0.05\n",
      "Precision = 0.42592592592592593\n",
      "Training model 248/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.1, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5052368551285483\n",
      "F1_score = 0.10720268006700168\n",
      "Recall = 0.058931860036832415\n",
      "Precision = 0.5925925925925926\n",
      "Training model 249/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5388085794802213\n",
      "F1_score = 0.18471337579617833\n",
      "Recall = 0.11153846153846154\n",
      "Precision = 0.5370370370370371\n",
      "Training model 250/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5418285096813762\n",
      "F1_score = 0.19130434782608693\n",
      "Recall = 0.1134020618556701\n",
      "Precision = 0.6111111111111112\n",
      "Training model 251/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.4580335332000888\n",
      "F1_score = 0.06388206388206388\n",
      "Recall = 0.034210526315789476\n",
      "Precision = 0.48148148148148145\n",
      "Training model 252/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5309389637002343\n",
      "F1_score = 0.14925373134328357\n",
      "Recall = 0.08196721311475409\n",
      "Precision = 0.8333333333333334\n",
      "Training model 253/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5457073534901082\n",
      "F1_score = 0.14414414414414414\n",
      "Recall = 0.14035087719298245\n",
      "Precision = 0.14814814814814814\n",
      "Training model 254/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5410600675705323\n",
      "F1_score = 0.18581907090464547\n",
      "Recall = 0.10704225352112676\n",
      "Precision = 0.7037037037037037\n",
      "Training model 255/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 50}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.497858581754778\n",
      "F1_score = 0.09049773755656108\n",
      "Recall = 0.05154639175257732\n",
      "Precision = 0.37037037037037035\n",
      "Training model 256/256 with parameters: {'DELTA': 1e-06, 'EPOCHS': 20, 'EPSILON': 0.5, 'LOGGING_INTERVAL': 200, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 512, 'learning_rate': 0.001, 'num_epochs': 100}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.5038296492191009\n",
      "F1_score = 0.1036717062634989\n",
      "Recall = 0.05867970660146699\n",
      "Precision = 0.4444444444444444\n",
      "Grid search finished.\n",
      "Best AUC: 0.5663\n",
      "Best parameters: {'DELTA': 1e-05, 'EPOCHS': 20, 'EPSILON': 1.0, 'LOGGING_INTERVAL': 100, 'MAX_GRAD_NORM': 0.2, 'MAX_PHYSICAL_BATCH_SIZE': 256, 'learning_rate': 0.01, 'num_epochs': 100}\n"
     ]
    }
   ],
   "source": [
    "logDP.grid_search(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\privacy_engine.py:142: UserWarning: Secure RNG turned off. This is perfectly fine for experimentation as it allows for much faster training performance, but remember to turn it on and retrain one last time before production with ``secure_mode`` turned on.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\rdp.py:332: UserWarning: Optimal order is the largest alpha. Please consider expanding the range of alphas to get a tighter privacy bound.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\opacus\\accountants\\analysis\\prv\\prvs.py:50: RuntimeWarning: invalid value encountered in log\n",
      "  z = np.log((np.exp(t) + q - 1) / q)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with hyperparameters:\n",
      "  EPSILON: 1.0\n",
      "  DELTA: 1e-05\n",
      "  EPOCHS: 20\n",
      "  MAX_GRAD_NORM: 0.2\n",
      "  MAX_PHYSICAL_BATCH_SIZE: 256\n",
      "  LOGGING_INTERVAL: 100\n",
      "  learning_rate: 0.01\n",
      "  num_epochs: 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1359: UserWarning: Using a non-full backward hook when the forward contains multiple autograd Nodes is deprecated and will be removed in future versions. This hook will be missing some grad_input. Please use register_full_backward_hook to get the documented behavior.\n",
      "  warnings.warn(\"Using a non-full backward hook when the forward contains multiple autograd Nodes \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss=0.6596  | ɛ: 0.66 \n",
      "epoch: 20, loss=0.6125  | ɛ: 0.97 \n",
      "epoch: 30, loss=0.5674  | ɛ: 1.22 \n",
      "epoch: 40, loss=0.5229  | ɛ: 1.43 \n",
      "epoch: 50, loss=0.5003  | ɛ: 1.61 \n",
      "epoch: 60, loss=0.4629  | ɛ: 1.78 \n",
      "epoch: 70, loss=0.4759  | ɛ: 1.94 \n",
      "epoch: 80, loss=0.4271  | ɛ: 2.09 \n",
      "epoch: 90, loss=0.4737  | ɛ: 2.24 \n",
      "epoch: 100, loss=0.4348  | ɛ: 2.37 \n",
      "auc_score = 0.5522308161815471\n",
      "F1_score = 0.21686746987951808\n",
      "Recall = 0.12949640287769784\n",
      "Precision = 0.6666666666666666\n",
      "{'roc_auc_score': 0.5522308161815471, 'F1_score': 0.21686746987951808, 'Recall': 0.12949640287769784, 'Precision': 0.6666666666666666}\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lossesLogDP,epsilons,y_predicted=logDP.train_model()\n",
    "y_predicted_cls=logDP.predict_model(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VIII. So sánh hiệu quả của các mô hình sau DP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test,y_predicted_cls.cpu())\n",
    "\n",
    "# Tính AUC\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Vẽ đường ROC\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (LogistcRDP)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"../static/app/images/ROCLogisticRegressionDP.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "fpr, tpr, thresholds = metrics.roc_curve(y_test, yResultNaive1)\n",
    "\n",
    "# Tính AUC\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "\n",
    "# Vẽ đường ROC\n",
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (NaiveBayesDP)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig(\"../static/app/images/ROCNaiveBayesDP.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc_score = 0.7050194414987627\n",
      "F1_score = 0.21686746987951808\n",
      "Recall = 0.6666666666666666\n",
      "Precision = 0.12949640287769784\n",
      "+----------+--------------------+---------------------+--------------------+---------------------+\n",
      "|          |   roc_auc_score    |      F1_score       |       Recall       |      Precision      |\n",
      "+----------+--------------------+---------------------+--------------------+---------------------+\n",
      "|   LogR   | 0.6073210007462393 | 0.21768707482993196 | 0.2962962962962963 | 0.17204301075268819 |\n",
      "|  LogRDP  | 0.7050194414987627 | 0.21686746987951808 | 0.6666666666666666 | 0.12949640287769784 |\n",
      "|  NaiveB  | 0.6375535132162917 | 0.17575757575757575 | 0.5370370370370371 | 0.10507246376811594 |\n",
      "| NaiveBDP | 0.6412650720710107 | 0.17956656346749225 | 0.5370370370370371 | 0.10780669144981413 |\n",
      "+----------+--------------------+---------------------+--------------------+---------------------+\n"
     ]
    }
   ],
   "source": [
    "logResultDP =evaluateModel(y_test,y_predicted_cls.cpu())\n",
    "model_names = ['LogR', 'LogRDP', 'NaiveB', 'NaiveBDP']\n",
    "# Kết quả của hàm evaluateModel cho từng model\n",
    "results = [\n",
    "    logResult,logResultDP,NaiveResult,NaiveResult1\n",
    "]\n",
    "# Tạo DataFrame từ kết quả\n",
    "df_results = pd.DataFrame(results, index=model_names)\n",
    "from tabulate import tabulate\n",
    "table = tabulate(df_results, headers='keys', tablefmt='pretty', showindex=True)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IX. Phân tích và ứng dụng mô hình tiềm năng nhất"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sự thay đổi về độ riêng tư và hàm mất mát trước và sau khi áp dụng DP "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "compare= lossesLog.__len__()\n",
    "if lossesLog.__len__() > lossesLogDP.__len__():\n",
    "    compare = lossesLogDP.__len__()\n",
    "else:\n",
    "    compare = lossesLog.__len__()\n",
    "# Plotting loss over epochs\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.plot(range(1, compare+1), lossesLog[0:compare], label='Loss (Logistic Model)', marker='o')\n",
    "plt.plot(range(1, compare+1), lossesLogDP[0:compare], label='Loss (Logistic Model with DP)', marker='o')\n",
    "plt.plot(range(1, compare+1), epsilons[0:compare], label='Epsilon', marker='o')\n",
    "\n",
    "plt.title('Loss and Epsilon Over Epochs')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss / Epsilon')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.savefig(\"../static/app/images/CompareOldAndNewModel.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Áp dụng mô hình vào dự đoán dữ liệu thực tế"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_17548\\4056345809.py:26: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  prediction2 = dp_model(torch.tensor(df_single_person))\n"
     ]
    }
   ],
   "source": [
    "data_single_person = {\n",
    "    'gender': [1],\n",
    "    'age': [40],\n",
    "    'hypertension': [1],\n",
    "    'heart_disease': [1],\n",
    "    'ever_married': [1],\n",
    "    'Residence_type': [1],\n",
    "    'avg_glucose_level': [260],\n",
    "    'bmi': [26.0],\n",
    "    'work_type_Govt_job': [0],\n",
    "    'work_type_Private': [1],\n",
    "    'work_type_Self-employed': [0],\n",
    "    'work_type_children': [0],\n",
    "    'smoking_status_Unknown': [0],\n",
    "    'smoking_status_formerly smoked': [0],\n",
    "    'smoking_status_never smoked': [0],\n",
    "    'smoking_status_smokes': [1]\n",
    "}\n",
    "\n",
    "df_single_person = pd.DataFrame(data_single_person)\n",
    "df_single_person=sc.transform(df_single_person)\n",
    "df_single_person=torch.from_numpy(df_single_person.astype(np.float32))\n",
    "dp_model = LogisticRegression(num_features)\n",
    "dp_model.model=torch.load('./StruckPredict.pth')\n",
    "dp_model.eval()\n",
    "prediction2 = dp_model(torch.tensor(df_single_person))\n",
    "prediction2 = prediction2.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bạn có khả năng bị đột quỵ, vui lòng chú ý sức khoẻ!\n"
     ]
    }
   ],
   "source": [
    "if prediction2.item() ==0:\n",
    "    print(\"Xin chúc mừng bạn không có nguy cơ bị đột quỵ\")\n",
    "else:\n",
    "    print(\"Bạn có khả năng bị đột quỵ, vui lòng chú ý sức khoẻ!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
